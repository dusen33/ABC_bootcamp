{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1970년대 보스턴 지역의 주택 가격을 예측하는 회귀 문제"
      ],
      "metadata": {
        "id": "UHHxkGi983CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 보스턴 주택가격 데이터 준비하기"
      ],
      "metadata": {
        "id": "SUlsca0B88an"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anMG8cin8j3u"
      },
      "outputs": [],
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋: 80, 테스트셋:20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split=0.2, seed = 777)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 형태 확인하기"
      ],
      "metadata": {
        "id": "TOQ3qEAF9m8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train.shape', X_train.shape)\n",
        "print('y_train.shape', y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJMSvCzd9lHf",
        "outputId": "31ae5b07-ef56-4ea1-9d00-368b9f76c8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape (404, 13)\n",
            "y_train.shape (404,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_5gYWCP-VFE",
        "outputId": "d4c59ba1-8746-434e-9d33-1a9f0113745f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doYaGbgs-vno",
        "outputId": "910bfe0e-72b0-4442-f6b6-e05e5404f439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.5199e-01, 0.0000e+00, 1.0590e+01, 0.0000e+00, 4.8900e-01,\n",
              "       5.7830e+00, 7.2700e+01, 4.3549e+00, 4.0000e+00, 2.7700e+02,\n",
              "       1.8600e+01, 3.8943e+02, 1.8060e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train #numpy.ndarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeoX_mme-hIG",
        "outputId": "e0885ea4-42b3-4315-cb15-9f62fab6ad8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.5,  8.3, 17.2, 25. , 28.5, 23. , 18.9, 50. , 15.6, 38.7, 24.6,\n",
              "       23.3,  9.5, 20. , 18.3, 36.4,  5. , 19.4, 28.1, 17.8, 19.6, 24.5,\n",
              "       10.4, 23.7, 19.4, 23.9, 21.4, 29.9, 24.4, 23.1, 25. , 30.1, 22.8,\n",
              "       22.8, 22. , 24.8, 15.6, 22. , 19.6, 13.1, 22.5, 18.9, 14.6, 13.3,\n",
              "       17.4, 20.8, 10.8, 21.4, 17.2, 13.8, 28.7, 35.1, 10.2, 21.7, 20.5,\n",
              "       25. , 21.1, 15.6, 23.6, 23.2, 28.7, 16.6, 26.2,  9.6, 18.2, 31.7,\n",
              "       42.8, 16.1, 22.6, 18.1, 23.8, 11.8, 16. , 21.5, 13.9, 11.7, 44.8,\n",
              "       20.1, 50. , 22.1, 20.6, 14.6, 48.8, 22.9, 14.4, 23.9, 15.6, 19.9,\n",
              "       20.5,  8.7, 26.5, 20.3, 23.8, 44. , 18.5, 17.5, 22.8, 14.3, 10.9,\n",
              "       36.1, 25. , 17.9, 17.7, 35.2, 20. , 24.3, 32.9, 15. , 50. , 33.8,\n",
              "       21.9, 28.4, 10.2, 12. , 17.1, 17.1, 22. , 25.1, 20.9, 37.6, 15.6,\n",
              "       43.5, 17.8, 20. , 15.2, 21.1, 19.9, 22.6, 14.4, 13.8, 37.3, 12.5,\n",
              "       11.7, 26.6,  7.2, 18.6, 29. , 14.9, 14.2, 20.5, 19. , 50. , 27.1,\n",
              "       18.4, 20.7, 29.6, 35.4, 21.7, 43.8, 22.6, 19.3, 13.8, 50. , 20.2,\n",
              "       29.6, 31.6, 43.1, 20.4, 29.4, 15.1, 20.1, 14.5, 23.8, 21.9, 23. ,\n",
              "       15.3, 10.9, 23.7, 16.5, 27.1, 20.6, 13.3, 10.5, 16.4, 50. , 26.6,\n",
              "        8.4, 35.4, 24.7,  7.2, 23.3, 20.2, 18.2, 22.4, 20.4, 27.5, 16.8,\n",
              "       24.4, 23.3, 50. , 21.6, 20.1, 18.8, 17.4, 19.1,  5.6, 16.6, 30.5,\n",
              "       19.1, 20.7, 22.2, 29.1, 23.9, 17.1, 12.3, 27.5, 13. , 17.4, 21.7,\n",
              "       24.3, 33.4, 16.1, 17.3, 37.2, 23.2,  5. , 20.9, 30.8, 21.6, 29.8,\n",
              "       22. , 21.2, 25. , 32.2, 30.1, 21. , 26.4, 27. , 21. , 12.7, 50. ,\n",
              "       50. , 17. , 48.3, 50. , 22.3, 19.6, 33.4, 20. , 11.8, 18.4, 15. ,\n",
              "       22.2, 23.6, 16.8, 23.4, 31.1, 33.3, 24.8, 19.5, 22.6, 29.1, 22.7,\n",
              "       22. , 46. , 13.1, 24.4, 17.8, 23.2, 19.6, 17.2, 20. , 14. , 22. ,\n",
              "       13.8, 32. , 15.4, 24.2, 20.4, 33.1, 36. , 19.3, 50. , 24.5, 41.7,\n",
              "       11. , 22.4,  9.7, 31.2, 13.5, 19.9, 21.7, 24.1, 13.8, 22.2, 13.1,\n",
              "       18.5, 21.4,  8.3, 13.4, 21.5, 11.3,  7. , 19.8, 10.5, 22.9, 24.3,\n",
              "       20.3, 30.3, 23.9, 20.1, 29. , 23. , 23.3, 23.7, 16.2, 17.8, 12.6,\n",
              "       19.3, 19.5, 50. , 10.4, 19.5, 16.3,  8.1, 18.9, 24.7, 24.8, 12.8,\n",
              "       27.5, 16.7, 18.6, 26.7, 32.4, 14.8, 24.5, 19.4, 18.8, 19.3,  8.4,\n",
              "       18.9,  7. , 30.7, 39.8, 21.9, 21.8, 34.9, 25. , 34.7, 17.6, 33. ,\n",
              "       20.8, 18.2, 20.6, 16.7, 14.1, 22.9, 22.3, 30.1, 50. , 48.5, 18.7,\n",
              "       22.6, 21.2, 14.1, 25.3, 15.4, 15.2, 20.1, 23.1, 22.5, 21.7, 11.9,\n",
              "       14.9, 19.1, 31.6, 34.6, 15.2, 15.7, 11.5, 23.1, 22.7, 24.8, 23.9,\n",
              "       36.2,  7.5,  8.8, 19.4, 17.5,  8.5, 16.1, 19.5, 13.6, 18.5, 13.6,\n",
              "       16.5, 19. , 33.2, 21.4, 13.4, 23.7, 34.9,  7.4, 12.7, 20.3,  7.2,\n",
              "       22.2, 10.2, 19.4, 22. , 21.2, 14.5, 21. , 23.8])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_test.shape', X_test.shape)\n",
        "print('y_test.shape', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_lJz-0G9lDu",
        "outputId": "3f1c19ea-0863-4b63-a169-e08e37328b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test.shape (102, 13)\n",
            "y_test.shape (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbOkndnIoekB",
        "outputId": "cfcdc295-7e18-402f-aeb7-f87843cb8ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoYmSMrboeg6",
        "outputId": "77b8801d-c632-4cda-fb36-f7665a43b74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.5,  8.3, 17.2, 25. , 28.5, 23. , 18.9, 50. , 15.6, 38.7, 24.6,\n",
              "       23.3,  9.5, 20. , 18.3, 36.4,  5. , 19.4, 28.1, 17.8, 19.6, 24.5,\n",
              "       10.4, 23.7, 19.4, 23.9, 21.4, 29.9, 24.4, 23.1, 25. , 30.1, 22.8,\n",
              "       22.8, 22. , 24.8, 15.6, 22. , 19.6, 13.1, 22.5, 18.9, 14.6, 13.3,\n",
              "       17.4, 20.8, 10.8, 21.4, 17.2, 13.8, 28.7, 35.1, 10.2, 21.7, 20.5,\n",
              "       25. , 21.1, 15.6, 23.6, 23.2, 28.7, 16.6, 26.2,  9.6, 18.2, 31.7,\n",
              "       42.8, 16.1, 22.6, 18.1, 23.8, 11.8, 16. , 21.5, 13.9, 11.7, 44.8,\n",
              "       20.1, 50. , 22.1, 20.6, 14.6, 48.8, 22.9, 14.4, 23.9, 15.6, 19.9,\n",
              "       20.5,  8.7, 26.5, 20.3, 23.8, 44. , 18.5, 17.5, 22.8, 14.3, 10.9,\n",
              "       36.1, 25. , 17.9, 17.7, 35.2, 20. , 24.3, 32.9, 15. , 50. , 33.8,\n",
              "       21.9, 28.4, 10.2, 12. , 17.1, 17.1, 22. , 25.1, 20.9, 37.6, 15.6,\n",
              "       43.5, 17.8, 20. , 15.2, 21.1, 19.9, 22.6, 14.4, 13.8, 37.3, 12.5,\n",
              "       11.7, 26.6,  7.2, 18.6, 29. , 14.9, 14.2, 20.5, 19. , 50. , 27.1,\n",
              "       18.4, 20.7, 29.6, 35.4, 21.7, 43.8, 22.6, 19.3, 13.8, 50. , 20.2,\n",
              "       29.6, 31.6, 43.1, 20.4, 29.4, 15.1, 20.1, 14.5, 23.8, 21.9, 23. ,\n",
              "       15.3, 10.9, 23.7, 16.5, 27.1, 20.6, 13.3, 10.5, 16.4, 50. , 26.6,\n",
              "        8.4, 35.4, 24.7,  7.2, 23.3, 20.2, 18.2, 22.4, 20.4, 27.5, 16.8,\n",
              "       24.4, 23.3, 50. , 21.6, 20.1, 18.8, 17.4, 19.1,  5.6, 16.6, 30.5,\n",
              "       19.1, 20.7, 22.2, 29.1, 23.9, 17.1, 12.3, 27.5, 13. , 17.4, 21.7,\n",
              "       24.3, 33.4, 16.1, 17.3, 37.2, 23.2,  5. , 20.9, 30.8, 21.6, 29.8,\n",
              "       22. , 21.2, 25. , 32.2, 30.1, 21. , 26.4, 27. , 21. , 12.7, 50. ,\n",
              "       50. , 17. , 48.3, 50. , 22.3, 19.6, 33.4, 20. , 11.8, 18.4, 15. ,\n",
              "       22.2, 23.6, 16.8, 23.4, 31.1, 33.3, 24.8, 19.5, 22.6, 29.1, 22.7,\n",
              "       22. , 46. , 13.1, 24.4, 17.8, 23.2, 19.6, 17.2, 20. , 14. , 22. ,\n",
              "       13.8, 32. , 15.4, 24.2, 20.4, 33.1, 36. , 19.3, 50. , 24.5, 41.7,\n",
              "       11. , 22.4,  9.7, 31.2, 13.5, 19.9, 21.7, 24.1, 13.8, 22.2, 13.1,\n",
              "       18.5, 21.4,  8.3, 13.4, 21.5, 11.3,  7. , 19.8, 10.5, 22.9, 24.3,\n",
              "       20.3, 30.3, 23.9, 20.1, 29. , 23. , 23.3, 23.7, 16.2, 17.8, 12.6,\n",
              "       19.3, 19.5, 50. , 10.4, 19.5, 16.3,  8.1, 18.9, 24.7, 24.8, 12.8,\n",
              "       27.5, 16.7, 18.6, 26.7, 32.4, 14.8, 24.5, 19.4, 18.8, 19.3,  8.4,\n",
              "       18.9,  7. , 30.7, 39.8, 21.9, 21.8, 34.9, 25. , 34.7, 17.6, 33. ,\n",
              "       20.8, 18.2, 20.6, 16.7, 14.1, 22.9, 22.3, 30.1, 50. , 48.5, 18.7,\n",
              "       22.6, 21.2, 14.1, 25.3, 15.4, 15.2, 20.1, 23.1, 22.5, 21.7, 11.9,\n",
              "       14.9, 19.1, 31.6, 34.6, 15.2, 15.7, 11.5, 23.1, 22.7, 24.8, 23.9,\n",
              "       36.2,  7.5,  8.8, 19.4, 17.5,  8.5, 16.1, 19.5, 13.6, 18.5, 13.6,\n",
              "       16.5, 19. , 33.2, 21.4, 13.4, 23.7, 34.9,  7.4, 12.7, 20.3,  7.2,\n",
              "       22.2, 10.2, 19.4, 22. , 21.2, 14.5, 21. , 23.8])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리 (feature) 표준화(Standardzaion)"
      ],
      "metadata": {
        "id": "ZcuAGHPb-rjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# (데이터 - 전체평균) / 표준편차\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)"
      ],
      "metadata": {
        "id": "_-nU5koQ9k-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리(X_train, X_test) 둘 다 처리\n",
        "X_train = (X_train-mean)/std\n",
        "X_test = (X_test-mean)/std\n",
        "\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHBQ_Uwe9k75",
        "outputId": "784fa68e-6c4a-4448-8a4c-d552c3d4826d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.40102395 -0.48033655 -0.12089418 -0.28828791 -0.58254176 -0.68137272\n",
            "  0.11117586  0.26484408 -0.65187119 -0.80249043  0.0756568   0.37366783\n",
            "  0.69211835]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 분리"
      ],
      "metadata": {
        "id": "WmLzyKsOB-59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_var, y_train, y_var = train_test_split(X_train, y_train, test_size=0.33, random_state=777)\n",
        "\n",
        "print(X_train.shape, X_var.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW989I_49k5G",
        "outputId": "38b7bc7a-8ac4-4b56-b04a-e69ff6def79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(270, 13) (134, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성하기"
      ],
      "metadata": {
        "id": "8SAuQLsmGxeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation = 'relu', input_shape=(13,)))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1)) # activation = 'liner'"
      ],
      "metadata": {
        "id": "LdNsPedBDURa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 설정하기"
      ],
      "metadata": {
        "id": "46BXXTh2HaDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss ='mse',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "O-7N-hSvDUN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습하기"
      ],
      "metadata": {
        "id": "lF3PfCm8JI1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=300, validation_data = (X_var, y_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7VUrIyYDULn",
        "outputId": "163c27ac-becc-44b2-cdde-f2c2d8a007ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 18ms/step - loss: 544.2779 - mae: 21.6028 - mse: 544.2779 - val_loss: 594.6411 - val_mae: 22.0946 - val_mse: 594.6411\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 520.3958 - mae: 21.0392 - mse: 520.3958 - val_loss: 569.0352 - val_mae: 21.5112 - val_mse: 569.0352\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 494.1914 - mae: 20.4082 - mse: 494.1914 - val_loss: 539.2008 - val_mae: 20.8148 - val_mse: 539.2008\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 463.6421 - mae: 19.6552 - mse: 463.6421 - val_loss: 502.3601 - val_mae: 19.9387 - val_mse: 502.3601\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 425.5097 - mae: 18.7079 - mse: 425.5097 - val_loss: 457.1551 - val_mae: 18.8212 - val_mse: 457.1551\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 380.0081 - mae: 17.5508 - mse: 380.0081 - val_loss: 400.8521 - val_mae: 17.3877 - val_mse: 400.8521\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 322.4446 - mae: 16.0405 - mse: 322.4446 - val_loss: 335.5875 - val_mae: 15.6752 - val_mse: 335.5875\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 259.7053 - mae: 14.2309 - mse: 259.7053 - val_loss: 264.4409 - val_mae: 13.6558 - val_mse: 264.4409\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 194.9457 - mae: 12.1184 - mse: 194.9457 - val_loss: 194.5171 - val_mae: 11.3649 - val_mse: 194.5171\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 135.4010 - mae: 9.8243 - mse: 135.4010 - val_loss: 137.8674 - val_mae: 9.2128 - val_mse: 137.8674\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 91.1054 - mae: 7.6984 - mse: 91.1054 - val_loss: 99.8456 - val_mae: 7.5535 - val_mse: 99.8456\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 65.5017 - mae: 6.3788 - mse: 65.5017 - val_loss: 78.7193 - val_mae: 6.5463 - val_mse: 78.7193\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 51.8811 - mae: 5.6422 - mse: 51.8811 - val_loss: 66.5393 - val_mae: 5.9298 - val_mse: 66.5393\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43.0218 - mae: 5.0665 - mse: 43.0218 - val_loss: 57.4792 - val_mae: 5.4428 - val_mse: 57.4792\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 36.8261 - mae: 4.6451 - mse: 36.8261 - val_loss: 50.1524 - val_mae: 5.0445 - val_mse: 50.1524\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31.6396 - mae: 4.2601 - mse: 31.6396 - val_loss: 45.3043 - val_mae: 4.7645 - val_mse: 45.3043\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 28.5433 - mae: 3.9688 - mse: 28.5433 - val_loss: 41.4778 - val_mae: 4.5499 - val_mse: 41.4778\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 26.3616 - mae: 3.7487 - mse: 26.3616 - val_loss: 38.5557 - val_mae: 4.3555 - val_mse: 38.5557\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.8110 - mae: 3.6020 - mse: 24.8110 - val_loss: 36.2201 - val_mae: 4.2023 - val_mse: 36.2201\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 23.6049 - mae: 3.4742 - mse: 23.6049 - val_loss: 34.5320 - val_mae: 4.0795 - val_mse: 34.5320\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.7960 - mae: 3.3758 - mse: 22.7960 - val_loss: 33.3878 - val_mae: 3.9928 - val_mse: 33.3878\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.9481 - mae: 3.2965 - mse: 21.9481 - val_loss: 32.3748 - val_mae: 3.9204 - val_mse: 32.3748\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.2732 - mae: 3.2229 - mse: 21.2732 - val_loss: 31.6465 - val_mae: 3.8617 - val_mse: 31.6465\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.6168 - mae: 3.1719 - mse: 20.6168 - val_loss: 30.4903 - val_mae: 3.8111 - val_mse: 30.4903\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 20.0457 - mae: 3.1233 - mse: 20.0457 - val_loss: 29.7209 - val_mae: 3.7609 - val_mse: 29.7209\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.5323 - mae: 3.0753 - mse: 19.5323 - val_loss: 29.0159 - val_mae: 3.7067 - val_mse: 29.0159\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.0149 - mae: 3.0211 - mse: 19.0149 - val_loss: 28.5037 - val_mae: 3.6505 - val_mse: 28.5037\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.4995 - mae: 2.9714 - mse: 18.4995 - val_loss: 27.8234 - val_mae: 3.6137 - val_mse: 27.8234\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.1800 - mae: 2.9402 - mse: 18.1800 - val_loss: 27.4619 - val_mae: 3.5701 - val_mse: 27.4619\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.6953 - mae: 2.8832 - mse: 17.6953 - val_loss: 26.7764 - val_mae: 3.5158 - val_mse: 26.7764\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.2053 - mae: 2.8446 - mse: 17.2053 - val_loss: 26.1126 - val_mae: 3.4855 - val_mse: 26.1126\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.8703 - mae: 2.8088 - mse: 16.8703 - val_loss: 25.5281 - val_mae: 3.4369 - val_mse: 25.5281\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.5642 - mae: 2.7794 - mse: 16.5642 - val_loss: 24.9646 - val_mae: 3.4069 - val_mse: 24.9646\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.1935 - mae: 2.7385 - mse: 16.1935 - val_loss: 24.6800 - val_mae: 3.3681 - val_mse: 24.6800\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.9188 - mae: 2.7062 - mse: 15.9188 - val_loss: 24.3072 - val_mae: 3.3289 - val_mse: 24.3072\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.7442 - mae: 2.6734 - mse: 15.7442 - val_loss: 24.0151 - val_mae: 3.2614 - val_mse: 24.0151\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.4468 - mae: 2.6533 - mse: 15.4468 - val_loss: 23.3945 - val_mae: 3.2607 - val_mse: 23.3945\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.0919 - mae: 2.6199 - mse: 15.0919 - val_loss: 22.9900 - val_mae: 3.2253 - val_mse: 22.9900\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8526 - mae: 2.5958 - mse: 14.8526 - val_loss: 22.7953 - val_mae: 3.1961 - val_mse: 22.7953\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.6878 - mae: 2.5716 - mse: 14.6878 - val_loss: 22.9761 - val_mae: 3.1868 - val_mse: 22.9761\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.3773 - mae: 2.5479 - mse: 14.3773 - val_loss: 22.2275 - val_mae: 3.1529 - val_mse: 22.2275\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.1973 - mae: 2.5306 - mse: 14.1973 - val_loss: 21.6575 - val_mae: 3.1187 - val_mse: 21.6575\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.0693 - mae: 2.5232 - mse: 14.0693 - val_loss: 21.5012 - val_mae: 3.1170 - val_mse: 21.5012\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 13.8039 - mae: 2.4907 - mse: 13.8039 - val_loss: 21.3021 - val_mae: 3.0889 - val_mse: 21.3021\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.6622 - mae: 2.4610 - mse: 13.6622 - val_loss: 21.2207 - val_mae: 3.0531 - val_mse: 21.2207\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.5271 - mae: 2.4398 - mse: 13.5271 - val_loss: 21.1809 - val_mae: 3.0544 - val_mse: 21.1809\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.4022 - mae: 2.4299 - mse: 13.4022 - val_loss: 21.0143 - val_mae: 3.0709 - val_mse: 21.0143\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.1805 - mae: 2.4142 - mse: 13.1805 - val_loss: 20.5712 - val_mae: 3.0453 - val_mse: 20.5712\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.0380 - mae: 2.4032 - mse: 13.0380 - val_loss: 20.1430 - val_mae: 3.0076 - val_mse: 20.1430\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.9622 - mae: 2.3941 - mse: 12.9622 - val_loss: 20.1942 - val_mae: 3.0193 - val_mse: 20.1942\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7872 - mae: 2.3791 - mse: 12.7872 - val_loss: 19.8554 - val_mae: 3.0045 - val_mse: 19.8554\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.7160 - mae: 2.3720 - mse: 12.7160 - val_loss: 20.0200 - val_mae: 3.0174 - val_mse: 20.0200\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5934 - mae: 2.3659 - mse: 12.5934 - val_loss: 19.5869 - val_mae: 2.9899 - val_mse: 19.5869\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.4802 - mae: 2.3567 - mse: 12.4802 - val_loss: 19.2565 - val_mae: 2.9619 - val_mse: 19.2565\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4110 - mae: 2.3497 - mse: 12.4110 - val_loss: 19.2671 - val_mae: 2.9625 - val_mse: 19.2671\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.2700 - mae: 2.3436 - mse: 12.2700 - val_loss: 18.9550 - val_mae: 2.9517 - val_mse: 18.9550\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2023 - mae: 2.3256 - mse: 12.2023 - val_loss: 18.9507 - val_mae: 2.9337 - val_mse: 18.9507\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1124 - mae: 2.3200 - mse: 12.1124 - val_loss: 18.6461 - val_mae: 2.9151 - val_mse: 18.6461\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.0506 - mae: 2.3193 - mse: 12.0506 - val_loss: 18.3249 - val_mae: 2.9047 - val_mse: 18.3249\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.9610 - mae: 2.3129 - mse: 11.9610 - val_loss: 18.4641 - val_mae: 2.9034 - val_mse: 18.4641\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9073 - mae: 2.2935 - mse: 11.9073 - val_loss: 18.5401 - val_mae: 2.9047 - val_mse: 18.5401\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.8194 - mae: 2.2940 - mse: 11.8194 - val_loss: 18.4146 - val_mae: 2.9023 - val_mse: 18.4146\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.7073 - mae: 2.2995 - mse: 11.7073 - val_loss: 18.0300 - val_mae: 2.9039 - val_mse: 18.0300\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.6397 - mae: 2.2958 - mse: 11.6397 - val_loss: 17.9697 - val_mae: 2.8869 - val_mse: 17.9697\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.5528 - mae: 2.2872 - mse: 11.5528 - val_loss: 18.0390 - val_mae: 2.8780 - val_mse: 18.0390\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4917 - mae: 2.2810 - mse: 11.4917 - val_loss: 17.7366 - val_mae: 2.8505 - val_mse: 17.7366\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.4196 - mae: 2.2634 - mse: 11.4196 - val_loss: 18.1403 - val_mae: 2.8839 - val_mse: 18.1403\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3885 - mae: 2.2629 - mse: 11.3885 - val_loss: 17.9362 - val_mae: 2.8668 - val_mse: 17.9362\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3020 - mae: 2.2525 - mse: 11.3020 - val_loss: 17.7710 - val_mae: 2.8406 - val_mse: 17.7710\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.2559 - mae: 2.2424 - mse: 11.2559 - val_loss: 17.7137 - val_mae: 2.8542 - val_mse: 17.7137\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1554 - mae: 2.2339 - mse: 11.1554 - val_loss: 17.5767 - val_mae: 2.8446 - val_mse: 17.5767\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1235 - mae: 2.2501 - mse: 11.1235 - val_loss: 17.1657 - val_mae: 2.8218 - val_mse: 17.1657\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.0812 - mae: 2.2524 - mse: 11.0812 - val_loss: 17.3788 - val_mae: 2.8360 - val_mse: 17.3788\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.0006 - mae: 2.2210 - mse: 11.0006 - val_loss: 17.5154 - val_mae: 2.8336 - val_mse: 17.5154\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9565 - mae: 2.2172 - mse: 10.9565 - val_loss: 17.2551 - val_mae: 2.8163 - val_mse: 17.2551\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.9057 - mae: 2.2245 - mse: 10.9057 - val_loss: 17.3249 - val_mae: 2.8396 - val_mse: 17.3249\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8022 - mae: 2.2182 - mse: 10.8022 - val_loss: 17.0203 - val_mae: 2.8279 - val_mse: 17.0203\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7924 - mae: 2.2254 - mse: 10.7924 - val_loss: 16.7825 - val_mae: 2.8161 - val_mse: 16.7825\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7552 - mae: 2.2141 - mse: 10.7552 - val_loss: 17.0322 - val_mae: 2.7979 - val_mse: 17.0322\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6743 - mae: 2.2142 - mse: 10.6743 - val_loss: 17.0805 - val_mae: 2.8270 - val_mse: 17.0805\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6598 - mae: 2.2107 - mse: 10.6598 - val_loss: 16.8832 - val_mae: 2.8061 - val_mse: 16.8832\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6461 - mae: 2.2171 - mse: 10.6461 - val_loss: 16.2817 - val_mae: 2.7636 - val_mse: 16.2817\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6152 - mae: 2.2289 - mse: 10.6152 - val_loss: 16.3829 - val_mae: 2.8005 - val_mse: 16.3829\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4993 - mae: 2.2219 - mse: 10.4993 - val_loss: 16.5145 - val_mae: 2.7798 - val_mse: 16.5145\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3826 - mae: 2.1889 - mse: 10.3826 - val_loss: 16.7543 - val_mae: 2.7835 - val_mse: 16.7543\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3818 - mae: 2.1756 - mse: 10.3818 - val_loss: 16.6338 - val_mae: 2.7628 - val_mse: 16.6338\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4452 - mae: 2.1619 - mse: 10.4452 - val_loss: 16.6054 - val_mae: 2.7533 - val_mse: 16.6054\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3741 - mae: 2.1679 - mse: 10.3741 - val_loss: 16.0244 - val_mae: 2.7517 - val_mse: 16.0244\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.1710 - mae: 2.1748 - mse: 10.1710 - val_loss: 16.3698 - val_mae: 2.7646 - val_mse: 16.3698\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2693 - mae: 2.1690 - mse: 10.2693 - val_loss: 16.5681 - val_mae: 2.7750 - val_mse: 16.5681\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1759 - mae: 2.1718 - mse: 10.1759 - val_loss: 16.0223 - val_mae: 2.7358 - val_mse: 16.0223\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1206 - mae: 2.1569 - mse: 10.1206 - val_loss: 16.2774 - val_mae: 2.7383 - val_mse: 16.2774\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1282 - mae: 2.1625 - mse: 10.1282 - val_loss: 16.4705 - val_mae: 2.7718 - val_mse: 16.4705\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9801 - mae: 2.1521 - mse: 9.9801 - val_loss: 15.8675 - val_mae: 2.7368 - val_mse: 15.8675\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0633 - mae: 2.1705 - mse: 10.0633 - val_loss: 15.6318 - val_mae: 2.6999 - val_mse: 15.6318\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9486 - mae: 2.1511 - mse: 9.9486 - val_loss: 15.7973 - val_mae: 2.7511 - val_mse: 15.7973\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.9580 - mae: 2.1539 - mse: 9.9580 - val_loss: 16.1157 - val_mae: 2.7579 - val_mse: 16.1157\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8172 - mae: 2.1272 - mse: 9.8172 - val_loss: 15.7084 - val_mae: 2.7090 - val_mse: 15.7084\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8249 - mae: 2.1428 - mse: 9.8249 - val_loss: 15.5304 - val_mae: 2.6972 - val_mse: 15.5304\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7792 - mae: 2.1248 - mse: 9.7792 - val_loss: 15.7768 - val_mae: 2.7193 - val_mse: 15.7768\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6569 - mae: 2.1268 - mse: 9.6569 - val_loss: 15.4442 - val_mae: 2.7339 - val_mse: 15.4442\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6911 - mae: 2.1448 - mse: 9.6911 - val_loss: 15.1565 - val_mae: 2.7014 - val_mse: 15.1565\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6450 - mae: 2.1411 - mse: 9.6450 - val_loss: 15.4263 - val_mae: 2.7071 - val_mse: 15.4263\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5445 - mae: 2.1248 - mse: 9.5445 - val_loss: 15.4889 - val_mae: 2.6871 - val_mse: 15.4889\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5427 - mae: 2.1205 - mse: 9.5427 - val_loss: 15.4935 - val_mae: 2.6910 - val_mse: 15.4935\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5240 - mae: 2.1086 - mse: 9.5240 - val_loss: 15.4566 - val_mae: 2.6985 - val_mse: 15.4566\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4527 - mae: 2.1092 - mse: 9.4527 - val_loss: 15.1332 - val_mae: 2.6782 - val_mse: 15.1332\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4106 - mae: 2.1106 - mse: 9.4106 - val_loss: 15.1662 - val_mae: 2.7000 - val_mse: 15.1662\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3633 - mae: 2.1097 - mse: 9.3633 - val_loss: 15.2991 - val_mae: 2.6967 - val_mse: 15.2991\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2910 - mae: 2.0945 - mse: 9.2910 - val_loss: 15.0353 - val_mae: 2.6680 - val_mse: 15.0353\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2724 - mae: 2.0892 - mse: 9.2724 - val_loss: 15.1569 - val_mae: 2.6789 - val_mse: 15.1569\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2360 - mae: 2.0815 - mse: 9.2360 - val_loss: 15.0460 - val_mae: 2.6746 - val_mse: 15.0460\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1804 - mae: 2.0934 - mse: 9.1804 - val_loss: 14.6729 - val_mae: 2.6689 - val_mse: 14.6729\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2323 - mae: 2.1127 - mse: 9.2323 - val_loss: 14.8750 - val_mae: 2.6957 - val_mse: 14.8750\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.1527 - mae: 2.0948 - mse: 9.1527 - val_loss: 14.9267 - val_mae: 2.6652 - val_mse: 14.9267\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0570 - mae: 2.0814 - mse: 9.0570 - val_loss: 14.9414 - val_mae: 2.6668 - val_mse: 14.9414\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0705 - mae: 2.0768 - mse: 9.0705 - val_loss: 14.7147 - val_mae: 2.6380 - val_mse: 14.7147\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0171 - mae: 2.0845 - mse: 9.0171 - val_loss: 14.5368 - val_mae: 2.6570 - val_mse: 14.5368\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9625 - mae: 2.0689 - mse: 8.9625 - val_loss: 14.6920 - val_mae: 2.6457 - val_mse: 14.6920\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.8882 - mae: 2.0506 - mse: 8.8882 - val_loss: 14.6538 - val_mae: 2.6406 - val_mse: 14.6538\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8641 - mae: 2.0606 - mse: 8.8641 - val_loss: 14.2488 - val_mae: 2.6208 - val_mse: 14.2488\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8109 - mae: 2.0578 - mse: 8.8109 - val_loss: 14.4891 - val_mae: 2.6461 - val_mse: 14.4891\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8179 - mae: 2.0544 - mse: 8.8179 - val_loss: 14.8858 - val_mae: 2.6712 - val_mse: 14.8858\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6974 - mae: 2.0231 - mse: 8.6974 - val_loss: 14.2873 - val_mae: 2.6148 - val_mse: 14.2873\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7267 - mae: 2.0518 - mse: 8.7267 - val_loss: 14.0599 - val_mae: 2.6204 - val_mse: 14.0599\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6708 - mae: 2.0569 - mse: 8.6708 - val_loss: 14.2753 - val_mae: 2.6455 - val_mse: 14.2753\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6217 - mae: 2.0497 - mse: 8.6217 - val_loss: 14.1271 - val_mae: 2.6219 - val_mse: 14.1271\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5743 - mae: 2.0505 - mse: 8.5743 - val_loss: 13.9060 - val_mae: 2.6221 - val_mse: 13.9060\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5482 - mae: 2.0438 - mse: 8.5482 - val_loss: 14.3088 - val_mae: 2.6261 - val_mse: 14.3088\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4762 - mae: 2.0165 - mse: 8.4762 - val_loss: 14.3335 - val_mae: 2.6195 - val_mse: 14.3335\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3240 - mae: 2.0163 - mse: 8.3240 - val_loss: 13.8716 - val_mae: 2.6071 - val_mse: 13.8716\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4158 - mae: 2.0438 - mse: 8.4158 - val_loss: 13.7190 - val_mae: 2.6212 - val_mse: 13.7190\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3600 - mae: 2.0323 - mse: 8.3600 - val_loss: 13.8030 - val_mae: 2.5883 - val_mse: 13.8030\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2757 - mae: 2.0066 - mse: 8.2757 - val_loss: 13.8307 - val_mae: 2.5804 - val_mse: 13.8307\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2237 - mae: 1.9963 - mse: 8.2237 - val_loss: 13.8924 - val_mae: 2.5838 - val_mse: 13.8924\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1655 - mae: 2.0000 - mse: 8.1655 - val_loss: 13.6735 - val_mae: 2.5874 - val_mse: 13.6735\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1477 - mae: 1.9919 - mse: 8.1477 - val_loss: 13.6223 - val_mae: 2.5619 - val_mse: 13.6223\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0637 - mae: 1.9866 - mse: 8.0637 - val_loss: 13.7085 - val_mae: 2.5801 - val_mse: 13.7085\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0304 - mae: 1.9751 - mse: 8.0304 - val_loss: 13.6917 - val_mae: 2.5796 - val_mse: 13.6917\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0221 - mae: 1.9940 - mse: 8.0221 - val_loss: 13.5690 - val_mae: 2.5906 - val_mse: 13.5690\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9178 - mae: 1.9832 - mse: 7.9178 - val_loss: 13.2706 - val_mae: 2.5377 - val_mse: 13.2706\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9175 - mae: 1.9784 - mse: 7.9175 - val_loss: 13.3153 - val_mae: 2.5310 - val_mse: 13.3153\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8582 - mae: 1.9678 - mse: 7.8582 - val_loss: 13.6677 - val_mae: 2.5753 - val_mse: 13.6677\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7894 - mae: 1.9566 - mse: 7.7894 - val_loss: 13.4899 - val_mae: 2.5300 - val_mse: 13.4899\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7896 - mae: 1.9455 - mse: 7.7896 - val_loss: 13.3897 - val_mae: 2.5395 - val_mse: 13.3897\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7985 - mae: 1.9689 - mse: 7.7985 - val_loss: 12.9340 - val_mae: 2.5419 - val_mse: 12.9340\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.7540 - mae: 1.9545 - mse: 7.7540 - val_loss: 13.2663 - val_mae: 2.5230 - val_mse: 13.2663\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6277 - mae: 1.9372 - mse: 7.6277 - val_loss: 13.3420 - val_mae: 2.5412 - val_mse: 13.3420\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6078 - mae: 1.9442 - mse: 7.6078 - val_loss: 13.2790 - val_mae: 2.5399 - val_mse: 13.2790\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5783 - mae: 1.9374 - mse: 7.5783 - val_loss: 13.1278 - val_mae: 2.5291 - val_mse: 13.1278\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5634 - mae: 1.9485 - mse: 7.5634 - val_loss: 12.9780 - val_mae: 2.5087 - val_mse: 12.9780\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5549 - mae: 1.9191 - mse: 7.5549 - val_loss: 13.5950 - val_mae: 2.5338 - val_mse: 13.5950\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5220 - mae: 1.9232 - mse: 7.5220 - val_loss: 13.1218 - val_mae: 2.5433 - val_mse: 13.1218\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3831 - mae: 1.9263 - mse: 7.3831 - val_loss: 12.7545 - val_mae: 2.4953 - val_mse: 12.7545\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3625 - mae: 1.9006 - mse: 7.3625 - val_loss: 12.9518 - val_mae: 2.5131 - val_mse: 12.9518\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3282 - mae: 1.9036 - mse: 7.3282 - val_loss: 12.5586 - val_mae: 2.4815 - val_mse: 12.5586\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3105 - mae: 1.8974 - mse: 7.3105 - val_loss: 12.6236 - val_mae: 2.4848 - val_mse: 12.6236\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2443 - mae: 1.8955 - mse: 7.2443 - val_loss: 12.5430 - val_mae: 2.4850 - val_mse: 12.5430\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2870 - mae: 1.8880 - mse: 7.2870 - val_loss: 12.7724 - val_mae: 2.4709 - val_mse: 12.7724\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1729 - mae: 1.8892 - mse: 7.1729 - val_loss: 12.6012 - val_mae: 2.4913 - val_mse: 12.6012\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1246 - mae: 1.8904 - mse: 7.1246 - val_loss: 12.4717 - val_mae: 2.4743 - val_mse: 12.4717\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0981 - mae: 1.8719 - mse: 7.0981 - val_loss: 12.5126 - val_mae: 2.4823 - val_mse: 12.5126\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0450 - mae: 1.8760 - mse: 7.0450 - val_loss: 12.3342 - val_mae: 2.4780 - val_mse: 12.3342\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1249 - mae: 1.8916 - mse: 7.1249 - val_loss: 12.2074 - val_mae: 2.4452 - val_mse: 12.2074\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9916 - mae: 1.8865 - mse: 6.9916 - val_loss: 12.5329 - val_mae: 2.5192 - val_mse: 12.5329\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0428 - mae: 1.8808 - mse: 7.0428 - val_loss: 12.3833 - val_mae: 2.4517 - val_mse: 12.3833\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8694 - mae: 1.8632 - mse: 6.8694 - val_loss: 12.1323 - val_mae: 2.4522 - val_mse: 12.1323\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8537 - mae: 1.8589 - mse: 6.8537 - val_loss: 12.1170 - val_mae: 2.4505 - val_mse: 12.1170\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8750 - mae: 1.8654 - mse: 6.8750 - val_loss: 12.2974 - val_mae: 2.4901 - val_mse: 12.2974\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8317 - mae: 1.8557 - mse: 6.8317 - val_loss: 11.7239 - val_mae: 2.4063 - val_mse: 11.7239\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7369 - mae: 1.8582 - mse: 6.7369 - val_loss: 12.0355 - val_mae: 2.4407 - val_mse: 12.0355\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6927 - mae: 1.8472 - mse: 6.6927 - val_loss: 12.1245 - val_mae: 2.4469 - val_mse: 12.1245\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6676 - mae: 1.8394 - mse: 6.6676 - val_loss: 12.1719 - val_mae: 2.4413 - val_mse: 12.1719\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6070 - mae: 1.8214 - mse: 6.6070 - val_loss: 12.0999 - val_mae: 2.4342 - val_mse: 12.0999\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6740 - mae: 1.8429 - mse: 6.6740 - val_loss: 11.5638 - val_mae: 2.4178 - val_mse: 11.5638\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5675 - mae: 1.8494 - mse: 6.5675 - val_loss: 11.7446 - val_mae: 2.4048 - val_mse: 11.7446\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5990 - mae: 1.8185 - mse: 6.5990 - val_loss: 12.0969 - val_mae: 2.4238 - val_mse: 12.0969\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5202 - mae: 1.8193 - mse: 6.5202 - val_loss: 11.7628 - val_mae: 2.4155 - val_mse: 11.7628\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4636 - mae: 1.8117 - mse: 6.4636 - val_loss: 11.7762 - val_mae: 2.4053 - val_mse: 11.7762\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3908 - mae: 1.8107 - mse: 6.3908 - val_loss: 11.7210 - val_mae: 2.4287 - val_mse: 11.7210\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3685 - mae: 1.8092 - mse: 6.3685 - val_loss: 11.6011 - val_mae: 2.3901 - val_mse: 11.6011\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2857 - mae: 1.7959 - mse: 6.2857 - val_loss: 11.6155 - val_mae: 2.3992 - val_mse: 11.6155\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2682 - mae: 1.8017 - mse: 6.2682 - val_loss: 11.3736 - val_mae: 2.3932 - val_mse: 11.3736\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2149 - mae: 1.7988 - mse: 6.2149 - val_loss: 11.5790 - val_mae: 2.3874 - val_mse: 11.5790\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2147 - mae: 1.7906 - mse: 6.2147 - val_loss: 11.6100 - val_mae: 2.3927 - val_mse: 11.6100\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1812 - mae: 1.7816 - mse: 6.1812 - val_loss: 11.5625 - val_mae: 2.3992 - val_mse: 11.5625\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0975 - mae: 1.7687 - mse: 6.0975 - val_loss: 11.2369 - val_mae: 2.3544 - val_mse: 11.2369\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0992 - mae: 1.7715 - mse: 6.0992 - val_loss: 11.3347 - val_mae: 2.3690 - val_mse: 11.3347\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0492 - mae: 1.7697 - mse: 6.0492 - val_loss: 11.3869 - val_mae: 2.3912 - val_mse: 11.3869\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0215 - mae: 1.7645 - mse: 6.0215 - val_loss: 11.2463 - val_mae: 2.3730 - val_mse: 11.2463\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9790 - mae: 1.7584 - mse: 5.9790 - val_loss: 11.1234 - val_mae: 2.3513 - val_mse: 11.1234\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9584 - mae: 1.7583 - mse: 5.9584 - val_loss: 10.8523 - val_mae: 2.3267 - val_mse: 10.8523\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9120 - mae: 1.7472 - mse: 5.9120 - val_loss: 11.1321 - val_mae: 2.3511 - val_mse: 11.1321\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8947 - mae: 1.7523 - mse: 5.8947 - val_loss: 11.1296 - val_mae: 2.3569 - val_mse: 11.1296\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9438 - mae: 1.7379 - mse: 5.9438 - val_loss: 11.2773 - val_mae: 2.3374 - val_mse: 11.2773\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7999 - mae: 1.7242 - mse: 5.7999 - val_loss: 10.9906 - val_mae: 2.3423 - val_mse: 10.9906\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8487 - mae: 1.7479 - mse: 5.8487 - val_loss: 10.7192 - val_mae: 2.3350 - val_mse: 10.7192\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7170 - mae: 1.7241 - mse: 5.7170 - val_loss: 11.1935 - val_mae: 2.3617 - val_mse: 11.1935\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7432 - mae: 1.7318 - mse: 5.7432 - val_loss: 10.8911 - val_mae: 2.3202 - val_mse: 10.8911\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7807 - mae: 1.7390 - mse: 5.7807 - val_loss: 10.8480 - val_mae: 2.3459 - val_mse: 10.8480\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6238 - mae: 1.7072 - mse: 5.6238 - val_loss: 11.0173 - val_mae: 2.3231 - val_mse: 11.0173\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6561 - mae: 1.7174 - mse: 5.6561 - val_loss: 10.6989 - val_mae: 2.3129 - val_mse: 10.6989\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5570 - mae: 1.7007 - mse: 5.5570 - val_loss: 11.0078 - val_mae: 2.3303 - val_mse: 11.0078\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5587 - mae: 1.6968 - mse: 5.5587 - val_loss: 10.9045 - val_mae: 2.3287 - val_mse: 10.9045\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4969 - mae: 1.6948 - mse: 5.4969 - val_loss: 10.9618 - val_mae: 2.3383 - val_mse: 10.9618\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5279 - mae: 1.7125 - mse: 5.5279 - val_loss: 10.5986 - val_mae: 2.3235 - val_mse: 10.5986\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5172 - mae: 1.7021 - mse: 5.5172 - val_loss: 10.6870 - val_mae: 2.3014 - val_mse: 10.6870\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5274 - mae: 1.6967 - mse: 5.5274 - val_loss: 11.0460 - val_mae: 2.3571 - val_mse: 11.0460\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4182 - mae: 1.6799 - mse: 5.4182 - val_loss: 10.5386 - val_mae: 2.3024 - val_mse: 10.5386\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3795 - mae: 1.6820 - mse: 5.3795 - val_loss: 10.6222 - val_mae: 2.3078 - val_mse: 10.6222\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2787 - mae: 1.6622 - mse: 5.2787 - val_loss: 10.6565 - val_mae: 2.3029 - val_mse: 10.6565\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2990 - mae: 1.6659 - mse: 5.2990 - val_loss: 10.5894 - val_mae: 2.2902 - val_mse: 10.5894\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2670 - mae: 1.6610 - mse: 5.2670 - val_loss: 10.5475 - val_mae: 2.2947 - val_mse: 10.5475\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2018 - mae: 1.6650 - mse: 5.2018 - val_loss: 10.5309 - val_mae: 2.3199 - val_mse: 10.5309\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3194 - mae: 1.6672 - mse: 5.3194 - val_loss: 10.3163 - val_mae: 2.2610 - val_mse: 10.3163\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2621 - mae: 1.6679 - mse: 5.2621 - val_loss: 10.1271 - val_mae: 2.2564 - val_mse: 10.1271\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1980 - mae: 1.6558 - mse: 5.1980 - val_loss: 10.7402 - val_mae: 2.3373 - val_mse: 10.7402\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1080 - mae: 1.6331 - mse: 5.1080 - val_loss: 10.1964 - val_mae: 2.2676 - val_mse: 10.1964\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1984 - mae: 1.6454 - mse: 5.1984 - val_loss: 10.4736 - val_mae: 2.2800 - val_mse: 10.4736\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9879 - mae: 1.6291 - mse: 4.9879 - val_loss: 10.5215 - val_mae: 2.3255 - val_mse: 10.5215\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0622 - mae: 1.6399 - mse: 5.0622 - val_loss: 10.2925 - val_mae: 2.2708 - val_mse: 10.2925\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9887 - mae: 1.6237 - mse: 4.9887 - val_loss: 10.1378 - val_mae: 2.2526 - val_mse: 10.1378\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0548 - mae: 1.6347 - mse: 5.0548 - val_loss: 10.1976 - val_mae: 2.2798 - val_mse: 10.1976\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0071 - mae: 1.6246 - mse: 5.0071 - val_loss: 10.6430 - val_mae: 2.2867 - val_mse: 10.6430\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8993 - mae: 1.6057 - mse: 4.8993 - val_loss: 10.1081 - val_mae: 2.2810 - val_mse: 10.1081\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9122 - mae: 1.6206 - mse: 4.9122 - val_loss: 10.2105 - val_mae: 2.2750 - val_mse: 10.2105\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8826 - mae: 1.6031 - mse: 4.8826 - val_loss: 10.2631 - val_mae: 2.2899 - val_mse: 10.2631\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8475 - mae: 1.6014 - mse: 4.8475 - val_loss: 9.9148 - val_mae: 2.2403 - val_mse: 9.9148\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8088 - mae: 1.5930 - mse: 4.8088 - val_loss: 10.3613 - val_mae: 2.2688 - val_mse: 10.3613\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7947 - mae: 1.5944 - mse: 4.7947 - val_loss: 10.1749 - val_mae: 2.2712 - val_mse: 10.1749\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7323 - mae: 1.5886 - mse: 4.7323 - val_loss: 10.1983 - val_mae: 2.2553 - val_mse: 10.1983\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7198 - mae: 1.5782 - mse: 4.7198 - val_loss: 10.2013 - val_mae: 2.2670 - val_mse: 10.2013\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8100 - mae: 1.5906 - mse: 4.8100 - val_loss: 10.0036 - val_mae: 2.2253 - val_mse: 10.0036\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7013 - mae: 1.5824 - mse: 4.7013 - val_loss: 10.1632 - val_mae: 2.2757 - val_mse: 10.1632\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6687 - mae: 1.5717 - mse: 4.6687 - val_loss: 10.3120 - val_mae: 2.2500 - val_mse: 10.3120\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6258 - mae: 1.5591 - mse: 4.6258 - val_loss: 10.1588 - val_mae: 2.2584 - val_mse: 10.1588\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6348 - mae: 1.5789 - mse: 4.6348 - val_loss: 9.7402 - val_mae: 2.2299 - val_mse: 9.7402\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6626 - mae: 1.5847 - mse: 4.6626 - val_loss: 10.1155 - val_mae: 2.2518 - val_mse: 10.1155\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5792 - mae: 1.5581 - mse: 4.5792 - val_loss: 10.0377 - val_mae: 2.2376 - val_mse: 10.0377\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5613 - mae: 1.5605 - mse: 4.5613 - val_loss: 10.0626 - val_mae: 2.2468 - val_mse: 10.0626\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5146 - mae: 1.5504 - mse: 4.5146 - val_loss: 9.9772 - val_mae: 2.2349 - val_mse: 9.9772\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5571 - mae: 1.5489 - mse: 4.5571 - val_loss: 10.1487 - val_mae: 2.2448 - val_mse: 10.1487\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5659 - mae: 1.5601 - mse: 4.5659 - val_loss: 9.7720 - val_mae: 2.2098 - val_mse: 9.7720\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4608 - mae: 1.5341 - mse: 4.4608 - val_loss: 10.1033 - val_mae: 2.2622 - val_mse: 10.1033\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4302 - mae: 1.5307 - mse: 4.4302 - val_loss: 9.9135 - val_mae: 2.2181 - val_mse: 9.9135\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3980 - mae: 1.5225 - mse: 4.3980 - val_loss: 10.0024 - val_mae: 2.2350 - val_mse: 10.0024\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3825 - mae: 1.5223 - mse: 4.3825 - val_loss: 9.8742 - val_mae: 2.2158 - val_mse: 9.8742\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3668 - mae: 1.5188 - mse: 4.3668 - val_loss: 9.7384 - val_mae: 2.2110 - val_mse: 9.7384\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3161 - mae: 1.5084 - mse: 4.3161 - val_loss: 9.8026 - val_mae: 2.2186 - val_mse: 9.8026\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3118 - mae: 1.5047 - mse: 4.3118 - val_loss: 9.7864 - val_mae: 2.2104 - val_mse: 9.7864\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2863 - mae: 1.4978 - mse: 4.2863 - val_loss: 9.9103 - val_mae: 2.2211 - val_mse: 9.9103\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3235 - mae: 1.4977 - mse: 4.3235 - val_loss: 9.8215 - val_mae: 2.2110 - val_mse: 9.8215\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2424 - mae: 1.4909 - mse: 4.2424 - val_loss: 9.9419 - val_mae: 2.2226 - val_mse: 9.9419\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2095 - mae: 1.4888 - mse: 4.2095 - val_loss: 9.6484 - val_mae: 2.1962 - val_mse: 9.6484\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2475 - mae: 1.4856 - mse: 4.2475 - val_loss: 9.7334 - val_mae: 2.2002 - val_mse: 9.7334\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2108 - mae: 1.4814 - mse: 4.2108 - val_loss: 9.4359 - val_mae: 2.1746 - val_mse: 9.4359\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2412 - mae: 1.4998 - mse: 4.2412 - val_loss: 9.7365 - val_mae: 2.2141 - val_mse: 9.7365\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1723 - mae: 1.4834 - mse: 4.1723 - val_loss: 9.5216 - val_mae: 2.1983 - val_mse: 9.5216\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1414 - mae: 1.4807 - mse: 4.1414 - val_loss: 9.7795 - val_mae: 2.2142 - val_mse: 9.7795\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1408 - mae: 1.4672 - mse: 4.1408 - val_loss: 9.7127 - val_mae: 2.1956 - val_mse: 9.7127\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0748 - mae: 1.4588 - mse: 4.0748 - val_loss: 9.5627 - val_mae: 2.2051 - val_mse: 9.5627\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0930 - mae: 1.4619 - mse: 4.0930 - val_loss: 9.7798 - val_mae: 2.2053 - val_mse: 9.7798\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0530 - mae: 1.4519 - mse: 4.0530 - val_loss: 9.5297 - val_mae: 2.1933 - val_mse: 9.5297\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0474 - mae: 1.4484 - mse: 4.0474 - val_loss: 9.6382 - val_mae: 2.1958 - val_mse: 9.6382\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0273 - mae: 1.4583 - mse: 4.0273 - val_loss: 9.5779 - val_mae: 2.2089 - val_mse: 9.5779\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9567 - mae: 1.4393 - mse: 3.9567 - val_loss: 9.4613 - val_mae: 2.1700 - val_mse: 9.4613\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0512 - mae: 1.4435 - mse: 4.0512 - val_loss: 9.6617 - val_mae: 2.2094 - val_mse: 9.6617\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0100 - mae: 1.4292 - mse: 4.0100 - val_loss: 9.7865 - val_mae: 2.1991 - val_mse: 9.7865\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9315 - mae: 1.4290 - mse: 3.9315 - val_loss: 9.5588 - val_mae: 2.2100 - val_mse: 9.5588\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0083 - mae: 1.4619 - mse: 4.0083 - val_loss: 9.5075 - val_mae: 2.2031 - val_mse: 9.5075\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9318 - mae: 1.4336 - mse: 3.9318 - val_loss: 9.4223 - val_mae: 2.1666 - val_mse: 9.4223\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9020 - mae: 1.4345 - mse: 3.9020 - val_loss: 9.7586 - val_mae: 2.2057 - val_mse: 9.7586\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9885 - mae: 1.4604 - mse: 3.9885 - val_loss: 9.6008 - val_mae: 2.2100 - val_mse: 9.6008\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8914 - mae: 1.4284 - mse: 3.8914 - val_loss: 9.3308 - val_mae: 2.1593 - val_mse: 9.3308\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8398 - mae: 1.4170 - mse: 3.8398 - val_loss: 9.5527 - val_mae: 2.1876 - val_mse: 9.5527\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8332 - mae: 1.4145 - mse: 3.8332 - val_loss: 9.6268 - val_mae: 2.2093 - val_mse: 9.6268\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8895 - mae: 1.4240 - mse: 3.8895 - val_loss: 9.3586 - val_mae: 2.1805 - val_mse: 9.3586\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8942 - mae: 1.4259 - mse: 3.8942 - val_loss: 9.6088 - val_mae: 2.2134 - val_mse: 9.6088\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7773 - mae: 1.3992 - mse: 3.7773 - val_loss: 9.0642 - val_mae: 2.1563 - val_mse: 9.0642\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7871 - mae: 1.4189 - mse: 3.7871 - val_loss: 9.6056 - val_mae: 2.1989 - val_mse: 9.6056\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7450 - mae: 1.4000 - mse: 3.7450 - val_loss: 9.3463 - val_mae: 2.1799 - val_mse: 9.3463\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7484 - mae: 1.4004 - mse: 3.7484 - val_loss: 9.4905 - val_mae: 2.1906 - val_mse: 9.4905\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6926 - mae: 1.3903 - mse: 3.6926 - val_loss: 9.2253 - val_mae: 2.1723 - val_mse: 9.2253\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7171 - mae: 1.3846 - mse: 3.7171 - val_loss: 9.6149 - val_mae: 2.1983 - val_mse: 9.6149\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6498 - mae: 1.3734 - mse: 3.6498 - val_loss: 9.4290 - val_mae: 2.1845 - val_mse: 9.4290\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6653 - mae: 1.3833 - mse: 3.6653 - val_loss: 9.4401 - val_mae: 2.1895 - val_mse: 9.4401\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6426 - mae: 1.3796 - mse: 3.6426 - val_loss: 9.4945 - val_mae: 2.1873 - val_mse: 9.4945\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6348 - mae: 1.3701 - mse: 3.6348 - val_loss: 9.3611 - val_mae: 2.1658 - val_mse: 9.3611\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6236 - mae: 1.3783 - mse: 3.6236 - val_loss: 9.2325 - val_mae: 2.1767 - val_mse: 9.2325\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6272 - mae: 1.3706 - mse: 3.6272 - val_loss: 9.3816 - val_mae: 2.1638 - val_mse: 9.3816\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5721 - mae: 1.3661 - mse: 3.5721 - val_loss: 9.3560 - val_mae: 2.1751 - val_mse: 9.3560\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5814 - mae: 1.3606 - mse: 3.5814 - val_loss: 9.1781 - val_mae: 2.1430 - val_mse: 9.1781\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5396 - mae: 1.3640 - mse: 3.5396 - val_loss: 8.9683 - val_mae: 2.1402 - val_mse: 8.9683\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5305 - mae: 1.3716 - mse: 3.5305 - val_loss: 9.3620 - val_mae: 2.1804 - val_mse: 9.3620\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5213 - mae: 1.3683 - mse: 3.5213 - val_loss: 9.4235 - val_mae: 2.1813 - val_mse: 9.4235\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5281 - mae: 1.3603 - mse: 3.5281 - val_loss: 9.2517 - val_mae: 2.1510 - val_mse: 9.2517\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5253 - mae: 1.3604 - mse: 3.5253 - val_loss: 9.2559 - val_mae: 2.1446 - val_mse: 9.2559\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4769 - mae: 1.3506 - mse: 3.4769 - val_loss: 9.3389 - val_mae: 2.1738 - val_mse: 9.3389\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.5148 - mae: 1.3371 - mse: 3.5148 - val_loss: 9.3317 - val_mae: 2.1545 - val_mse: 9.3317\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4319 - mae: 1.3401 - mse: 3.4319 - val_loss: 9.4025 - val_mae: 2.1777 - val_mse: 9.4025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 결과 분석"
      ],
      "metadata": {
        "id": "eZQDq81wKASU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his_dict = history.history\n",
        "mse = his_dict['mse']\n",
        "val_mse = his_dict['val_mse'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
        "\n",
        "epochs = range(1, len(mse) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# 훈련 및 검증 손실 그리기\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, mse, color = 'blue', label = 'train_mse')\n",
        "ax1.plot(epochs, val_mse, color = 'orange', label = 'val_mse')\n",
        "ax1.set_title('train and val mse')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('mse')\n",
        "ax1.legend()\n",
        "\n",
        "mae = his_dict['mae']\n",
        "val_mae = his_dict['val_mae']\n",
        "\n",
        "# 훈련 및 검증 정확도 그리기\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, mae, color = 'blue', label = 'train_mae')\n",
        "ax2.plot(epochs, val_mae, color = 'orange', label = 'val_mae')\n",
        "ax2.set_title('train and val mae')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7g3K_p2DUJY",
        "outputId": "c631fd24-6f68-4a38-eb8c-2e73f201bdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가하기"
      ],
      "metadata": {
        "id": "bBR23DgNLldP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # 2.2 -> 실제 집값과 2,200 달러 정도 차이로 집값 예측"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS4zqRZ1DUHT",
        "outputId": "c3d6e520-b5b7-49bf-c8aa-0a992a856b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 9.9074 - mae: 2.1823 - mse: 9.9074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.907391548156738, 2.182342052459717, 9.907391548156738]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 예측하고 결과 확인"
      ],
      "metadata": {
        "id": "b-VRH7TiMLni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, test_predictions)\n",
        "plt.xlabel('True Values [Price]')\n",
        "plt.ylabel('Predictions [Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJeg_J2QMNzH",
        "outputId": "3272d3e4-19a7-43b3-89df-1313331c4f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold 사용하여 모델 학습하기\n",
        "\n",
        "*   학습 데이터 부족으로 성능이 낮은 경우 적용 가능\n",
        "*   검증 데이터셋을 K-Fold로 사용하여, 학습 데이터 확보\n",
        "\n"
      ],
      "metadata": {
        "id": "C91rVghaNlHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold를 위한 데이터 준비하기"
      ],
      "metadata": {
        "id": "O2ntg84-N6-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋:80, 테스트셋:20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2, seed=777)"
      ],
      "metadata": {
        "id": "PMdkTIhpMNw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "HZmI-QkTOGVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# (데이터-전체평균)/표준편차\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "# 전처리(X_train, X_test) 둘 다 처리\n",
        "X_train = (X_train-mean)/std\n",
        "X_teat = (X_test-mean)/std"
      ],
      "metadata": {
        "id": "geYtBqwvMNLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold를 사용한 모델 학습"
      ],
      "metadata": {
        "id": "pNoMCVq7OUCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 3-Fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1)) # 연속적인 값 -> linear -> defalut 가 linear 함수임, activation=linear\n",
        "\n",
        "  model.compile(optimizer='adam', loss ='mse', metrics=['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(KFold)의 평가 정보를 담는 리스트 선언\n",
        "mae_list =[]\n",
        "\n",
        "# K번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "\n",
        "  # 학습데이터, 검증데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기\n",
        "  model.fit(X_train_fold, y_train_fold, epochs=300, validation_data=(X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXkbZGnbOTjP",
        "outputId": "c8c8b1da-f03e-4e1e-dfb3-46da3c094a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 16ms/step - loss: 543.5356 - mae: 21.4973 - val_loss: 514.6813 - val_mae: 20.8912\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 508.3042 - mae: 20.6750 - val_loss: 479.1526 - val_mae: 20.0403\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 469.2623 - mae: 19.7489 - val_loss: 439.7313 - val_mae: 19.0595\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 424.9160 - mae: 18.6640 - val_loss: 394.7339 - val_mae: 17.8876\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 374.6997 - mae: 17.3370 - val_loss: 342.5876 - val_mae: 16.4497\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 316.9722 - mae: 15.7324 - val_loss: 284.1711 - val_mae: 14.6594\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 254.4742 - mae: 13.8032 - val_loss: 224.1742 - val_mae: 12.5592\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 195.7764 - mae: 11.6800 - val_loss: 169.5675 - val_mae: 10.4385\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 145.9832 - mae: 9.6462 - val_loss: 126.7469 - val_mae: 8.5860\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 111.0806 - mae: 8.0108 - val_loss: 97.3063 - val_mae: 7.2924\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 89.6726 - mae: 7.0641 - val_loss: 79.2329 - val_mae: 6.5203\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 75.7250 - mae: 6.4742 - val_loss: 67.6055 - val_mae: 6.0321\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 66.1693 - mae: 6.0738 - val_loss: 57.4196 - val_mae: 5.5272\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 57.0073 - mae: 5.6667 - val_loss: 49.4688 - val_mae: 5.1000\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 49.3477 - mae: 5.2399 - val_loss: 43.5858 - val_mae: 4.7470\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 43.5123 - mae: 4.9172 - val_loss: 38.0619 - val_mae: 4.4233\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 38.5739 - mae: 4.5886 - val_loss: 33.7401 - val_mae: 4.1627\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 34.5855 - mae: 4.2999 - val_loss: 30.5699 - val_mae: 3.9831\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31.4862 - mae: 4.0475 - val_loss: 28.2768 - val_mae: 3.8597\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29.2031 - mae: 3.8636 - val_loss: 26.3361 - val_mae: 3.7253\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 27.1307 - mae: 3.6954 - val_loss: 24.8595 - val_mae: 3.6350\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25.4479 - mae: 3.5744 - val_loss: 23.7591 - val_mae: 3.5591\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.1582 - mae: 3.4634 - val_loss: 22.9445 - val_mae: 3.4856\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 23.1483 - mae: 3.3579 - val_loss: 22.3973 - val_mae: 3.4372\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 22.0578 - mae: 3.2593 - val_loss: 21.9064 - val_mae: 3.4064\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.2392 - mae: 3.1867 - val_loss: 21.5379 - val_mae: 3.3856\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.5453 - mae: 3.1266 - val_loss: 21.1756 - val_mae: 3.3726\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.8744 - mae: 3.0745 - val_loss: 20.7285 - val_mae: 3.3447\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.2492 - mae: 3.0122 - val_loss: 20.3199 - val_mae: 3.3096\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.6899 - mae: 2.9512 - val_loss: 20.0374 - val_mae: 3.2775\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.1971 - mae: 2.8968 - val_loss: 19.8175 - val_mae: 3.2651\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.7720 - mae: 2.8570 - val_loss: 19.6082 - val_mae: 3.2583\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.3479 - mae: 2.8328 - val_loss: 19.4383 - val_mae: 3.2533\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 17.0638 - mae: 2.8121 - val_loss: 19.1867 - val_mae: 3.2350\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.6703 - mae: 2.7634 - val_loss: 19.0320 - val_mae: 3.2126\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.2993 - mae: 2.7346 - val_loss: 18.7732 - val_mae: 3.1929\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.0491 - mae: 2.7024 - val_loss: 18.6172 - val_mae: 3.1695\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.6905 - mae: 2.6654 - val_loss: 18.3926 - val_mae: 3.1492\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.3875 - mae: 2.6386 - val_loss: 18.2373 - val_mae: 3.1347\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.1378 - mae: 2.6221 - val_loss: 18.0461 - val_mae: 3.1207\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8607 - mae: 2.5974 - val_loss: 17.8660 - val_mae: 3.1039\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6144 - mae: 2.5752 - val_loss: 17.7596 - val_mae: 3.0958\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.4143 - mae: 2.5587 - val_loss: 17.6405 - val_mae: 3.0886\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.1624 - mae: 2.5357 - val_loss: 17.4895 - val_mae: 3.0766\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9846 - mae: 2.5264 - val_loss: 17.3206 - val_mae: 3.0650\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7866 - mae: 2.5147 - val_loss: 17.2639 - val_mae: 3.0772\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7010 - mae: 2.5228 - val_loss: 17.0795 - val_mae: 3.0647\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.3287 - mae: 2.4850 - val_loss: 16.9986 - val_mae: 3.0475\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.1802 - mae: 2.4578 - val_loss: 16.9307 - val_mae: 3.0211\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1714 - mae: 2.4431 - val_loss: 16.8243 - val_mae: 3.0153\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.8702 - mae: 2.4409 - val_loss: 16.8202 - val_mae: 3.0383\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6720 - mae: 2.4362 - val_loss: 16.6358 - val_mae: 3.0243\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5361 - mae: 2.4202 - val_loss: 16.5652 - val_mae: 3.0145\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3952 - mae: 2.4018 - val_loss: 16.4622 - val_mae: 3.0000\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.3060 - mae: 2.3992 - val_loss: 16.3904 - val_mae: 3.0114\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2362 - mae: 2.4018 - val_loss: 16.4597 - val_mae: 3.0207\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.0313 - mae: 2.3750 - val_loss: 16.1754 - val_mae: 2.9936\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.8499 - mae: 2.3681 - val_loss: 16.1776 - val_mae: 2.9952\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7720 - mae: 2.3567 - val_loss: 16.0924 - val_mae: 2.9841\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.6582 - mae: 2.3481 - val_loss: 15.9545 - val_mae: 2.9716\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5514 - mae: 2.3367 - val_loss: 15.9732 - val_mae: 2.9748\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5019 - mae: 2.3239 - val_loss: 15.8239 - val_mae: 2.9504\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3453 - mae: 2.3133 - val_loss: 15.7793 - val_mae: 2.9600\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.2232 - mae: 2.3111 - val_loss: 15.7840 - val_mae: 2.9668\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.1613 - mae: 2.3086 - val_loss: 15.7557 - val_mae: 2.9628\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.0582 - mae: 2.3021 - val_loss: 15.6072 - val_mae: 2.9485\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.9767 - mae: 2.2930 - val_loss: 15.6267 - val_mae: 2.9542\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.8873 - mae: 2.2878 - val_loss: 15.6702 - val_mae: 2.9620\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.7847 - mae: 2.2750 - val_loss: 15.5937 - val_mae: 2.9523\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.7319 - mae: 2.2698 - val_loss: 15.5502 - val_mae: 2.9317\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6548 - mae: 2.2661 - val_loss: 15.5782 - val_mae: 2.9425\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4976 - mae: 2.2528 - val_loss: 15.5060 - val_mae: 2.9464\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.5509 - mae: 2.2626 - val_loss: 15.6668 - val_mae: 2.9691\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4518 - mae: 2.2554 - val_loss: 15.3325 - val_mae: 2.9230\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3169 - mae: 2.2315 - val_loss: 15.2332 - val_mae: 2.9080\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3078 - mae: 2.2416 - val_loss: 15.3702 - val_mae: 2.9368\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2023 - mae: 2.2439 - val_loss: 15.2739 - val_mae: 2.9266\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0480 - mae: 2.2186 - val_loss: 15.2118 - val_mae: 2.9150\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9657 - mae: 2.2078 - val_loss: 15.0956 - val_mae: 2.8985\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8837 - mae: 2.1969 - val_loss: 15.0790 - val_mae: 2.8960\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8275 - mae: 2.1864 - val_loss: 14.9964 - val_mae: 2.8845\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7994 - mae: 2.1807 - val_loss: 14.8395 - val_mae: 2.8624\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7502 - mae: 2.1877 - val_loss: 15.0863 - val_mae: 2.8954\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6148 - mae: 2.1706 - val_loss: 15.1132 - val_mae: 2.8931\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5421 - mae: 2.1644 - val_loss: 14.9932 - val_mae: 2.8827\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4934 - mae: 2.1630 - val_loss: 14.9353 - val_mae: 2.8792\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4305 - mae: 2.1473 - val_loss: 14.9141 - val_mae: 2.8721\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4458 - mae: 2.1578 - val_loss: 15.0309 - val_mae: 2.8816\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1953 - mae: 2.1268 - val_loss: 14.7745 - val_mae: 2.8500\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3417 - mae: 2.1432 - val_loss: 14.7026 - val_mae: 2.8353\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1595 - mae: 2.1226 - val_loss: 14.8114 - val_mae: 2.8588\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1305 - mae: 2.1262 - val_loss: 14.7344 - val_mae: 2.8522\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0591 - mae: 2.1258 - val_loss: 14.9176 - val_mae: 2.8836\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9946 - mae: 2.1228 - val_loss: 14.7946 - val_mae: 2.8567\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9193 - mae: 2.1089 - val_loss: 14.6654 - val_mae: 2.8331\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8130 - mae: 2.0947 - val_loss: 14.5845 - val_mae: 2.8338\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7472 - mae: 2.0921 - val_loss: 14.5415 - val_mae: 2.8294\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7161 - mae: 2.0894 - val_loss: 14.5148 - val_mae: 2.8197\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6490 - mae: 2.0851 - val_loss: 14.4237 - val_mae: 2.8011\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5987 - mae: 2.0731 - val_loss: 14.3637 - val_mae: 2.7861\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5287 - mae: 2.0649 - val_loss: 14.2721 - val_mae: 2.7647\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4748 - mae: 2.0640 - val_loss: 14.4010 - val_mae: 2.7836\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4458 - mae: 2.0679 - val_loss: 14.5271 - val_mae: 2.8105\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3540 - mae: 2.0522 - val_loss: 14.3784 - val_mae: 2.7903\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3032 - mae: 2.0445 - val_loss: 14.2135 - val_mae: 2.7653\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2788 - mae: 2.0413 - val_loss: 14.2420 - val_mae: 2.7767\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2208 - mae: 2.0347 - val_loss: 14.2230 - val_mae: 2.7666\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1429 - mae: 2.0250 - val_loss: 14.1596 - val_mae: 2.7579\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1122 - mae: 2.0170 - val_loss: 14.0794 - val_mae: 2.7493\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1992 - mae: 2.0372 - val_loss: 14.3130 - val_mae: 2.7907\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0371 - mae: 2.0146 - val_loss: 14.2847 - val_mae: 2.7756\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9538 - mae: 2.0064 - val_loss: 14.1662 - val_mae: 2.7477\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9185 - mae: 2.0039 - val_loss: 14.1855 - val_mae: 2.7540\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8824 - mae: 1.9939 - val_loss: 14.1613 - val_mae: 2.7499\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8476 - mae: 1.9940 - val_loss: 14.2023 - val_mae: 2.7671\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8224 - mae: 2.0024 - val_loss: 14.1001 - val_mae: 2.7429\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6716 - mae: 1.9724 - val_loss: 14.1801 - val_mae: 2.7546\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6775 - mae: 1.9714 - val_loss: 14.1631 - val_mae: 2.7526\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5914 - mae: 1.9653 - val_loss: 14.0762 - val_mae: 2.7295\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5191 - mae: 1.9654 - val_loss: 14.2535 - val_mae: 2.7657\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4849 - mae: 1.9651 - val_loss: 14.3027 - val_mae: 2.7650\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4882 - mae: 1.9536 - val_loss: 14.1365 - val_mae: 2.7376\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3513 - mae: 1.9366 - val_loss: 14.2130 - val_mae: 2.7478\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3639 - mae: 1.9474 - val_loss: 14.0572 - val_mae: 2.7239\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.2925 - mae: 1.9382 - val_loss: 14.1820 - val_mae: 2.7456\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2403 - mae: 1.9251 - val_loss: 14.1132 - val_mae: 2.7494\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1893 - mae: 1.9198 - val_loss: 13.9319 - val_mae: 2.7164\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1841 - mae: 1.9237 - val_loss: 13.9282 - val_mae: 2.7223\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0998 - mae: 1.9199 - val_loss: 13.9020 - val_mae: 2.7091\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0732 - mae: 1.9124 - val_loss: 13.9235 - val_mae: 2.7108\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0194 - mae: 1.9007 - val_loss: 14.0377 - val_mae: 2.7207\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9978 - mae: 1.9049 - val_loss: 13.9545 - val_mae: 2.7049\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9264 - mae: 1.9042 - val_loss: 14.2573 - val_mae: 2.7864\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9204 - mae: 1.9057 - val_loss: 14.0994 - val_mae: 2.7506\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8348 - mae: 1.8855 - val_loss: 14.0593 - val_mae: 2.7180\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.8584 - mae: 1.8921 - val_loss: 14.1697 - val_mae: 2.7503\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7656 - mae: 1.8675 - val_loss: 13.9724 - val_mae: 2.7120\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.7376 - mae: 1.8632 - val_loss: 13.9376 - val_mae: 2.7041\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6811 - mae: 1.8677 - val_loss: 13.9905 - val_mae: 2.7189\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.6325 - mae: 1.8625 - val_loss: 13.9921 - val_mae: 2.7163\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5610 - mae: 1.8485 - val_loss: 14.0103 - val_mae: 2.7096\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.5803 - mae: 1.8560 - val_loss: 14.0740 - val_mae: 2.7146\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5283 - mae: 1.8542 - val_loss: 14.2294 - val_mae: 2.7517\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4688 - mae: 1.8284 - val_loss: 14.1372 - val_mae: 2.7252\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4296 - mae: 1.8267 - val_loss: 14.2561 - val_mae: 2.7389\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4183 - mae: 1.8385 - val_loss: 14.1952 - val_mae: 2.7629\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4336 - mae: 1.8237 - val_loss: 13.9942 - val_mae: 2.7106\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4197 - mae: 1.8282 - val_loss: 14.0222 - val_mae: 2.7098\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.2386 - mae: 1.8169 - val_loss: 14.1996 - val_mae: 2.7720\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3116 - mae: 1.8232 - val_loss: 14.0454 - val_mae: 2.7159\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2148 - mae: 1.8096 - val_loss: 13.9981 - val_mae: 2.7255\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1388 - mae: 1.8011 - val_loss: 14.1184 - val_mae: 2.7123\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0965 - mae: 1.7924 - val_loss: 14.1963 - val_mae: 2.7308\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0845 - mae: 1.7888 - val_loss: 14.2194 - val_mae: 2.7523\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0351 - mae: 1.7856 - val_loss: 14.1332 - val_mae: 2.7059\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.0181 - mae: 1.7823 - val_loss: 14.2146 - val_mae: 2.7482\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0095 - mae: 1.7812 - val_loss: 14.3283 - val_mae: 2.7700\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9457 - mae: 1.7722 - val_loss: 14.0670 - val_mae: 2.7015\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9195 - mae: 1.7627 - val_loss: 14.0807 - val_mae: 2.7126\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8290 - mae: 1.7537 - val_loss: 14.1075 - val_mae: 2.7293\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8222 - mae: 1.7587 - val_loss: 14.1908 - val_mae: 2.7339\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.7700 - mae: 1.7496 - val_loss: 14.2066 - val_mae: 2.7249\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7605 - mae: 1.7539 - val_loss: 14.3330 - val_mae: 2.7426\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.7278 - mae: 1.7457 - val_loss: 14.2615 - val_mae: 2.7368\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.7095 - mae: 1.7406 - val_loss: 14.3245 - val_mae: 2.7392\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.6606 - mae: 1.7379 - val_loss: 14.1943 - val_mae: 2.7166\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6582 - mae: 1.7317 - val_loss: 14.4640 - val_mae: 2.7520\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.6739 - mae: 1.7618 - val_loss: 14.6787 - val_mae: 2.8111\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5766 - mae: 1.7350 - val_loss: 14.3830 - val_mae: 2.7464\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5467 - mae: 1.7118 - val_loss: 14.4094 - val_mae: 2.7384\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5643 - mae: 1.7222 - val_loss: 14.4610 - val_mae: 2.7449\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.4337 - mae: 1.7025 - val_loss: 14.3675 - val_mae: 2.7438\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4788 - mae: 1.7180 - val_loss: 14.4355 - val_mae: 2.7540\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4701 - mae: 1.7155 - val_loss: 14.4193 - val_mae: 2.7245\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4545 - mae: 1.7040 - val_loss: 14.3473 - val_mae: 2.7086\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3402 - mae: 1.6996 - val_loss: 14.7018 - val_mae: 2.8099\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3562 - mae: 1.7117 - val_loss: 14.4048 - val_mae: 2.7275\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3375 - mae: 1.6896 - val_loss: 14.4156 - val_mae: 2.7403\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2353 - mae: 1.6704 - val_loss: 14.5543 - val_mae: 2.7778\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3061 - mae: 1.7054 - val_loss: 14.6193 - val_mae: 2.7788\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2350 - mae: 1.6856 - val_loss: 14.4813 - val_mae: 2.7854\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1782 - mae: 1.6675 - val_loss: 14.5311 - val_mae: 2.7450\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2257 - mae: 1.6805 - val_loss: 14.4985 - val_mae: 2.7383\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1164 - mae: 1.6675 - val_loss: 14.5966 - val_mae: 2.7510\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2165 - mae: 1.6817 - val_loss: 14.6201 - val_mae: 2.7823\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0892 - mae: 1.6616 - val_loss: 14.4862 - val_mae: 2.7214\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1009 - mae: 1.6597 - val_loss: 14.4599 - val_mae: 2.7418\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0473 - mae: 1.6555 - val_loss: 14.5911 - val_mae: 2.7708\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9898 - mae: 1.6527 - val_loss: 14.6180 - val_mae: 2.7492\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9968 - mae: 1.6462 - val_loss: 14.5114 - val_mae: 2.7555\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9392 - mae: 1.6332 - val_loss: 14.5969 - val_mae: 2.7560\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9314 - mae: 1.6381 - val_loss: 14.5314 - val_mae: 2.7445\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8970 - mae: 1.6264 - val_loss: 14.5805 - val_mae: 2.7747\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9315 - mae: 1.6243 - val_loss: 14.4421 - val_mae: 2.7501\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8545 - mae: 1.6244 - val_loss: 14.5621 - val_mae: 2.7817\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8348 - mae: 1.6246 - val_loss: 14.6972 - val_mae: 2.7873\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7879 - mae: 1.6188 - val_loss: 14.6801 - val_mae: 2.7740\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7835 - mae: 1.6045 - val_loss: 14.5706 - val_mae: 2.7691\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7389 - mae: 1.5988 - val_loss: 14.4813 - val_mae: 2.7161\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8167 - mae: 1.6089 - val_loss: 14.4040 - val_mae: 2.7580\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6917 - mae: 1.5902 - val_loss: 14.4453 - val_mae: 2.7426\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7071 - mae: 1.6050 - val_loss: 14.5672 - val_mae: 2.7331\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7343 - mae: 1.6101 - val_loss: 14.7094 - val_mae: 2.7711\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7410 - mae: 1.5959 - val_loss: 14.7246 - val_mae: 2.7949\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7776 - mae: 1.6194 - val_loss: 14.8845 - val_mae: 2.7647\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6055 - mae: 1.5831 - val_loss: 14.5595 - val_mae: 2.7361\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6265 - mae: 1.5784 - val_loss: 14.6362 - val_mae: 2.7627\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5950 - mae: 1.5809 - val_loss: 14.4678 - val_mae: 2.7301\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.6559 - mae: 1.5753 - val_loss: 14.4882 - val_mae: 2.7558\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5688 - mae: 1.5956 - val_loss: 14.8948 - val_mae: 2.7494\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5918 - mae: 1.5728 - val_loss: 14.5803 - val_mae: 2.7588\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5196 - mae: 1.5642 - val_loss: 14.8771 - val_mae: 2.7949\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4856 - mae: 1.5748 - val_loss: 14.5867 - val_mae: 2.7500\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4507 - mae: 1.5449 - val_loss: 14.5358 - val_mae: 2.7406\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3903 - mae: 1.5303 - val_loss: 14.7963 - val_mae: 2.7911\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5189 - mae: 1.5741 - val_loss: 14.9512 - val_mae: 2.7945\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3467 - mae: 1.5261 - val_loss: 14.7066 - val_mae: 2.7705\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3927 - mae: 1.5398 - val_loss: 14.7905 - val_mae: 2.7741\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3457 - mae: 1.5479 - val_loss: 14.8198 - val_mae: 2.7738\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3384 - mae: 1.5330 - val_loss: 14.6573 - val_mae: 2.7712\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2701 - mae: 1.5023 - val_loss: 14.4398 - val_mae: 2.7238\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3511 - mae: 1.5478 - val_loss: 14.6618 - val_mae: 2.7351\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2778 - mae: 1.5218 - val_loss: 14.8023 - val_mae: 2.7905\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3258 - mae: 1.5245 - val_loss: 14.8034 - val_mae: 2.7876\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2059 - mae: 1.5055 - val_loss: 14.7180 - val_mae: 2.7505\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1748 - mae: 1.5072 - val_loss: 14.6678 - val_mae: 2.7447\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.2355 - mae: 1.5168 - val_loss: 14.7463 - val_mae: 2.7602\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2127 - mae: 1.5123 - val_loss: 14.4258 - val_mae: 2.7102\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1132 - mae: 1.4915 - val_loss: 14.8756 - val_mae: 2.8198\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1940 - mae: 1.5058 - val_loss: 14.8537 - val_mae: 2.7917\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1227 - mae: 1.4976 - val_loss: 14.7484 - val_mae: 2.7743\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0906 - mae: 1.4837 - val_loss: 14.7140 - val_mae: 2.7518\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0731 - mae: 1.4802 - val_loss: 14.9665 - val_mae: 2.7923\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0465 - mae: 1.4819 - val_loss: 14.7627 - val_mae: 2.7627\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0698 - mae: 1.4705 - val_loss: 14.7289 - val_mae: 2.7581\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9792 - mae: 1.4674 - val_loss: 14.8590 - val_mae: 2.7753\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0149 - mae: 1.4654 - val_loss: 14.5484 - val_mae: 2.7349\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9765 - mae: 1.4673 - val_loss: 14.7552 - val_mae: 2.7675\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9582 - mae: 1.4540 - val_loss: 14.5329 - val_mae: 2.7295\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9627 - mae: 1.4583 - val_loss: 14.7482 - val_mae: 2.7445\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9180 - mae: 1.4510 - val_loss: 14.6176 - val_mae: 2.7324\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9259 - mae: 1.4347 - val_loss: 14.5125 - val_mae: 2.7327\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8741 - mae: 1.4397 - val_loss: 14.6191 - val_mae: 2.7473\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8732 - mae: 1.4389 - val_loss: 14.7000 - val_mae: 2.7530\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8447 - mae: 1.4284 - val_loss: 14.5820 - val_mae: 2.7404\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8748 - mae: 1.4318 - val_loss: 14.4958 - val_mae: 2.7151\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7942 - mae: 1.4263 - val_loss: 14.7542 - val_mae: 2.7309\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9014 - mae: 1.4298 - val_loss: 14.6153 - val_mae: 2.7151\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8853 - mae: 1.4442 - val_loss: 14.8701 - val_mae: 2.7608\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8902 - mae: 1.4358 - val_loss: 14.3700 - val_mae: 2.6938\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7773 - mae: 1.4182 - val_loss: 14.8589 - val_mae: 2.7786\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7381 - mae: 1.4290 - val_loss: 14.6839 - val_mae: 2.7478\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7047 - mae: 1.3933 - val_loss: 14.7402 - val_mae: 2.7577\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7414 - mae: 1.4083 - val_loss: 14.6950 - val_mae: 2.7358\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6953 - mae: 1.3977 - val_loss: 14.6301 - val_mae: 2.7470\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6752 - mae: 1.3934 - val_loss: 14.6013 - val_mae: 2.7448\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6374 - mae: 1.3876 - val_loss: 14.5431 - val_mae: 2.7126\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.6364 - mae: 1.3821 - val_loss: 14.7482 - val_mae: 2.7648\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6169 - mae: 1.3781 - val_loss: 14.7112 - val_mae: 2.7548\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6359 - mae: 1.3984 - val_loss: 14.6696 - val_mae: 2.7485\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5794 - mae: 1.3714 - val_loss: 14.7813 - val_mae: 2.7605\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5567 - mae: 1.3625 - val_loss: 14.5466 - val_mae: 2.7141\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6329 - mae: 1.3965 - val_loss: 14.6201 - val_mae: 2.7182\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5558 - mae: 1.3796 - val_loss: 14.8267 - val_mae: 2.7651\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5377 - mae: 1.3621 - val_loss: 14.7575 - val_mae: 2.7429\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4994 - mae: 1.3619 - val_loss: 14.7749 - val_mae: 2.7392\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5907 - mae: 1.3636 - val_loss: 14.7206 - val_mae: 2.7333\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5465 - mae: 1.3797 - val_loss: 14.8012 - val_mae: 2.7406\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4963 - mae: 1.3471 - val_loss: 14.7951 - val_mae: 2.7638\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4190 - mae: 1.3435 - val_loss: 14.9339 - val_mae: 2.7494\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4726 - mae: 1.3743 - val_loss: 14.7640 - val_mae: 2.7517\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5482 - mae: 1.3566 - val_loss: 14.7206 - val_mae: 2.7313\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4256 - mae: 1.3595 - val_loss: 14.7095 - val_mae: 2.7115\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4378 - mae: 1.3565 - val_loss: 14.7029 - val_mae: 2.7496\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.4211 - mae: 1.3425 - val_loss: 14.6941 - val_mae: 2.7408\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4720 - mae: 1.3693 - val_loss: 14.6544 - val_mae: 2.7191\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.4366 - mae: 1.3440 - val_loss: 15.0325 - val_mae: 2.7782\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3927 - mae: 1.3434 - val_loss: 14.4475 - val_mae: 2.6710\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3466 - mae: 1.3240 - val_loss: 14.5679 - val_mae: 2.7099\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3351 - mae: 1.3217 - val_loss: 14.6589 - val_mae: 2.7139\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2966 - mae: 1.3272 - val_loss: 14.6399 - val_mae: 2.7240\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3132 - mae: 1.3178 - val_loss: 14.6624 - val_mae: 2.7227\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2726 - mae: 1.3055 - val_loss: 14.5966 - val_mae: 2.7103\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2633 - mae: 1.3096 - val_loss: 14.6028 - val_mae: 2.7237\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2458 - mae: 1.3131 - val_loss: 14.7984 - val_mae: 2.7444\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2674 - mae: 1.3009 - val_loss: 14.5944 - val_mae: 2.7162\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2704 - mae: 1.3223 - val_loss: 14.8644 - val_mae: 2.7512\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2928 - mae: 1.3006 - val_loss: 14.6242 - val_mae: 2.7201\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2703 - mae: 1.3221 - val_loss: 14.7814 - val_mae: 2.7250\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2333 - mae: 1.3002 - val_loss: 14.7052 - val_mae: 2.7314\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2056 - mae: 1.2937 - val_loss: 14.7485 - val_mae: 2.7255\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2327 - mae: 1.3165 - val_loss: 14.6478 - val_mae: 2.7149\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1482 - mae: 1.2816 - val_loss: 15.0850 - val_mae: 2.7847\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1990 - mae: 1.2940 - val_loss: 14.8255 - val_mae: 2.7337\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3302 - mae: 1.3515 - val_loss: 14.8927 - val_mae: 2.7504\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3021 - mae: 1.3146 - val_loss: 14.4248 - val_mae: 2.6852\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1454 - mae: 1.2818 - val_loss: 14.8510 - val_mae: 2.7459\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1291 - mae: 1.2778 - val_loss: 14.6347 - val_mae: 2.7109\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1232 - mae: 1.2856 - val_loss: 14.5006 - val_mae: 2.6880\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0447 - mae: 1.2637 - val_loss: 14.7631 - val_mae: 2.7458\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5911251.5000 - mae: 2407.7266\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 16ms/step - loss: 500.4270 - mae: 20.5298 - val_loss: 579.7804 - val_mae: 22.1715\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 466.9833 - mae: 19.7265 - val_loss: 536.4510 - val_mae: 21.2346\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 428.1063 - mae: 18.7409 - val_loss: 487.0930 - val_mae: 20.1124\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 382.3907 - mae: 17.5575 - val_loss: 429.5479 - val_mae: 18.7332\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 332.7922 - mae: 16.1586 - val_loss: 362.3834 - val_mae: 16.9928\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 275.4027 - mae: 14.4166 - val_loss: 291.2537 - val_mae: 14.9250\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 218.3482 - mae: 12.5193 - val_loss: 222.2287 - val_mae: 12.6089\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 163.7471 - mae: 10.4641 - val_loss: 165.2378 - val_mae: 10.3421\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 120.6489 - mae: 8.6654 - val_loss: 121.5597 - val_mae: 8.3640\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 90.1577 - mae: 7.3328 - val_loss: 95.6598 - val_mae: 7.2485\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 70.3940 - mae: 6.3954 - val_loss: 80.8008 - val_mae: 6.5688\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 57.8412 - mae: 5.7579 - val_loss: 68.6228 - val_mae: 6.0009\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 47.8964 - mae: 5.1799 - val_loss: 58.9870 - val_mae: 5.4673\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 39.7318 - mae: 4.6804 - val_loss: 51.5568 - val_mae: 4.9860\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 34.2328 - mae: 4.3160 - val_loss: 45.7123 - val_mae: 4.5730\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29.7463 - mae: 4.0328 - val_loss: 41.6795 - val_mae: 4.3012\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.9943 - mae: 3.8414 - val_loss: 38.8507 - val_mae: 4.0853\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 24.7593 - mae: 3.6851 - val_loss: 36.7581 - val_mae: 3.9330\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.3338 - mae: 3.5813 - val_loss: 34.9487 - val_mae: 3.8143\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.1554 - mae: 3.4955 - val_loss: 33.5806 - val_mae: 3.7157\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 21.1680 - mae: 3.4170 - val_loss: 32.2788 - val_mae: 3.6343\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.4850 - mae: 3.3631 - val_loss: 31.1352 - val_mae: 3.5708\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 19.6747 - mae: 3.2966 - val_loss: 30.3736 - val_mae: 3.5043\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 19.0828 - mae: 3.2447 - val_loss: 29.5305 - val_mae: 3.4428\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.4288 - mae: 3.1815 - val_loss: 28.9324 - val_mae: 3.3879\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.9145 - mae: 3.1280 - val_loss: 28.2349 - val_mae: 3.3497\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.4186 - mae: 3.0792 - val_loss: 27.7556 - val_mae: 3.3092\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.0556 - mae: 3.0504 - val_loss: 26.9507 - val_mae: 3.2699\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.5178 - mae: 3.0049 - val_loss: 26.4864 - val_mae: 3.2258\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.1627 - mae: 2.9513 - val_loss: 26.2661 - val_mae: 3.1858\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.6915 - mae: 2.8959 - val_loss: 25.8149 - val_mae: 3.1718\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.3072 - mae: 2.8714 - val_loss: 25.2691 - val_mae: 3.1361\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.8587 - mae: 2.8385 - val_loss: 24.6561 - val_mae: 3.0968\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.6542 - mae: 2.8261 - val_loss: 24.4126 - val_mae: 3.0599\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.3111 - mae: 2.7816 - val_loss: 24.1037 - val_mae: 3.0669\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.0009 - mae: 2.7456 - val_loss: 23.9591 - val_mae: 3.0418\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.7437 - mae: 2.7066 - val_loss: 23.7808 - val_mae: 3.0444\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5295 - mae: 2.7017 - val_loss: 23.2889 - val_mae: 2.9973\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.2640 - mae: 2.6769 - val_loss: 23.1783 - val_mae: 3.0049\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.0413 - mae: 2.6440 - val_loss: 22.9729 - val_mae: 2.9744\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.8144 - mae: 2.6155 - val_loss: 22.7864 - val_mae: 2.9829\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.6140 - mae: 2.5966 - val_loss: 22.5592 - val_mae: 2.9753\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4531 - mae: 2.5810 - val_loss: 22.3614 - val_mae: 2.9308\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.2520 - mae: 2.5674 - val_loss: 22.1702 - val_mae: 2.9360\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0707 - mae: 2.5560 - val_loss: 22.1348 - val_mae: 2.9650\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.9165 - mae: 2.5303 - val_loss: 22.0119 - val_mae: 2.9511\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7547 - mae: 2.4993 - val_loss: 21.7768 - val_mae: 2.8870\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.6511 - mae: 2.4905 - val_loss: 21.6013 - val_mae: 2.8865\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4843 - mae: 2.4871 - val_loss: 21.4433 - val_mae: 2.8912\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3693 - mae: 2.4780 - val_loss: 21.4424 - val_mae: 2.9007\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2159 - mae: 2.4391 - val_loss: 21.4870 - val_mae: 2.9154\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1601 - mae: 2.4153 - val_loss: 21.4270 - val_mae: 2.9091\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0289 - mae: 2.4195 - val_loss: 21.1522 - val_mae: 2.8832\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9375 - mae: 2.4296 - val_loss: 21.1002 - val_mae: 2.8459\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8284 - mae: 2.4000 - val_loss: 21.0985 - val_mae: 2.8743\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6882 - mae: 2.3732 - val_loss: 21.0258 - val_mae: 2.8834\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5736 - mae: 2.3703 - val_loss: 20.8712 - val_mae: 2.8547\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5577 - mae: 2.3686 - val_loss: 20.7270 - val_mae: 2.8106\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3472 - mae: 2.3395 - val_loss: 20.7028 - val_mae: 2.8597\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.2982 - mae: 2.3383 - val_loss: 20.6240 - val_mae: 2.8548\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1697 - mae: 2.3310 - val_loss: 20.5960 - val_mae: 2.8363\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1579 - mae: 2.3355 - val_loss: 20.5251 - val_mae: 2.8123\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0173 - mae: 2.3096 - val_loss: 20.5684 - val_mae: 2.8414\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0647 - mae: 2.2960 - val_loss: 20.6704 - val_mae: 2.8771\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9112 - mae: 2.2853 - val_loss: 20.4500 - val_mae: 2.8228\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8273 - mae: 2.2935 - val_loss: 20.3396 - val_mae: 2.7844\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8012 - mae: 2.2642 - val_loss: 20.3046 - val_mae: 2.8049\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6924 - mae: 2.2388 - val_loss: 20.3592 - val_mae: 2.8374\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6892 - mae: 2.2581 - val_loss: 20.1715 - val_mae: 2.8123\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5393 - mae: 2.2520 - val_loss: 20.1275 - val_mae: 2.7946\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5429 - mae: 2.2268 - val_loss: 20.1774 - val_mae: 2.7796\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4950 - mae: 2.1940 - val_loss: 20.2179 - val_mae: 2.7972\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3430 - mae: 2.1992 - val_loss: 20.0350 - val_mae: 2.7701\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3069 - mae: 2.2243 - val_loss: 19.9844 - val_mae: 2.7764\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2400 - mae: 2.2057 - val_loss: 20.0165 - val_mae: 2.8034\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1753 - mae: 2.1893 - val_loss: 19.9382 - val_mae: 2.7842\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1547 - mae: 2.1839 - val_loss: 19.9370 - val_mae: 2.7653\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.0490 - mae: 2.1560 - val_loss: 20.0230 - val_mae: 2.7880\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9853 - mae: 2.1505 - val_loss: 19.9846 - val_mae: 2.7857\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9341 - mae: 2.1456 - val_loss: 20.0528 - val_mae: 2.8114\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9289 - mae: 2.1573 - val_loss: 19.7459 - val_mae: 2.7716\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9112 - mae: 2.1703 - val_loss: 19.5930 - val_mae: 2.7440\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8104 - mae: 2.1296 - val_loss: 19.7819 - val_mae: 2.7926\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7357 - mae: 2.1058 - val_loss: 19.6866 - val_mae: 2.7788\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6786 - mae: 2.1130 - val_loss: 19.5715 - val_mae: 2.7595\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6604 - mae: 2.1173 - val_loss: 19.4892 - val_mae: 2.7413\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.6641 - mae: 2.0970 - val_loss: 19.4949 - val_mae: 2.7428\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5749 - mae: 2.0683 - val_loss: 19.6055 - val_mae: 2.7755\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5180 - mae: 2.0941 - val_loss: 19.4408 - val_mae: 2.7288\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4305 - mae: 2.0904 - val_loss: 19.5117 - val_mae: 2.7505\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3675 - mae: 2.0636 - val_loss: 19.5586 - val_mae: 2.7709\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3969 - mae: 2.0510 - val_loss: 19.4688 - val_mae: 2.7790\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2996 - mae: 2.0618 - val_loss: 19.2350 - val_mae: 2.7282\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2741 - mae: 2.0445 - val_loss: 19.4002 - val_mae: 2.7471\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2482 - mae: 2.0287 - val_loss: 19.2745 - val_mae: 2.7434\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1048 - mae: 2.0335 - val_loss: 19.0831 - val_mae: 2.7051\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1424 - mae: 2.0334 - val_loss: 19.0120 - val_mae: 2.6956\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1228 - mae: 2.0105 - val_loss: 19.1098 - val_mae: 2.7141\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.9401 - mae: 2.0089 - val_loss: 19.1886 - val_mae: 2.7433\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9544 - mae: 2.0056 - val_loss: 19.1181 - val_mae: 2.7378\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8982 - mae: 1.9872 - val_loss: 19.0113 - val_mae: 2.7246\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8901 - mae: 1.9843 - val_loss: 18.8308 - val_mae: 2.6777\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8236 - mae: 1.9835 - val_loss: 18.7583 - val_mae: 2.6945\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8048 - mae: 1.9769 - val_loss: 18.9265 - val_mae: 2.7354\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7393 - mae: 1.9549 - val_loss: 18.9841 - val_mae: 2.7328\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6778 - mae: 1.9506 - val_loss: 18.6808 - val_mae: 2.6707\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6639 - mae: 1.9542 - val_loss: 18.7450 - val_mae: 2.6798\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5750 - mae: 1.9210 - val_loss: 18.8457 - val_mae: 2.7122\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.6034 - mae: 1.9235 - val_loss: 18.8040 - val_mae: 2.7092\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4904 - mae: 1.9220 - val_loss: 18.6814 - val_mae: 2.6823\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5669 - mae: 1.9556 - val_loss: 18.5513 - val_mae: 2.6781\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3992 - mae: 1.9093 - val_loss: 18.9407 - val_mae: 2.7438\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4696 - mae: 1.9170 - val_loss: 18.8730 - val_mae: 2.7130\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3384 - mae: 1.9080 - val_loss: 18.7644 - val_mae: 2.7184\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3518 - mae: 1.9107 - val_loss: 18.6864 - val_mae: 2.7079\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1981 - mae: 1.8967 - val_loss: 18.4944 - val_mae: 2.6622\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2504 - mae: 1.8915 - val_loss: 18.4782 - val_mae: 2.6801\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2282 - mae: 1.8683 - val_loss: 18.4860 - val_mae: 2.6871\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1629 - mae: 1.8654 - val_loss: 18.5002 - val_mae: 2.7067\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1148 - mae: 1.8754 - val_loss: 18.3221 - val_mae: 2.6611\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0570 - mae: 1.8545 - val_loss: 18.5501 - val_mae: 2.6904\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0274 - mae: 1.8445 - val_loss: 18.4212 - val_mae: 2.6892\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9740 - mae: 1.8463 - val_loss: 18.2831 - val_mae: 2.6695\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9436 - mae: 1.8377 - val_loss: 18.3593 - val_mae: 2.6968\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8817 - mae: 1.8362 - val_loss: 18.3155 - val_mae: 2.6754\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9135 - mae: 1.8446 - val_loss: 18.3500 - val_mae: 2.6625\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8722 - mae: 1.8253 - val_loss: 18.4237 - val_mae: 2.7036\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0193 - mae: 1.8680 - val_loss: 18.2652 - val_mae: 2.6998\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8864 - mae: 1.8448 - val_loss: 18.2299 - val_mae: 2.7065\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7344 - mae: 1.8284 - val_loss: 17.9474 - val_mae: 2.6476\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7227 - mae: 1.8334 - val_loss: 18.0684 - val_mae: 2.6754\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6478 - mae: 1.8060 - val_loss: 18.1551 - val_mae: 2.7083\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5575 - mae: 1.7986 - val_loss: 17.9836 - val_mae: 2.6783\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6144 - mae: 1.8214 - val_loss: 17.9727 - val_mae: 2.6682\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.4873 - mae: 1.7962 - val_loss: 17.9094 - val_mae: 2.6664\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5087 - mae: 1.7817 - val_loss: 17.8439 - val_mae: 2.6460\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5007 - mae: 1.7862 - val_loss: 17.9047 - val_mae: 2.6874\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3875 - mae: 1.7683 - val_loss: 17.7619 - val_mae: 2.6633\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.3754 - mae: 1.7626 - val_loss: 17.6675 - val_mae: 2.6653\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3536 - mae: 1.7639 - val_loss: 17.6792 - val_mae: 2.6747\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3099 - mae: 1.7597 - val_loss: 17.7516 - val_mae: 2.6636\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3073 - mae: 1.7660 - val_loss: 17.5187 - val_mae: 2.6350\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2670 - mae: 1.7624 - val_loss: 17.5981 - val_mae: 2.6574\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1805 - mae: 1.7309 - val_loss: 17.5667 - val_mae: 2.6521\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1798 - mae: 1.7308 - val_loss: 17.4057 - val_mae: 2.6351\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1498 - mae: 1.7347 - val_loss: 17.6374 - val_mae: 2.6731\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1088 - mae: 1.7185 - val_loss: 17.5055 - val_mae: 2.6486\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1661 - mae: 1.7330 - val_loss: 17.5754 - val_mae: 2.6707\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1036 - mae: 1.7180 - val_loss: 17.5107 - val_mae: 2.6423\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0351 - mae: 1.7117 - val_loss: 17.5804 - val_mae: 2.6636\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9746 - mae: 1.7066 - val_loss: 17.4069 - val_mae: 2.6543\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0453 - mae: 1.7271 - val_loss: 17.5278 - val_mae: 2.6875\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9319 - mae: 1.7105 - val_loss: 17.3375 - val_mae: 2.6368\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9044 - mae: 1.6843 - val_loss: 17.3305 - val_mae: 2.6417\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8531 - mae: 1.6844 - val_loss: 17.3371 - val_mae: 2.6502\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8277 - mae: 1.6792 - val_loss: 17.2996 - val_mae: 2.6465\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8369 - mae: 1.6841 - val_loss: 17.4178 - val_mae: 2.6776\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8265 - mae: 1.6682 - val_loss: 17.1617 - val_mae: 2.6205\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7531 - mae: 1.6740 - val_loss: 17.3331 - val_mae: 2.6635\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7247 - mae: 1.6738 - val_loss: 17.3501 - val_mae: 2.6644\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7426 - mae: 1.6673 - val_loss: 17.1584 - val_mae: 2.6350\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7145 - mae: 1.6702 - val_loss: 17.1572 - val_mae: 2.6525\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6188 - mae: 1.6570 - val_loss: 17.0682 - val_mae: 2.6437\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5919 - mae: 1.6424 - val_loss: 17.1663 - val_mae: 2.6558\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6353 - mae: 1.6556 - val_loss: 17.2670 - val_mae: 2.6726\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5721 - mae: 1.6568 - val_loss: 17.1262 - val_mae: 2.6541\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5476 - mae: 1.6375 - val_loss: 17.1454 - val_mae: 2.6519\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5122 - mae: 1.6272 - val_loss: 17.2011 - val_mae: 2.6460\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6086 - mae: 1.6546 - val_loss: 17.1929 - val_mae: 2.6629\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4774 - mae: 1.6202 - val_loss: 17.0163 - val_mae: 2.6282\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4716 - mae: 1.6234 - val_loss: 17.0635 - val_mae: 2.6447\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4309 - mae: 1.6364 - val_loss: 16.9942 - val_mae: 2.6347\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3570 - mae: 1.6204 - val_loss: 17.0211 - val_mae: 2.6457\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3845 - mae: 1.6088 - val_loss: 16.9933 - val_mae: 2.6629\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.3444 - mae: 1.6102 - val_loss: 17.0684 - val_mae: 2.6519\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2930 - mae: 1.6143 - val_loss: 16.8650 - val_mae: 2.6288\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3132 - mae: 1.6041 - val_loss: 16.9003 - val_mae: 2.6518\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3573 - mae: 1.6155 - val_loss: 16.9690 - val_mae: 2.6542\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2014 - mae: 1.5930 - val_loss: 16.8660 - val_mae: 2.6450\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2755 - mae: 1.5916 - val_loss: 16.7339 - val_mae: 2.6183\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1898 - mae: 1.5817 - val_loss: 16.6849 - val_mae: 2.6331\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1677 - mae: 1.5892 - val_loss: 16.7465 - val_mae: 2.6381\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1258 - mae: 1.5817 - val_loss: 16.8912 - val_mae: 2.6608\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1264 - mae: 1.5747 - val_loss: 16.8150 - val_mae: 2.6444\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0944 - mae: 1.5635 - val_loss: 16.6279 - val_mae: 2.6201\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0995 - mae: 1.5640 - val_loss: 16.6031 - val_mae: 2.6317\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0439 - mae: 1.5710 - val_loss: 16.6181 - val_mae: 2.6266\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0036 - mae: 1.5611 - val_loss: 16.6438 - val_mae: 2.6227\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0052 - mae: 1.5552 - val_loss: 16.6906 - val_mae: 2.6478\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0234 - mae: 1.5516 - val_loss: 16.5794 - val_mae: 2.6361\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1032 - mae: 1.5802 - val_loss: 16.5369 - val_mae: 2.6189\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9769 - mae: 1.5501 - val_loss: 16.5865 - val_mae: 2.6331\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9220 - mae: 1.5337 - val_loss: 16.4747 - val_mae: 2.6078\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9334 - mae: 1.5507 - val_loss: 16.4426 - val_mae: 2.6146\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0393 - mae: 1.5624 - val_loss: 16.5379 - val_mae: 2.6525\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8472 - mae: 1.5263 - val_loss: 16.4175 - val_mae: 2.5976\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9119 - mae: 1.5600 - val_loss: 16.4988 - val_mae: 2.6322\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8904 - mae: 1.5579 - val_loss: 16.5133 - val_mae: 2.6603\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8029 - mae: 1.5185 - val_loss: 16.2639 - val_mae: 2.5880\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7895 - mae: 1.5205 - val_loss: 16.2621 - val_mae: 2.6099\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7793 - mae: 1.5133 - val_loss: 16.2631 - val_mae: 2.6107\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7678 - mae: 1.5177 - val_loss: 16.4030 - val_mae: 2.6164\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7556 - mae: 1.5226 - val_loss: 16.3307 - val_mae: 2.6360\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7078 - mae: 1.5020 - val_loss: 16.2696 - val_mae: 2.5982\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.6992 - mae: 1.4947 - val_loss: 16.3969 - val_mae: 2.6346\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8235 - mae: 1.5391 - val_loss: 16.3561 - val_mae: 2.6231\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7392 - mae: 1.5031 - val_loss: 16.2409 - val_mae: 2.5867\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7097 - mae: 1.4849 - val_loss: 16.4567 - val_mae: 2.6546\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6555 - mae: 1.4984 - val_loss: 16.3068 - val_mae: 2.6259\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6162 - mae: 1.4932 - val_loss: 16.2524 - val_mae: 2.5888\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7384 - mae: 1.4900 - val_loss: 16.1092 - val_mae: 2.5957\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6033 - mae: 1.4796 - val_loss: 16.3879 - val_mae: 2.6590\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5753 - mae: 1.4962 - val_loss: 16.1924 - val_mae: 2.6146\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5064 - mae: 1.4778 - val_loss: 16.1303 - val_mae: 2.6096\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.5159 - mae: 1.4621 - val_loss: 16.2427 - val_mae: 2.6362\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4974 - mae: 1.4648 - val_loss: 16.1173 - val_mae: 2.5997\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4680 - mae: 1.4611 - val_loss: 16.1668 - val_mae: 2.6250\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4521 - mae: 1.4490 - val_loss: 16.0317 - val_mae: 2.5994\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4257 - mae: 1.4591 - val_loss: 16.4357 - val_mae: 2.6735\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4477 - mae: 1.4624 - val_loss: 16.2709 - val_mae: 2.6438\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4025 - mae: 1.4541 - val_loss: 15.9245 - val_mae: 2.6026\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3909 - mae: 1.4749 - val_loss: 16.1282 - val_mae: 2.6464\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3832 - mae: 1.4375 - val_loss: 15.8844 - val_mae: 2.5975\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3329 - mae: 1.4304 - val_loss: 15.9258 - val_mae: 2.6142\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2786 - mae: 1.4308 - val_loss: 15.9977 - val_mae: 2.6289\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2778 - mae: 1.4357 - val_loss: 16.0282 - val_mae: 2.6366\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.2610 - mae: 1.4248 - val_loss: 15.8787 - val_mae: 2.6023\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.3524 - mae: 1.4587 - val_loss: 15.9030 - val_mae: 2.6209\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2584 - mae: 1.4485 - val_loss: 16.1464 - val_mae: 2.6765\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2693 - mae: 1.4370 - val_loss: 15.8886 - val_mae: 2.6095\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2283 - mae: 1.4303 - val_loss: 15.8199 - val_mae: 2.6131\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.2636 - mae: 1.4287 - val_loss: 15.7737 - val_mae: 2.6178\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1773 - mae: 1.4225 - val_loss: 15.8507 - val_mae: 2.6283\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1449 - mae: 1.3984 - val_loss: 15.7884 - val_mae: 2.6368\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1213 - mae: 1.4029 - val_loss: 15.6818 - val_mae: 2.6016\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1155 - mae: 1.4152 - val_loss: 15.7133 - val_mae: 2.6239\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0937 - mae: 1.3962 - val_loss: 15.6924 - val_mae: 2.6115\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0818 - mae: 1.3905 - val_loss: 15.7411 - val_mae: 2.6194\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0547 - mae: 1.3996 - val_loss: 15.7090 - val_mae: 2.6299\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0530 - mae: 1.4000 - val_loss: 15.7592 - val_mae: 2.6426\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0174 - mae: 1.3874 - val_loss: 15.5717 - val_mae: 2.6005\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0295 - mae: 1.3797 - val_loss: 15.5454 - val_mae: 2.6137\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0474 - mae: 1.3926 - val_loss: 15.5615 - val_mae: 2.6101\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0245 - mae: 1.3827 - val_loss: 15.6135 - val_mae: 2.6306\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0673 - mae: 1.3995 - val_loss: 15.6729 - val_mae: 2.6357\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1009 - mae: 1.3971 - val_loss: 15.4191 - val_mae: 2.5770\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0410 - mae: 1.3822 - val_loss: 15.6990 - val_mae: 2.6548\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0115 - mae: 1.3926 - val_loss: 15.5416 - val_mae: 2.6187\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9812 - mae: 1.3732 - val_loss: 15.3923 - val_mae: 2.5929\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9786 - mae: 1.3935 - val_loss: 15.7284 - val_mae: 2.6638\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9328 - mae: 1.3760 - val_loss: 15.6694 - val_mae: 2.6360\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8850 - mae: 1.3728 - val_loss: 15.4590 - val_mae: 2.6036\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8566 - mae: 1.3530 - val_loss: 15.5688 - val_mae: 2.6485\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9039 - mae: 1.3487 - val_loss: 15.4495 - val_mae: 2.6198\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8295 - mae: 1.3417 - val_loss: 15.2550 - val_mae: 2.5861\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0342 - mae: 1.4195 - val_loss: 15.4383 - val_mae: 2.6313\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9009 - mae: 1.3690 - val_loss: 15.2456 - val_mae: 2.5756\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9053 - mae: 1.3762 - val_loss: 15.7666 - val_mae: 2.6920\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8253 - mae: 1.3720 - val_loss: 15.3345 - val_mae: 2.6048\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8128 - mae: 1.3602 - val_loss: 15.3079 - val_mae: 2.6190\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7764 - mae: 1.3398 - val_loss: 15.4513 - val_mae: 2.6410\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7249 - mae: 1.3503 - val_loss: 15.3137 - val_mae: 2.6107\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7559 - mae: 1.3628 - val_loss: 15.1387 - val_mae: 2.6122\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7446 - mae: 1.3390 - val_loss: 15.2529 - val_mae: 2.6248\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7354 - mae: 1.3626 - val_loss: 15.6974 - val_mae: 2.6786\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6793 - mae: 1.3446 - val_loss: 15.3974 - val_mae: 2.6396\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7714 - mae: 1.3429 - val_loss: 15.2151 - val_mae: 2.6175\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6380 - mae: 1.3246 - val_loss: 15.2593 - val_mae: 2.6357\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6926 - mae: 1.3269 - val_loss: 15.0269 - val_mae: 2.6061\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5929 - mae: 1.3155 - val_loss: 15.1993 - val_mae: 2.6350\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6077 - mae: 1.3210 - val_loss: 15.0680 - val_mae: 2.6265\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5781 - mae: 1.3103 - val_loss: 15.1142 - val_mae: 2.6356\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5600 - mae: 1.3184 - val_loss: 14.9341 - val_mae: 2.6045\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5627 - mae: 1.3150 - val_loss: 14.8421 - val_mae: 2.5996\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5822 - mae: 1.2977 - val_loss: 15.0190 - val_mae: 2.6244\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5261 - mae: 1.3005 - val_loss: 15.0507 - val_mae: 2.6177\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5408 - mae: 1.3148 - val_loss: 14.9538 - val_mae: 2.6192\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4890 - mae: 1.2854 - val_loss: 14.9573 - val_mae: 2.6146\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4904 - mae: 1.2846 - val_loss: 15.0904 - val_mae: 2.6364\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4512 - mae: 1.2847 - val_loss: 15.0069 - val_mae: 2.6251\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5018 - mae: 1.3091 - val_loss: 15.1474 - val_mae: 2.6519\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4433 - mae: 1.2811 - val_loss: 14.8387 - val_mae: 2.6013\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4624 - mae: 1.2797 - val_loss: 14.8128 - val_mae: 2.5969\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4391 - mae: 1.2832 - val_loss: 14.9159 - val_mae: 2.6138\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4269 - mae: 1.2695 - val_loss: 14.7474 - val_mae: 2.5950\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3858 - mae: 1.2720 - val_loss: 14.9422 - val_mae: 2.6320\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4811 - mae: 1.3228 - val_loss: 15.0482 - val_mae: 2.6524\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5393 - mae: 1.3028 - val_loss: 14.7717 - val_mae: 2.5972\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4119 - mae: 1.2743 - val_loss: 14.8816 - val_mae: 2.6366\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3643 - mae: 1.2701 - val_loss: 14.6403 - val_mae: 2.6010\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3344 - mae: 1.2614 - val_loss: 14.6235 - val_mae: 2.5875\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3607 - mae: 1.2681 - val_loss: 14.8450 - val_mae: 2.6314\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3236 - mae: 1.2641 - val_loss: 14.8570 - val_mae: 2.6267\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3959 - mae: 1.2575 - val_loss: 14.6540 - val_mae: 2.6209\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3895 - mae: 1.3157 - val_loss: 14.8065 - val_mae: 2.6340\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3458 - mae: 1.2776 - val_loss: 14.5439 - val_mae: 2.6182\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2305 - mae: 1.2491 - val_loss: 14.5679 - val_mae: 2.6151\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2612 - mae: 1.2675 - val_loss: 14.5043 - val_mae: 2.6200\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2404 - mae: 1.2347 - val_loss: 14.5532 - val_mae: 2.6107\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1937 - mae: 1.2530 - val_loss: 14.6405 - val_mae: 2.6232\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2918964.0000 - mae: 1685.1616\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 19ms/step - loss: 595.5413 - mae: 22.5467 - val_loss: 484.5945 - val_mae: 20.2098\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 564.9948 - mae: 21.8532 - val_loss: 455.8376 - val_mae: 19.4643\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 532.3740 - mae: 21.0943 - val_loss: 424.3880 - val_mae: 18.6190\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 495.2393 - mae: 20.2002 - val_loss: 388.3390 - val_mae: 17.6195\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 452.0070 - mae: 19.1428 - val_loss: 345.0555 - val_mae: 16.3862\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 397.3054 - mae: 17.7768 - val_loss: 295.5580 - val_mae: 14.9775\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 337.9250 - mae: 16.1723 - val_loss: 241.7925 - val_mae: 13.4465\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 272.2044 - mae: 14.2539 - val_loss: 188.1490 - val_mae: 11.7337\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 208.1762 - mae: 12.1116 - val_loss: 138.6278 - val_mae: 9.8755\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 149.2250 - mae: 9.9720 - val_loss: 99.1658 - val_mae: 8.2307\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 106.1797 - mae: 8.0766 - val_loss: 71.9192 - val_mae: 7.0021\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 75.6183 - mae: 6.6047 - val_loss: 56.7094 - val_mae: 6.1154\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 60.8514 - mae: 5.8472 - val_loss: 48.3286 - val_mae: 5.6115\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 51.0967 - mae: 5.2325 - val_loss: 41.3003 - val_mae: 5.1649\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 44.0280 - mae: 4.8034 - val_loss: 35.9173 - val_mae: 4.7995\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 38.9235 - mae: 4.4789 - val_loss: 31.4563 - val_mae: 4.4630\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 34.7692 - mae: 4.1814 - val_loss: 28.1326 - val_mae: 4.1795\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31.8058 - mae: 3.9642 - val_loss: 25.7038 - val_mae: 3.9732\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 29.6648 - mae: 3.7998 - val_loss: 23.9036 - val_mae: 3.7902\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28.1082 - mae: 3.6900 - val_loss: 22.6235 - val_mae: 3.6888\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26.8347 - mae: 3.6063 - val_loss: 21.5965 - val_mae: 3.5848\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25.8377 - mae: 3.5336 - val_loss: 20.9779 - val_mae: 3.5273\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 25.0754 - mae: 3.4807 - val_loss: 20.4146 - val_mae: 3.4663\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.4001 - mae: 3.4279 - val_loss: 19.9317 - val_mae: 3.4104\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 23.8418 - mae: 3.3831 - val_loss: 19.4367 - val_mae: 3.3601\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.1987 - mae: 3.3341 - val_loss: 19.0674 - val_mae: 3.3176\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.6782 - mae: 3.2949 - val_loss: 18.7403 - val_mae: 3.2814\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.2062 - mae: 3.2624 - val_loss: 18.5753 - val_mae: 3.2626\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.6871 - mae: 3.2401 - val_loss: 18.2813 - val_mae: 3.2434\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.2381 - mae: 3.2122 - val_loss: 17.8424 - val_mae: 3.1909\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 20.7628 - mae: 3.1595 - val_loss: 17.3780 - val_mae: 3.1361\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.4582 - mae: 3.1287 - val_loss: 17.1914 - val_mae: 3.1115\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.9807 - mae: 3.0932 - val_loss: 16.8623 - val_mae: 3.0726\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.6519 - mae: 3.0621 - val_loss: 16.6938 - val_mae: 3.0454\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.4439 - mae: 3.0300 - val_loss: 16.4489 - val_mae: 2.9926\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.0743 - mae: 3.0130 - val_loss: 16.6211 - val_mae: 3.0170\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.7343 - mae: 3.0185 - val_loss: 16.8262 - val_mae: 3.0427\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.4281 - mae: 2.9796 - val_loss: 16.3049 - val_mae: 2.9628\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.1556 - mae: 2.9659 - val_loss: 16.3877 - val_mae: 2.9805\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.7302 - mae: 2.9278 - val_loss: 15.9313 - val_mae: 2.9350\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.5746 - mae: 2.8872 - val_loss: 15.5703 - val_mae: 2.8648\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.1812 - mae: 2.8474 - val_loss: 15.6150 - val_mae: 2.8779\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.9822 - mae: 2.8437 - val_loss: 15.7028 - val_mae: 2.8953\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7604 - mae: 2.8463 - val_loss: 15.7245 - val_mae: 2.9000\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.5110 - mae: 2.8210 - val_loss: 15.3732 - val_mae: 2.8506\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.3174 - mae: 2.7912 - val_loss: 15.3462 - val_mae: 2.8369\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.0745 - mae: 2.7729 - val_loss: 15.3483 - val_mae: 2.8388\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.9485 - mae: 2.7516 - val_loss: 15.0911 - val_mae: 2.8066\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.7424 - mae: 2.7281 - val_loss: 15.1114 - val_mae: 2.8325\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.6475 - mae: 2.7417 - val_loss: 15.2249 - val_mae: 2.8533\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.3734 - mae: 2.7127 - val_loss: 14.8675 - val_mae: 2.8123\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.1874 - mae: 2.6825 - val_loss: 14.6636 - val_mae: 2.7858\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.0650 - mae: 2.6660 - val_loss: 14.5209 - val_mae: 2.7702\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.9998 - mae: 2.6637 - val_loss: 14.6198 - val_mae: 2.7866\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.7438 - mae: 2.6444 - val_loss: 14.5899 - val_mae: 2.7858\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.5854 - mae: 2.6363 - val_loss: 14.5412 - val_mae: 2.7871\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.4988 - mae: 2.6324 - val_loss: 14.4190 - val_mae: 2.7835\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.3549 - mae: 2.6162 - val_loss: 14.1796 - val_mae: 2.7529\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.2164 - mae: 2.6003 - val_loss: 14.1326 - val_mae: 2.7426\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.0726 - mae: 2.5903 - val_loss: 14.1788 - val_mae: 2.7606\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.9382 - mae: 2.5860 - val_loss: 14.1933 - val_mae: 2.7667\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8398 - mae: 2.5775 - val_loss: 13.9196 - val_mae: 2.7356\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.7169 - mae: 2.5571 - val_loss: 13.9799 - val_mae: 2.7353\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.5782 - mae: 2.5483 - val_loss: 13.9852 - val_mae: 2.7368\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5021 - mae: 2.5378 - val_loss: 13.8026 - val_mae: 2.7108\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3891 - mae: 2.5200 - val_loss: 13.7794 - val_mae: 2.7083\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3579 - mae: 2.5192 - val_loss: 13.8779 - val_mae: 2.7247\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2011 - mae: 2.5088 - val_loss: 13.8235 - val_mae: 2.7155\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.1392 - mae: 2.5043 - val_loss: 13.7331 - val_mae: 2.7019\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.0018 - mae: 2.4902 - val_loss: 13.7169 - val_mae: 2.6958\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.9981 - mae: 2.4964 - val_loss: 13.7774 - val_mae: 2.7236\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7935 - mae: 2.4819 - val_loss: 13.7174 - val_mae: 2.7147\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7270 - mae: 2.4744 - val_loss: 13.7677 - val_mae: 2.7147\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6440 - mae: 2.4575 - val_loss: 13.6665 - val_mae: 2.7051\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5075 - mae: 2.4543 - val_loss: 13.7464 - val_mae: 2.7254\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.4909 - mae: 2.4498 - val_loss: 13.4866 - val_mae: 2.6965\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3937 - mae: 2.4414 - val_loss: 13.4818 - val_mae: 2.6790\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3144 - mae: 2.4389 - val_loss: 13.5445 - val_mae: 2.6985\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.2173 - mae: 2.4458 - val_loss: 13.5919 - val_mae: 2.7056\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.1148 - mae: 2.4357 - val_loss: 13.5423 - val_mae: 2.7083\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.0538 - mae: 2.4254 - val_loss: 13.3920 - val_mae: 2.6936\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.9474 - mae: 2.4126 - val_loss: 13.2968 - val_mae: 2.6723\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9114 - mae: 2.4125 - val_loss: 13.3654 - val_mae: 2.6681\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.8316 - mae: 2.4060 - val_loss: 13.1689 - val_mae: 2.6528\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7569 - mae: 2.3928 - val_loss: 12.8978 - val_mae: 2.6341\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7160 - mae: 2.3937 - val_loss: 13.0313 - val_mae: 2.6653\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.6053 - mae: 2.3869 - val_loss: 13.0167 - val_mae: 2.6419\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5510 - mae: 2.3735 - val_loss: 12.8710 - val_mae: 2.6152\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4778 - mae: 2.3638 - val_loss: 12.9196 - val_mae: 2.6340\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3695 - mae: 2.3631 - val_loss: 12.8411 - val_mae: 2.6440\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3236 - mae: 2.3598 - val_loss: 12.9385 - val_mae: 2.6410\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2329 - mae: 2.3495 - val_loss: 12.7750 - val_mae: 2.6160\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1932 - mae: 2.3407 - val_loss: 12.5779 - val_mae: 2.5827\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.1129 - mae: 2.3327 - val_loss: 12.7325 - val_mae: 2.6191\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0920 - mae: 2.3436 - val_loss: 12.7838 - val_mae: 2.6332\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.0113 - mae: 2.3225 - val_loss: 12.3957 - val_mae: 2.5773\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9902 - mae: 2.3162 - val_loss: 12.3719 - val_mae: 2.5711\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9414 - mae: 2.3371 - val_loss: 12.8042 - val_mae: 2.6378\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8458 - mae: 2.3230 - val_loss: 12.6019 - val_mae: 2.6052\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7758 - mae: 2.3056 - val_loss: 12.3882 - val_mae: 2.5775\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7617 - mae: 2.3076 - val_loss: 12.5530 - val_mae: 2.5911\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.6567 - mae: 2.3001 - val_loss: 12.4616 - val_mae: 2.5906\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6716 - mae: 2.2970 - val_loss: 12.4008 - val_mae: 2.5879\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5521 - mae: 2.2883 - val_loss: 12.5332 - val_mae: 2.5889\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5332 - mae: 2.2936 - val_loss: 12.4076 - val_mae: 2.5878\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4518 - mae: 2.2838 - val_loss: 12.3837 - val_mae: 2.5840\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.4286 - mae: 2.2760 - val_loss: 12.2480 - val_mae: 2.5747\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3711 - mae: 2.2788 - val_loss: 12.4546 - val_mae: 2.5930\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2845 - mae: 2.2743 - val_loss: 12.4221 - val_mae: 2.5948\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3025 - mae: 2.2732 - val_loss: 12.2238 - val_mae: 2.5679\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2729 - mae: 2.2729 - val_loss: 12.5043 - val_mae: 2.6128\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1518 - mae: 2.2696 - val_loss: 12.2894 - val_mae: 2.5612\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0933 - mae: 2.2522 - val_loss: 12.2235 - val_mae: 2.5672\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1376 - mae: 2.2528 - val_loss: 12.0697 - val_mae: 2.5768\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0467 - mae: 2.2473 - val_loss: 12.2927 - val_mae: 2.5696\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0466 - mae: 2.2438 - val_loss: 12.0797 - val_mae: 2.5440\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1050 - mae: 2.2581 - val_loss: 12.6526 - val_mae: 2.6648\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8765 - mae: 2.2443 - val_loss: 12.1569 - val_mae: 2.5636\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8826 - mae: 2.2336 - val_loss: 12.0549 - val_mae: 2.5241\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8104 - mae: 2.2222 - val_loss: 12.1193 - val_mae: 2.5723\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8477 - mae: 2.2525 - val_loss: 12.9003 - val_mae: 2.6681\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7877 - mae: 2.2455 - val_loss: 12.2859 - val_mae: 2.6015\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7312 - mae: 2.2152 - val_loss: 11.8566 - val_mae: 2.5428\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6393 - mae: 2.2067 - val_loss: 11.9672 - val_mae: 2.5486\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5831 - mae: 2.2109 - val_loss: 11.9869 - val_mae: 2.5422\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5489 - mae: 2.2088 - val_loss: 11.9747 - val_mae: 2.5816\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4406 - mae: 2.1957 - val_loss: 11.9399 - val_mae: 2.5554\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3780 - mae: 2.1878 - val_loss: 11.8918 - val_mae: 2.5382\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4254 - mae: 2.1898 - val_loss: 11.7762 - val_mae: 2.5284\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3001 - mae: 2.1830 - val_loss: 11.9223 - val_mae: 2.5819\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2798 - mae: 2.1785 - val_loss: 11.9069 - val_mae: 2.5700\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2578 - mae: 2.1799 - val_loss: 11.9721 - val_mae: 2.5739\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1669 - mae: 2.1625 - val_loss: 11.7234 - val_mae: 2.5364\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1169 - mae: 2.1620 - val_loss: 11.6756 - val_mae: 2.5225\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0662 - mae: 2.1582 - val_loss: 11.7427 - val_mae: 2.5415\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0109 - mae: 2.1548 - val_loss: 11.8607 - val_mae: 2.5595\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9949 - mae: 2.1552 - val_loss: 11.6635 - val_mae: 2.5203\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9732 - mae: 2.1547 - val_loss: 11.6336 - val_mae: 2.5376\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9539 - mae: 2.1473 - val_loss: 11.5625 - val_mae: 2.5356\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8663 - mae: 2.1427 - val_loss: 11.4672 - val_mae: 2.5119\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7951 - mae: 2.1374 - val_loss: 11.6412 - val_mae: 2.5085\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8395 - mae: 2.1430 - val_loss: 11.6675 - val_mae: 2.5455\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6960 - mae: 2.1281 - val_loss: 11.6093 - val_mae: 2.5162\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7450 - mae: 2.1271 - val_loss: 11.3617 - val_mae: 2.4699\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5958 - mae: 2.1266 - val_loss: 11.8423 - val_mae: 2.5429\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6281 - mae: 2.1227 - val_loss: 11.4257 - val_mae: 2.5229\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5412 - mae: 2.1085 - val_loss: 11.4136 - val_mae: 2.5004\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4874 - mae: 2.1037 - val_loss: 11.3179 - val_mae: 2.4765\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4492 - mae: 2.0911 - val_loss: 11.2407 - val_mae: 2.5008\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5156 - mae: 2.0872 - val_loss: 11.0637 - val_mae: 2.4479\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4206 - mae: 2.0989 - val_loss: 11.6763 - val_mae: 2.5215\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3555 - mae: 2.0975 - val_loss: 11.2940 - val_mae: 2.4956\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2663 - mae: 2.0742 - val_loss: 11.1533 - val_mae: 2.4828\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2233 - mae: 2.0694 - val_loss: 11.2779 - val_mae: 2.4679\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1962 - mae: 2.0753 - val_loss: 11.3193 - val_mae: 2.4773\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.2130 - mae: 2.0861 - val_loss: 11.6259 - val_mae: 2.5199\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0663 - mae: 2.0632 - val_loss: 11.0696 - val_mae: 2.4698\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1028 - mae: 2.0530 - val_loss: 11.0687 - val_mae: 2.4470\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.0566 - mae: 2.0551 - val_loss: 11.2770 - val_mae: 2.4836\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9924 - mae: 2.0519 - val_loss: 11.0471 - val_mae: 2.4680\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9507 - mae: 2.0402 - val_loss: 10.9716 - val_mae: 2.4501\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9347 - mae: 2.0407 - val_loss: 10.9810 - val_mae: 2.4349\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8669 - mae: 2.0300 - val_loss: 11.2239 - val_mae: 2.4745\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9393 - mae: 2.0543 - val_loss: 11.5326 - val_mae: 2.5206\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7903 - mae: 2.0320 - val_loss: 11.1255 - val_mae: 2.4718\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7485 - mae: 2.0200 - val_loss: 11.0196 - val_mae: 2.4607\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7759 - mae: 2.0236 - val_loss: 11.0002 - val_mae: 2.4358\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9060 - mae: 2.0449 - val_loss: 11.5501 - val_mae: 2.5036\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7434 - mae: 2.0290 - val_loss: 10.7270 - val_mae: 2.4514\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6309 - mae: 1.9992 - val_loss: 10.8222 - val_mae: 2.4022\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6212 - mae: 2.0176 - val_loss: 11.3211 - val_mae: 2.4497\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5125 - mae: 1.9997 - val_loss: 11.0046 - val_mae: 2.4500\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5590 - mae: 1.9982 - val_loss: 10.9020 - val_mae: 2.4549\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4676 - mae: 1.9863 - val_loss: 10.8651 - val_mae: 2.4144\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4143 - mae: 1.9805 - val_loss: 11.0789 - val_mae: 2.4414\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4032 - mae: 1.9833 - val_loss: 10.8946 - val_mae: 2.4576\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3990 - mae: 1.9812 - val_loss: 10.9495 - val_mae: 2.4119\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3140 - mae: 1.9780 - val_loss: 11.0577 - val_mae: 2.4402\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3822 - mae: 1.9709 - val_loss: 10.7350 - val_mae: 2.4272\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2585 - mae: 1.9588 - val_loss: 11.0566 - val_mae: 2.4519\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2820 - mae: 1.9752 - val_loss: 11.1961 - val_mae: 2.4471\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1165 - mae: 1.9536 - val_loss: 10.7978 - val_mae: 2.4137\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2954 - mae: 1.9474 - val_loss: 10.7899 - val_mae: 2.3974\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0552 - mae: 1.9379 - val_loss: 11.2060 - val_mae: 2.4654\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1903 - mae: 1.9723 - val_loss: 11.2615 - val_mae: 2.4567\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9674 - mae: 1.9248 - val_loss: 10.9038 - val_mae: 2.4267\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0238 - mae: 1.9264 - val_loss: 10.8344 - val_mae: 2.4159\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9867 - mae: 1.9351 - val_loss: 11.1358 - val_mae: 2.4408\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9109 - mae: 1.9276 - val_loss: 10.7845 - val_mae: 2.3937\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9158 - mae: 1.9162 - val_loss: 10.7482 - val_mae: 2.4150\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8906 - mae: 1.9184 - val_loss: 10.8707 - val_mae: 2.4055\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8291 - mae: 1.9002 - val_loss: 10.7048 - val_mae: 2.3864\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8959 - mae: 1.9207 - val_loss: 11.0740 - val_mae: 2.4353\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6947 - mae: 1.8948 - val_loss: 10.6609 - val_mae: 2.3716\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8112 - mae: 1.8957 - val_loss: 10.7065 - val_mae: 2.3802\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6981 - mae: 1.8957 - val_loss: 11.0447 - val_mae: 2.4431\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6976 - mae: 1.9104 - val_loss: 10.8208 - val_mae: 2.3989\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6356 - mae: 1.8864 - val_loss: 10.6238 - val_mae: 2.3768\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5718 - mae: 1.8838 - val_loss: 10.9113 - val_mae: 2.4086\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5831 - mae: 1.8894 - val_loss: 10.8641 - val_mae: 2.4113\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5268 - mae: 1.8733 - val_loss: 10.7771 - val_mae: 2.4003\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5060 - mae: 1.8593 - val_loss: 10.8841 - val_mae: 2.3815\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4475 - mae: 1.8635 - val_loss: 11.0762 - val_mae: 2.4168\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4227 - mae: 1.8762 - val_loss: 10.8870 - val_mae: 2.4241\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3898 - mae: 1.8538 - val_loss: 10.7285 - val_mae: 2.3823\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3454 - mae: 1.8352 - val_loss: 10.8215 - val_mae: 2.3867\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3893 - mae: 1.8546 - val_loss: 10.7967 - val_mae: 2.3816\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2858 - mae: 1.8366 - val_loss: 10.9125 - val_mae: 2.4272\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2372 - mae: 1.8339 - val_loss: 10.9171 - val_mae: 2.3865\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2088 - mae: 1.8324 - val_loss: 10.7584 - val_mae: 2.3715\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1969 - mae: 1.8246 - val_loss: 10.6503 - val_mae: 2.3858\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2861 - mae: 1.8241 - val_loss: 10.5664 - val_mae: 2.3578\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1342 - mae: 1.8070 - val_loss: 10.6899 - val_mae: 2.3857\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1867 - mae: 1.8415 - val_loss: 10.9674 - val_mae: 2.4006\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0624 - mae: 1.8145 - val_loss: 10.6329 - val_mae: 2.3783\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0791 - mae: 1.7946 - val_loss: 10.6430 - val_mae: 2.3441\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1756 - mae: 1.8391 - val_loss: 11.0903 - val_mae: 2.4185\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0259 - mae: 1.8040 - val_loss: 10.5740 - val_mae: 2.3739\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0180 - mae: 1.7886 - val_loss: 10.8350 - val_mae: 2.3739\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9308 - mae: 1.7851 - val_loss: 10.8186 - val_mae: 2.3900\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9813 - mae: 1.8073 - val_loss: 11.0496 - val_mae: 2.4109\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9306 - mae: 1.7820 - val_loss: 10.5061 - val_mae: 2.3334\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8561 - mae: 1.7670 - val_loss: 11.1154 - val_mae: 2.4160\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8559 - mae: 1.7999 - val_loss: 10.8543 - val_mae: 2.3783\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7764 - mae: 1.7643 - val_loss: 10.6165 - val_mae: 2.3438\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7769 - mae: 1.7608 - val_loss: 11.0798 - val_mae: 2.3948\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7419 - mae: 1.7770 - val_loss: 10.7772 - val_mae: 2.3580\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7217 - mae: 1.7462 - val_loss: 10.7082 - val_mae: 2.3529\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6534 - mae: 1.7465 - val_loss: 10.6553 - val_mae: 2.3724\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6315 - mae: 1.7435 - val_loss: 10.6279 - val_mae: 2.3544\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6192 - mae: 1.7401 - val_loss: 10.6951 - val_mae: 2.3535\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6060 - mae: 1.7266 - val_loss: 10.5959 - val_mae: 2.3504\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5842 - mae: 1.7315 - val_loss: 10.8598 - val_mae: 2.3988\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5730 - mae: 1.7486 - val_loss: 10.9106 - val_mae: 2.3847\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4706 - mae: 1.7232 - val_loss: 10.6387 - val_mae: 2.3454\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5480 - mae: 1.7293 - val_loss: 10.3496 - val_mae: 2.3327\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5026 - mae: 1.7171 - val_loss: 10.9664 - val_mae: 2.3689\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4463 - mae: 1.7325 - val_loss: 10.8063 - val_mae: 2.4059\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3987 - mae: 1.7277 - val_loss: 10.7240 - val_mae: 2.3791\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4198 - mae: 1.7062 - val_loss: 10.5529 - val_mae: 2.3320\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3811 - mae: 1.7072 - val_loss: 10.7078 - val_mae: 2.3755\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3828 - mae: 1.7186 - val_loss: 10.4538 - val_mae: 2.3584\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2910 - mae: 1.6773 - val_loss: 10.5780 - val_mae: 2.3249\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3601 - mae: 1.6804 - val_loss: 10.8120 - val_mae: 2.3683\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3541 - mae: 1.7245 - val_loss: 10.8905 - val_mae: 2.3779\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4540 - mae: 1.6937 - val_loss: 10.3411 - val_mae: 2.3256\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2684 - mae: 1.6931 - val_loss: 11.1221 - val_mae: 2.4150\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2477 - mae: 1.6859 - val_loss: 10.4288 - val_mae: 2.3210\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1250 - mae: 1.6577 - val_loss: 10.8287 - val_mae: 2.3537\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1505 - mae: 1.6761 - val_loss: 10.5721 - val_mae: 2.3567\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0648 - mae: 1.6540 - val_loss: 10.7262 - val_mae: 2.3530\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0240 - mae: 1.6491 - val_loss: 10.6779 - val_mae: 2.3443\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0661 - mae: 1.6611 - val_loss: 10.7091 - val_mae: 2.3678\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.9799 - mae: 1.6308 - val_loss: 10.5280 - val_mae: 2.3333\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9937 - mae: 1.6366 - val_loss: 10.7710 - val_mae: 2.3741\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9377 - mae: 1.6300 - val_loss: 10.6307 - val_mae: 2.3340\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0217 - mae: 1.6399 - val_loss: 10.5755 - val_mae: 2.3512\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9577 - mae: 1.6484 - val_loss: 10.9250 - val_mae: 2.3755\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8912 - mae: 1.6241 - val_loss: 10.6368 - val_mae: 2.3540\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8579 - mae: 1.6183 - val_loss: 10.7208 - val_mae: 2.3536\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8115 - mae: 1.6084 - val_loss: 10.5973 - val_mae: 2.3272\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8359 - mae: 1.6077 - val_loss: 10.6258 - val_mae: 2.3546\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.7734 - mae: 1.6021 - val_loss: 10.8400 - val_mae: 2.3525\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7508 - mae: 1.6072 - val_loss: 10.5768 - val_mae: 2.3421\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7406 - mae: 1.5929 - val_loss: 10.8018 - val_mae: 2.3529\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7200 - mae: 1.6080 - val_loss: 10.8894 - val_mae: 2.3652\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8288 - mae: 1.6253 - val_loss: 10.8528 - val_mae: 2.3661\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8627 - mae: 1.6367 - val_loss: 10.7502 - val_mae: 2.3705\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6494 - mae: 1.5794 - val_loss: 10.9557 - val_mae: 2.3517\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6648 - mae: 1.5825 - val_loss: 10.7178 - val_mae: 2.3496\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5753 - mae: 1.5751 - val_loss: 10.7866 - val_mae: 2.3640\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5703 - mae: 1.5828 - val_loss: 10.8482 - val_mae: 2.3706\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5746 - mae: 1.5868 - val_loss: 11.0143 - val_mae: 2.3698\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6865 - mae: 1.5951 - val_loss: 10.8065 - val_mae: 2.3657\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5013 - mae: 1.5530 - val_loss: 10.9946 - val_mae: 2.3463\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5458 - mae: 1.5727 - val_loss: 10.9446 - val_mae: 2.3800\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4466 - mae: 1.5517 - val_loss: 10.6633 - val_mae: 2.3293\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4627 - mae: 1.5419 - val_loss: 10.9162 - val_mae: 2.3551\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4454 - mae: 1.5472 - val_loss: 10.9735 - val_mae: 2.3679\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4828 - mae: 1.5730 - val_loss: 11.2132 - val_mae: 2.3986\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3750 - mae: 1.5369 - val_loss: 10.8622 - val_mae: 2.3433\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.3990 - mae: 1.5391 - val_loss: 10.8694 - val_mae: 2.3512\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4241 - mae: 1.5456 - val_loss: 10.7271 - val_mae: 2.3490\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3698 - mae: 1.5426 - val_loss: 10.9904 - val_mae: 2.3627\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3569 - mae: 1.5416 - val_loss: 10.8975 - val_mae: 2.3395\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3155 - mae: 1.5407 - val_loss: 11.0009 - val_mae: 2.3759\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2687 - mae: 1.5197 - val_loss: 10.6864 - val_mae: 2.3290\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2541 - mae: 1.5312 - val_loss: 11.3411 - val_mae: 2.4183\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2928 - mae: 1.5347 - val_loss: 10.8974 - val_mae: 2.3555\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2301 - mae: 1.5182 - val_loss: 11.1882 - val_mae: 2.4075\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1718 - mae: 1.5048 - val_loss: 10.8533 - val_mae: 2.3519\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2052 - mae: 1.5110 - val_loss: 10.8638 - val_mae: 2.3723\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1446 - mae: 1.4951 - val_loss: 10.9505 - val_mae: 2.3626\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1309 - mae: 1.5008 - val_loss: 10.9928 - val_mae: 2.3760\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1236 - mae: 1.4853 - val_loss: 10.8817 - val_mae: 2.3500\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2031 - mae: 1.5079 - val_loss: 11.0079 - val_mae: 2.3658\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1167 - mae: 1.4758 - val_loss: 10.7554 - val_mae: 2.3527\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0368 - mae: 1.4825 - val_loss: 11.2800 - val_mae: 2.4132\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0833 - mae: 1.4979 - val_loss: 10.9668 - val_mae: 2.3853\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0527 - mae: 1.4813 - val_loss: 11.0611 - val_mae: 2.3857\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 7247231.5000 - mae: 2661.7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHW322CUOTg6",
        "outputId": "04003371-0e71-46b2-a57f-4ad6e51080ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2407.7265625, 1685.16162109375, 2661.78564453125]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold 사용한 모델 성능평가"
      ],
      "metadata": {
        "id": "lLrLB0s-SOu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list) # 2.02 -> 실제 집값과 2000달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjFZ8x9EOTB-",
        "outputId": "ddcfaee7-8956-4ffe-888b-366fb7163483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2251.5579427083335"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 사용하지 않고 학습한 모델 성능평가"
      ],
      "metadata": {
        "id": "uUcxe4XlSbXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋:80, 테스트셋:20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2, seed=777)"
      ],
      "metadata": {
        "id": "v53GCEGrSinC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (데이터-전체평균)/표준편차\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "# 전처리(X_train, X_test) 둘 다 처리\n",
        "X_train = (X_train-mean)/std\n",
        "X_teat = (X_test-mean)/std\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation = 'relu', input_shape=(13,)))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1)) # activation=linear\n",
        "\n",
        "model.compile(optimizer='adam', loss ='mse', metrics=['mae'])\n",
        "\n",
        "# 검증 데이터셋 사용하지 않고 모두 학습에 사용\n",
        "model.fit(X_train, y_train, epochs=300)\n",
        "\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYqvO-nXSpGf",
        "outputId": "0c830a75-7d75-4f16-896b-2231d5e1d9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 569.0139 - mae: 22.0262\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 530.3778 - mae: 21.1692\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 483.3785 - mae: 20.1162\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 424.5645 - mae: 18.6868\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 350.2896 - mae: 16.6909\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 267.7659 - mae: 14.1529\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 185.1611 - mae: 11.1806\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.0889 - mae: 8.6317\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 87.8118 - mae: 7.0841\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 67.6559 - mae: 6.1936\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 52.8177 - mae: 5.4636\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.9037 - mae: 4.8790\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.9438 - mae: 4.3943\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 31.8004 - mae: 4.1029\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.8890 - mae: 3.8796\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 26.7932 - mae: 3.7168\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 25.4056 - mae: 3.5966\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 24.1887 - mae: 3.5047\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 23.1720 - mae: 3.4183\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 22.3079 - mae: 3.3619\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.6015 - mae: 3.3197\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.9021 - mae: 3.2524\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.3198 - mae: 3.1683\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.7588 - mae: 3.1379\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 19.1075 - mae: 3.1037\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 18.6123 - mae: 3.0596\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 18.1133 - mae: 3.0103\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6581 - mae: 2.9671\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 17.2222 - mae: 2.9273\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 16.7992 - mae: 2.8944\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 16.5051 - mae: 2.8733\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 16.0913 - mae: 2.8344\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 15.7290 - mae: 2.7889\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 15.4189 - mae: 2.7669\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.2332 - mae: 2.7191\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.8331 - mae: 2.6949\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 14.6657 - mae: 2.7015\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 14.3643 - mae: 2.6579\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 14.0955 - mae: 2.6325\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.8678 - mae: 2.6179\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 13.6133 - mae: 2.5954\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.4196 - mae: 2.5774\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 13.2613 - mae: 2.5608\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.0308 - mae: 2.5567\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.8759 - mae: 2.5265\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.7464 - mae: 2.5275\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.5588 - mae: 2.4911\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.3362 - mae: 2.4797\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.3050 - mae: 2.4962\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 12.1293 - mae: 2.4603\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 11.9466 - mae: 2.4507\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.7609 - mae: 2.4377\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 11.6241 - mae: 2.4181\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.5944 - mae: 2.4425\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.4386 - mae: 2.4195\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.3311 - mae: 2.3849\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 11.1789 - mae: 2.3813\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 11.0604 - mae: 2.3866\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.9531 - mae: 2.3665\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.9411 - mae: 2.3459\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.7597 - mae: 2.3560\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.8544 - mae: 2.3508\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.6714 - mae: 2.3421\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.5217 - mae: 2.3293\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.4012 - mae: 2.2910\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.3027 - mae: 2.2972\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.2319 - mae: 2.2890\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 10.1223 - mae: 2.2730\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.0645 - mae: 2.2808\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.9405 - mae: 2.2630\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 9.8596 - mae: 2.2524\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.8712 - mae: 2.2406\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.7949 - mae: 2.2674\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.6469 - mae: 2.2298\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.5969 - mae: 2.2115\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.5719 - mae: 2.2193\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.4589 - mae: 2.2084\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3408 - mae: 2.2002\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3915 - mae: 2.1839\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.2552 - mae: 2.2032\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 9.1925 - mae: 2.1740\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 9.0996 - mae: 2.1690\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9950 - mae: 2.1591\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9224 - mae: 2.1406\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9311 - mae: 2.1514\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.9547 - mae: 2.1333\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9173 - mae: 2.1637\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.6741 - mae: 2.1253\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.6922 - mae: 2.1067\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.6517 - mae: 2.1279\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.5245 - mae: 2.1024\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.4409 - mae: 2.1015\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.3814 - mae: 2.0836\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.3107 - mae: 2.0694\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.2512 - mae: 2.0740\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.2029 - mae: 2.0688\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.1678 - mae: 2.0543\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.1235 - mae: 2.0626\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.0681 - mae: 2.0492\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 8.0000 - mae: 2.0434\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.9424 - mae: 2.0252\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.9025 - mae: 2.0377\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.8766 - mae: 2.0322\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.8197 - mae: 2.0372\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7913 - mae: 2.0086\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7525 - mae: 2.0057\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.8357 - mae: 2.0362\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7632 - mae: 1.9957\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.6160 - mae: 2.0043\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.5386 - mae: 1.9811\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4924 - mae: 1.9765\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4562 - mae: 1.9773\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.4147 - mae: 1.9590\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.4071 - mae: 1.9787\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.3015 - mae: 1.9515\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.2664 - mae: 1.9415\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.2165 - mae: 1.9308\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.3054 - mae: 1.9698\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.1863 - mae: 1.9402\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.1916 - mae: 1.9335\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.1762 - mae: 1.9568\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.0679 - mae: 1.9146\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 7.0170 - mae: 1.9034\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.9414 - mae: 1.8982\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.9113 - mae: 1.8984\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8763 - mae: 1.8961\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8372 - mae: 1.8860\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.7500 - mae: 1.8658\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.7806 - mae: 1.8893\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.7441 - mae: 1.8641\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.7292 - mae: 1.8738\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6487 - mae: 1.8517\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.5824 - mae: 1.8491\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.6124 - mae: 1.8538\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.5326 - mae: 1.8458\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5003 - mae: 1.8351\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4902 - mae: 1.8296\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.4280 - mae: 1.8275\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3910 - mae: 1.8150\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3871 - mae: 1.8216\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3831 - mae: 1.8303\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3824 - mae: 1.8089\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2893 - mae: 1.8126\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3085 - mae: 1.8063\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2682 - mae: 1.8164\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2796 - mae: 1.7866\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.1586 - mae: 1.7930\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.1064 - mae: 1.7812\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.1130 - mae: 1.7836\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2295 - mae: 1.7927\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.0602 - mae: 1.7890\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 6.0328 - mae: 1.7694\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9737 - mae: 1.7630\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.9733 - mae: 1.7731\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.9557 - mae: 1.7568\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9150 - mae: 1.7563\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8552 - mae: 1.7420\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8852 - mae: 1.7402\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.8151 - mae: 1.7484\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8673 - mae: 1.7426\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7654 - mae: 1.7291\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7387 - mae: 1.7264\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7099 - mae: 1.7218\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.6654 - mae: 1.7195\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7266 - mae: 1.7237\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.6545 - mae: 1.7292\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.6458 - mae: 1.7029\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.6700 - mae: 1.7345\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5923 - mae: 1.7158\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5795 - mae: 1.6834\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4749 - mae: 1.6934\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5230 - mae: 1.6900\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5342 - mae: 1.7176\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5668 - mae: 1.6731\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4376 - mae: 1.6865\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4604 - mae: 1.6746\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3596 - mae: 1.6703\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3165 - mae: 1.6612\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3508 - mae: 1.6675\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2489 - mae: 1.6336\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2528 - mae: 1.6620\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2607 - mae: 1.6524\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.1821 - mae: 1.6556\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1620 - mae: 1.6287\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.1163 - mae: 1.6345\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.1278 - mae: 1.6170\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.1020 - mae: 1.6188\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0656 - mae: 1.6172\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0432 - mae: 1.6102\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.0524 - mae: 1.6231\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0100 - mae: 1.5987\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 5.0158 - mae: 1.6112\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.9940 - mae: 1.6162\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9380 - mae: 1.5898\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9067 - mae: 1.5963\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9222 - mae: 1.5905\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8504 - mae: 1.5773\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8738 - mae: 1.5865\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8356 - mae: 1.5834\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9047 - mae: 1.5732\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.7808 - mae: 1.5804\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8360 - mae: 1.5596\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6978 - mae: 1.5650\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6686 - mae: 1.5643\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.7559 - mae: 1.5496\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8582 - mae: 1.5897\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6839 - mae: 1.5485\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.5751 - mae: 1.5352\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6418 - mae: 1.5412\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5654 - mae: 1.5205\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5182 - mae: 1.5127\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4750 - mae: 1.5056\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4853 - mae: 1.5180\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.4878 - mae: 1.5048\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4790 - mae: 1.5243\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4224 - mae: 1.5003\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3881 - mae: 1.4862\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4197 - mae: 1.5035\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4181 - mae: 1.5027\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3412 - mae: 1.4842\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3802 - mae: 1.4886\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2859 - mae: 1.4790\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3360 - mae: 1.4778\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4031 - mae: 1.5105\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4732 - mae: 1.5417\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3735 - mae: 1.4996\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2972 - mae: 1.4746\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1807 - mae: 1.4512\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1948 - mae: 1.4758\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2265 - mae: 1.4789\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2477 - mae: 1.4522\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2626 - mae: 1.4650\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2245 - mae: 1.4979\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 4.1875 - mae: 1.4499\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1022 - mae: 1.4388\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0998 - mae: 1.4436\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1804 - mae: 1.4861\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1748 - mae: 1.4444\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0388 - mae: 1.4534\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0998 - mae: 1.4306\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.9447 - mae: 1.4217\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0549 - mae: 1.4458\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0429 - mae: 1.4426\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.9781 - mae: 1.4100\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0405 - mae: 1.4653\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0237 - mae: 1.4296\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8698 - mae: 1.4012\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.9310 - mae: 1.4102\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 3.8813 - mae: 1.4265\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8655 - mae: 1.3923\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8951 - mae: 1.4169\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8986 - mae: 1.3918\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8991 - mae: 1.4328\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7752 - mae: 1.3866\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 3.7728 - mae: 1.3836\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7493 - mae: 1.3821\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7171 - mae: 1.3696\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7194 - mae: 1.3759\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7187 - mae: 1.3600\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 3.6612 - mae: 1.3765\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7119 - mae: 1.3763\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7358 - mae: 1.3776\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.6505 - mae: 1.3542\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 3.6636 - mae: 1.3608\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.6625 - mae: 1.3478\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.6209 - mae: 1.3396\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5867 - mae: 1.3492\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5678 - mae: 1.3422\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.6415 - mae: 1.3374\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7033 - mae: 1.3925\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5451 - mae: 1.3304\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5295 - mae: 1.3557\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5808 - mae: 1.3581\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5433 - mae: 1.3230\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4619 - mae: 1.3373\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5267 - mae: 1.3444\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5288 - mae: 1.3188\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5364 - mae: 1.3602\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5161 - mae: 1.3514\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4115 - mae: 1.3241\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4414 - mae: 1.3175\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 3.5125 - mae: 1.3289\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4924 - mae: 1.3243\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4132 - mae: 1.3181\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3785 - mae: 1.3225\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3219 - mae: 1.2840\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3805 - mae: 1.3317\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3514 - mae: 1.2932\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3859 - mae: 1.3099\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2645 - mae: 1.2650\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2954 - mae: 1.3093\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2550 - mae: 1.2773\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2853 - mae: 1.2959\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2494 - mae: 1.2758\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1936 - mae: 1.2629\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2459 - mae: 1.2662\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1748 - mae: 1.2716\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3132 - mae: 1.3006\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2729 - mae: 1.3103\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1516 - mae: 1.2729\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3230953.7500 - mae: 1769.3420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3230953.75, 1769.342041015625]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # 1.9 -> 실제 집값과 1900달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG_8iQEmSp73",
        "outputId": "53584e6c-0db8-42ca-9da4-44fdf626e2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 3230953.7500 - mae: 1769.3420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3230953.75, 1769.342041015625]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-Fold, 5-Fold 사용한 모델의 성능 평가"
      ],
      "metadata": {
        "id": "cQMmJtShT2P2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-Fold를 사용한 모델 성능평가"
      ],
      "metadata": {
        "id": "Av8vWdB9T57G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 3-Fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k = 4\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1)) # 연속적인 값 -> linear -> defalut 가 linear 함수임, activation=linear\n",
        "\n",
        "  model.compile(optimizer='adam', loss ='mse', metrics=['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(KFold)의 평가 정보를 담는 리스트 선언\n",
        "mae_list =[]\n",
        "\n",
        "# K번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "\n",
        "  # 학습데이터, 검증데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기\n",
        "  model.fit(X_train_fold, y_train_fold, epochs=300, validation_data=(X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUCJRPuFT-SP",
        "outputId": "b98dc2b5-4250-478e-ee72-379e95909460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 16ms/step - loss: 574.8801 - mae: 22.1091 - val_loss: 535.3705 - val_mae: 21.4002\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 544.0790 - mae: 21.3918 - val_loss: 508.7937 - val_mae: 20.7399\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 510.3687 - mae: 20.5999 - val_loss: 477.7499 - val_mae: 19.9398\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 470.3723 - mae: 19.5940 - val_loss: 438.7965 - val_mae: 18.8972\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 420.5246 - mae: 18.2861 - val_loss: 391.6801 - val_mae: 17.5964\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 361.1061 - mae: 16.6853 - val_loss: 336.6467 - val_mae: 15.9887\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 293.0260 - mae: 14.8120 - val_loss: 276.3563 - val_mae: 14.1960\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 225.8812 - mae: 12.7577 - val_loss: 211.6406 - val_mae: 12.2491\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 160.2530 - mae: 10.4408 - val_loss: 152.4967 - val_mae: 10.2054\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 107.2538 - mae: 8.4004 - val_loss: 108.2094 - val_mae: 8.4007\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 77.8646 - mae: 7.0566 - val_loss: 79.8659 - val_mae: 7.0597\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 61.5174 - mae: 6.2106 - val_loss: 63.4382 - val_mae: 6.1309\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 52.0661 - mae: 5.5978 - val_loss: 53.2951 - val_mae: 5.4419\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 44.9934 - mae: 5.1623 - val_loss: 45.7037 - val_mae: 4.9560\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 38.3401 - mae: 4.7331 - val_loss: 40.0940 - val_mae: 4.5619\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 33.3683 - mae: 4.3354 - val_loss: 35.5612 - val_mae: 4.1741\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 29.7561 - mae: 4.0290 - val_loss: 32.4248 - val_mae: 3.9637\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 26.8686 - mae: 3.7741 - val_loss: 29.7281 - val_mae: 3.7853\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.6629 - mae: 3.5780 - val_loss: 27.9007 - val_mae: 3.6651\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 22.9641 - mae: 3.4001 - val_loss: 26.6252 - val_mae: 3.5842\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 21.7473 - mae: 3.2958 - val_loss: 25.6362 - val_mae: 3.5325\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 20.7121 - mae: 3.1936 - val_loss: 25.0198 - val_mae: 3.4842\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 19.7715 - mae: 3.1051 - val_loss: 24.4039 - val_mae: 3.4442\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.0466 - mae: 3.0386 - val_loss: 23.8713 - val_mae: 3.4210\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 18.3656 - mae: 2.9836 - val_loss: 23.4340 - val_mae: 3.4051\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 17.8980 - mae: 2.9466 - val_loss: 23.0559 - val_mae: 3.4054\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.4256 - mae: 2.9118 - val_loss: 22.6493 - val_mae: 3.3998\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.9993 - mae: 2.8731 - val_loss: 22.5392 - val_mae: 3.4068\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.5965 - mae: 2.8283 - val_loss: 22.3962 - val_mae: 3.4022\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 16.2221 - mae: 2.7956 - val_loss: 22.1657 - val_mae: 3.3873\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 15.9630 - mae: 2.7778 - val_loss: 21.7764 - val_mae: 3.3658\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 15.6430 - mae: 2.7492 - val_loss: 21.5896 - val_mae: 3.3508\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.3261 - mae: 2.7136 - val_loss: 21.4507 - val_mae: 3.3423\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 15.1323 - mae: 2.6971 - val_loss: 21.2272 - val_mae: 3.3289\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.8695 - mae: 2.6698 - val_loss: 21.0214 - val_mae: 3.3113\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.6837 - mae: 2.6487 - val_loss: 20.5689 - val_mae: 3.2911\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.4001 - mae: 2.6320 - val_loss: 20.4949 - val_mae: 3.2775\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.2000 - mae: 2.6112 - val_loss: 20.3178 - val_mae: 3.2711\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.9838 - mae: 2.5937 - val_loss: 20.0625 - val_mae: 3.2490\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.8023 - mae: 2.5771 - val_loss: 19.8296 - val_mae: 3.2335\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.6005 - mae: 2.5422 - val_loss: 19.7972 - val_mae: 3.2228\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.4070 - mae: 2.5227 - val_loss: 19.6486 - val_mae: 3.2157\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.2723 - mae: 2.5169 - val_loss: 19.4343 - val_mae: 3.2060\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.1361 - mae: 2.5164 - val_loss: 19.4422 - val_mae: 3.2040\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.9600 - mae: 2.4897 - val_loss: 19.3691 - val_mae: 3.1967\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.8580 - mae: 2.4790 - val_loss: 19.2432 - val_mae: 3.1798\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.6997 - mae: 2.4693 - val_loss: 19.1612 - val_mae: 3.1778\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.6372 - mae: 2.4808 - val_loss: 18.8098 - val_mae: 3.1552\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.3903 - mae: 2.4605 - val_loss: 18.8483 - val_mae: 3.1453\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.2752 - mae: 2.4487 - val_loss: 18.6160 - val_mae: 3.1362\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.1684 - mae: 2.4446 - val_loss: 18.4710 - val_mae: 3.1245\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.1399 - mae: 2.4366 - val_loss: 18.4087 - val_mae: 3.1050\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.0126 - mae: 2.4327 - val_loss: 18.1523 - val_mae: 3.1029\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.8257 - mae: 2.4132 - val_loss: 18.2199 - val_mae: 3.0867\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.6904 - mae: 2.3977 - val_loss: 17.9895 - val_mae: 3.0759\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.5932 - mae: 2.3974 - val_loss: 17.8773 - val_mae: 3.0681\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.4634 - mae: 2.3832 - val_loss: 18.0210 - val_mae: 3.0680\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.3749 - mae: 2.3733 - val_loss: 17.9094 - val_mae: 3.0609\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.2553 - mae: 2.3555 - val_loss: 17.9768 - val_mae: 3.0573\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.2115 - mae: 2.3524 - val_loss: 17.7523 - val_mae: 3.0485\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.0810 - mae: 2.3433 - val_loss: 17.7294 - val_mae: 3.0403\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.1118 - mae: 2.3488 - val_loss: 17.5007 - val_mae: 3.0338\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.9087 - mae: 2.3247 - val_loss: 17.4517 - val_mae: 3.0114\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.8294 - mae: 2.3154 - val_loss: 17.2743 - val_mae: 2.9984\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.7118 - mae: 2.3045 - val_loss: 17.2093 - val_mae: 2.9963\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6667 - mae: 2.3007 - val_loss: 17.2380 - val_mae: 3.0007\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.6146 - mae: 2.3011 - val_loss: 17.1961 - val_mae: 3.0004\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.5722 - mae: 2.3054 - val_loss: 17.0512 - val_mae: 2.9902\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.3914 - mae: 2.2789 - val_loss: 17.0843 - val_mae: 2.9777\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.3485 - mae: 2.2647 - val_loss: 16.9219 - val_mae: 2.9651\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.2906 - mae: 2.2521 - val_loss: 16.8723 - val_mae: 2.9642\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.3298 - mae: 2.2904 - val_loss: 16.6438 - val_mae: 2.9807\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.1835 - mae: 2.2762 - val_loss: 16.7596 - val_mae: 2.9684\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.1372 - mae: 2.2411 - val_loss: 16.8216 - val_mae: 2.9588\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.0577 - mae: 2.2393 - val_loss: 16.5951 - val_mae: 2.9464\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.9640 - mae: 2.2229 - val_loss: 16.6904 - val_mae: 2.9418\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.8543 - mae: 2.2099 - val_loss: 16.5909 - val_mae: 2.9461\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8087 - mae: 2.2164 - val_loss: 16.4670 - val_mae: 2.9426\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.7779 - mae: 2.2138 - val_loss: 16.3226 - val_mae: 2.9282\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.6967 - mae: 2.2074 - val_loss: 16.4521 - val_mae: 2.9399\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.7208 - mae: 2.2091 - val_loss: 16.4641 - val_mae: 2.9457\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.5878 - mae: 2.1748 - val_loss: 16.3966 - val_mae: 2.9089\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.5760 - mae: 2.1650 - val_loss: 16.3960 - val_mae: 2.9135\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.4936 - mae: 2.1677 - val_loss: 16.2112 - val_mae: 2.9262\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.4690 - mae: 2.1759 - val_loss: 16.1784 - val_mae: 2.9058\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.3778 - mae: 2.1531 - val_loss: 16.3522 - val_mae: 2.9130\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.2876 - mae: 2.1419 - val_loss: 16.1434 - val_mae: 2.8963\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.3217 - mae: 2.1662 - val_loss: 15.9408 - val_mae: 2.8939\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2442 - mae: 2.1425 - val_loss: 16.2084 - val_mae: 2.9061\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1930 - mae: 2.1353 - val_loss: 15.9617 - val_mae: 2.8974\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.1492 - mae: 2.1256 - val_loss: 16.0435 - val_mae: 2.9005\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.9923 - mae: 2.1109 - val_loss: 15.8907 - val_mae: 2.8836\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9490 - mae: 2.1049 - val_loss: 15.9623 - val_mae: 2.9020\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9348 - mae: 2.1092 - val_loss: 15.8709 - val_mae: 2.9008\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.8624 - mae: 2.0973 - val_loss: 16.0813 - val_mae: 2.9076\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.8173 - mae: 2.0843 - val_loss: 15.9299 - val_mae: 2.8999\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7747 - mae: 2.0824 - val_loss: 15.8188 - val_mae: 2.8960\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.7528 - mae: 2.0964 - val_loss: 15.7335 - val_mae: 2.8913\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7140 - mae: 2.0826 - val_loss: 15.6891 - val_mae: 2.8722\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.6335 - mae: 2.0734 - val_loss: 15.8458 - val_mae: 2.8977\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.5484 - mae: 2.0635 - val_loss: 15.7516 - val_mae: 2.8821\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.5172 - mae: 2.0533 - val_loss: 15.7503 - val_mae: 2.8864\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4866 - mae: 2.0526 - val_loss: 15.5662 - val_mae: 2.8781\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.4296 - mae: 2.0473 - val_loss: 15.6105 - val_mae: 2.8736\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.3943 - mae: 2.0260 - val_loss: 15.7529 - val_mae: 2.8826\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.4026 - mae: 2.0499 - val_loss: 15.5246 - val_mae: 2.8822\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.2800 - mae: 2.0321 - val_loss: 15.4922 - val_mae: 2.8570\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2205 - mae: 2.0168 - val_loss: 15.4565 - val_mae: 2.8588\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.2134 - mae: 2.0167 - val_loss: 15.4194 - val_mae: 2.8610\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1766 - mae: 2.0139 - val_loss: 15.5728 - val_mae: 2.8590\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.1362 - mae: 2.0041 - val_loss: 15.2443 - val_mae: 2.8516\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1299 - mae: 2.0080 - val_loss: 15.4372 - val_mae: 2.8679\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.0603 - mae: 2.0062 - val_loss: 15.3406 - val_mae: 2.8564\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.9247 - mae: 1.9840 - val_loss: 15.1759 - val_mae: 2.8487\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9314 - mae: 1.9877 - val_loss: 15.2044 - val_mae: 2.8540\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.8367 - mae: 1.9820 - val_loss: 15.3104 - val_mae: 2.8561\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8219 - mae: 1.9660 - val_loss: 15.2504 - val_mae: 2.8448\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.7454 - mae: 1.9650 - val_loss: 15.1689 - val_mae: 2.8511\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.7187 - mae: 1.9687 - val_loss: 15.0202 - val_mae: 2.8404\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.6439 - mae: 1.9505 - val_loss: 15.1763 - val_mae: 2.8431\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6371 - mae: 1.9444 - val_loss: 15.2001 - val_mae: 2.8421\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.6526 - mae: 1.9634 - val_loss: 14.7993 - val_mae: 2.8276\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.5309 - mae: 1.9437 - val_loss: 14.9029 - val_mae: 2.8270\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5573 - mae: 1.9538 - val_loss: 15.0255 - val_mae: 2.8493\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4925 - mae: 1.9339 - val_loss: 14.8854 - val_mae: 2.8190\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4057 - mae: 1.9241 - val_loss: 14.6872 - val_mae: 2.8201\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3942 - mae: 1.9499 - val_loss: 14.8810 - val_mae: 2.8312\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3907 - mae: 1.9233 - val_loss: 14.5608 - val_mae: 2.7987\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.2665 - mae: 1.9082 - val_loss: 14.8356 - val_mae: 2.8215\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.2421 - mae: 1.9100 - val_loss: 14.8152 - val_mae: 2.8255\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1977 - mae: 1.8939 - val_loss: 14.7079 - val_mae: 2.8171\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.1470 - mae: 1.8993 - val_loss: 14.6228 - val_mae: 2.8102\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1367 - mae: 1.9049 - val_loss: 14.7031 - val_mae: 2.8060\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.1068 - mae: 1.9046 - val_loss: 14.5507 - val_mae: 2.8023\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1410 - mae: 1.8815 - val_loss: 14.7283 - val_mae: 2.8076\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9834 - mae: 1.8811 - val_loss: 14.6065 - val_mae: 2.8214\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9430 - mae: 1.8851 - val_loss: 14.3472 - val_mae: 2.7911\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8653 - mae: 1.8694 - val_loss: 14.5025 - val_mae: 2.7895\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.8512 - mae: 1.8588 - val_loss: 14.5191 - val_mae: 2.8004\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.7952 - mae: 1.8595 - val_loss: 14.4528 - val_mae: 2.8059\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8256 - mae: 1.8714 - val_loss: 14.3482 - val_mae: 2.8103\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7960 - mae: 1.8727 - val_loss: 14.4294 - val_mae: 2.7952\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6983 - mae: 1.8358 - val_loss: 14.2634 - val_mae: 2.7901\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6874 - mae: 1.8417 - val_loss: 14.3573 - val_mae: 2.7996\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6358 - mae: 1.8536 - val_loss: 14.3697 - val_mae: 2.7962\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5980 - mae: 1.8399 - val_loss: 14.3234 - val_mae: 2.8008\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6543 - mae: 1.8255 - val_loss: 14.3948 - val_mae: 2.7945\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.5313 - mae: 1.8129 - val_loss: 14.1664 - val_mae: 2.7860\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5103 - mae: 1.8269 - val_loss: 14.2351 - val_mae: 2.7899\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4870 - mae: 1.8275 - val_loss: 14.2679 - val_mae: 2.7944\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4265 - mae: 1.8177 - val_loss: 14.1740 - val_mae: 2.7866\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4092 - mae: 1.8052 - val_loss: 14.1378 - val_mae: 2.7830\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.3795 - mae: 1.7924 - val_loss: 14.2786 - val_mae: 2.7914\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.3527 - mae: 1.8058 - val_loss: 14.0680 - val_mae: 2.7856\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.3728 - mae: 1.7988 - val_loss: 14.1886 - val_mae: 2.7795\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2345 - mae: 1.7869 - val_loss: 14.1712 - val_mae: 2.7905\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2642 - mae: 1.8170 - val_loss: 14.2633 - val_mae: 2.7968\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2003 - mae: 1.7941 - val_loss: 14.0949 - val_mae: 2.7947\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1940 - mae: 1.7791 - val_loss: 14.1445 - val_mae: 2.8000\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2731 - mae: 1.8142 - val_loss: 14.0012 - val_mae: 2.7946\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0654 - mae: 1.7604 - val_loss: 14.0042 - val_mae: 2.7744\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0971 - mae: 1.7551 - val_loss: 14.0433 - val_mae: 2.7809\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1552 - mae: 1.7976 - val_loss: 14.2311 - val_mae: 2.8009\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1554 - mae: 1.7737 - val_loss: 13.8875 - val_mae: 2.7743\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0514 - mae: 1.7591 - val_loss: 14.0780 - val_mae: 2.7833\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9826 - mae: 1.7605 - val_loss: 13.9460 - val_mae: 2.7817\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9780 - mae: 1.7723 - val_loss: 13.9972 - val_mae: 2.7785\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9166 - mae: 1.7409 - val_loss: 13.8618 - val_mae: 2.7601\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8944 - mae: 1.7351 - val_loss: 13.9523 - val_mae: 2.7665\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8358 - mae: 1.7317 - val_loss: 13.7452 - val_mae: 2.7607\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8969 - mae: 1.7554 - val_loss: 13.8746 - val_mae: 2.7614\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7972 - mae: 1.7397 - val_loss: 13.5115 - val_mae: 2.7505\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7132 - mae: 1.7027 - val_loss: 13.7988 - val_mae: 2.7580\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7440 - mae: 1.7246 - val_loss: 13.6593 - val_mae: 2.7543\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7196 - mae: 1.7202 - val_loss: 13.5541 - val_mae: 2.7480\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7570 - mae: 1.7262 - val_loss: 13.6031 - val_mae: 2.7505\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6114 - mae: 1.7072 - val_loss: 13.9427 - val_mae: 2.7630\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6174 - mae: 1.6963 - val_loss: 13.7597 - val_mae: 2.7593\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5969 - mae: 1.7021 - val_loss: 13.5836 - val_mae: 2.7568\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5389 - mae: 1.6904 - val_loss: 13.7970 - val_mae: 2.7644\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4896 - mae: 1.6803 - val_loss: 13.7065 - val_mae: 2.7431\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5058 - mae: 1.7107 - val_loss: 13.7660 - val_mae: 2.7571\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.5438 - mae: 1.7011 - val_loss: 13.8530 - val_mae: 2.7481\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4137 - mae: 1.6766 - val_loss: 13.4733 - val_mae: 2.7358\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4263 - mae: 1.6840 - val_loss: 13.6821 - val_mae: 2.7416\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3532 - mae: 1.6914 - val_loss: 13.6117 - val_mae: 2.7554\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3374 - mae: 1.6664 - val_loss: 13.5927 - val_mae: 2.7349\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4105 - mae: 1.6952 - val_loss: 13.7847 - val_mae: 2.7447\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5089 - mae: 1.6868 - val_loss: 13.3622 - val_mae: 2.7359\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2555 - mae: 1.6518 - val_loss: 13.6960 - val_mae: 2.7297\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3349 - mae: 1.6489 - val_loss: 13.5109 - val_mae: 2.7296\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.2180 - mae: 1.6497 - val_loss: 13.5953 - val_mae: 2.7424\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1676 - mae: 1.6437 - val_loss: 13.5946 - val_mae: 2.7304\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1435 - mae: 1.6325 - val_loss: 13.3508 - val_mae: 2.7176\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1182 - mae: 1.6295 - val_loss: 13.4907 - val_mae: 2.7181\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1163 - mae: 1.6400 - val_loss: 13.3576 - val_mae: 2.7116\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0779 - mae: 1.6233 - val_loss: 13.4838 - val_mae: 2.7141\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0886 - mae: 1.6262 - val_loss: 13.2893 - val_mae: 2.7170\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.9998 - mae: 1.6191 - val_loss: 13.4991 - val_mae: 2.7286\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.9819 - mae: 1.6146 - val_loss: 13.5681 - val_mae: 2.7247\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9785 - mae: 1.6111 - val_loss: 13.4592 - val_mae: 2.7195\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0888 - mae: 1.6133 - val_loss: 13.5914 - val_mae: 2.7052\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0431 - mae: 1.6284 - val_loss: 13.3129 - val_mae: 2.7107\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.9090 - mae: 1.6039 - val_loss: 13.4802 - val_mae: 2.7143\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.9763 - mae: 1.6196 - val_loss: 13.6456 - val_mae: 2.7198\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.8983 - mae: 1.5962 - val_loss: 13.3254 - val_mae: 2.7220\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.8222 - mae: 1.5806 - val_loss: 13.5114 - val_mae: 2.7052\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.8040 - mae: 1.5829 - val_loss: 13.3758 - val_mae: 2.7077\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7720 - mae: 1.5745 - val_loss: 13.3320 - val_mae: 2.7037\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7941 - mae: 1.5949 - val_loss: 13.2869 - val_mae: 2.7075\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7222 - mae: 1.5725 - val_loss: 13.3418 - val_mae: 2.6976\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7052 - mae: 1.5667 - val_loss: 13.3224 - val_mae: 2.7031\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7101 - mae: 1.5681 - val_loss: 13.3988 - val_mae: 2.7112\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.6396 - mae: 1.5572 - val_loss: 13.2768 - val_mae: 2.6966\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.6595 - mae: 1.5633 - val_loss: 13.2466 - val_mae: 2.7020\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.6400 - mae: 1.5571 - val_loss: 13.4183 - val_mae: 2.7185\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.5952 - mae: 1.5508 - val_loss: 13.5206 - val_mae: 2.7149\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6420 - mae: 1.5791 - val_loss: 13.2652 - val_mae: 2.7076\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.5468 - mae: 1.5460 - val_loss: 13.1537 - val_mae: 2.6846\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5942 - mae: 1.5396 - val_loss: 13.2964 - val_mae: 2.7001\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6134 - mae: 1.5639 - val_loss: 13.1412 - val_mae: 2.6958\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.5288 - mae: 1.5399 - val_loss: 13.3616 - val_mae: 2.7117\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4686 - mae: 1.5323 - val_loss: 13.2758 - val_mae: 2.7076\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4693 - mae: 1.5292 - val_loss: 13.2445 - val_mae: 2.7075\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4156 - mae: 1.5371 - val_loss: 13.3457 - val_mae: 2.7041\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5321 - mae: 1.5365 - val_loss: 13.2254 - val_mae: 2.6884\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4137 - mae: 1.5224 - val_loss: 13.2012 - val_mae: 2.6987\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3701 - mae: 1.5117 - val_loss: 13.1625 - val_mae: 2.6899\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3508 - mae: 1.5115 - val_loss: 13.2871 - val_mae: 2.6964\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3315 - mae: 1.5191 - val_loss: 13.1081 - val_mae: 2.7055\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3201 - mae: 1.5017 - val_loss: 13.1598 - val_mae: 2.6898\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3279 - mae: 1.5021 - val_loss: 13.1440 - val_mae: 2.6912\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3585 - mae: 1.5173 - val_loss: 13.1536 - val_mae: 2.6821\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2547 - mae: 1.4939 - val_loss: 13.2465 - val_mae: 2.6908\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2900 - mae: 1.5099 - val_loss: 13.2552 - val_mae: 2.7076\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2238 - mae: 1.4882 - val_loss: 13.0828 - val_mae: 2.6785\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.2055 - mae: 1.4839 - val_loss: 13.0164 - val_mae: 2.6742\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.1948 - mae: 1.4805 - val_loss: 13.0646 - val_mae: 2.6760\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.1721 - mae: 1.4802 - val_loss: 13.2968 - val_mae: 2.7003\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.1421 - mae: 1.4838 - val_loss: 13.2360 - val_mae: 2.7080\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.1395 - mae: 1.4771 - val_loss: 13.1315 - val_mae: 2.6879\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1792 - mae: 1.4862 - val_loss: 13.2541 - val_mae: 2.6940\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0928 - mae: 1.4641 - val_loss: 13.0475 - val_mae: 2.6693\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0766 - mae: 1.4716 - val_loss: 13.3242 - val_mae: 2.7008\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0647 - mae: 1.4770 - val_loss: 13.1970 - val_mae: 2.6857\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0748 - mae: 1.4572 - val_loss: 13.1165 - val_mae: 2.6708\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0101 - mae: 1.4510 - val_loss: 13.2607 - val_mae: 2.6892\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0230 - mae: 1.4669 - val_loss: 13.0934 - val_mae: 2.6872\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9829 - mae: 1.4428 - val_loss: 13.1297 - val_mae: 2.6761\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.0355 - mae: 1.4603 - val_loss: 13.2131 - val_mae: 2.6841\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9571 - mae: 1.4485 - val_loss: 13.1549 - val_mae: 2.6756\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9677 - mae: 1.4360 - val_loss: 13.0142 - val_mae: 2.6626\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9279 - mae: 1.4473 - val_loss: 13.0949 - val_mae: 2.6687\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9281 - mae: 1.4432 - val_loss: 12.9677 - val_mae: 2.6647\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9233 - mae: 1.4293 - val_loss: 13.1409 - val_mae: 2.6764\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0163 - mae: 1.4656 - val_loss: 12.8496 - val_mae: 2.6637\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8675 - mae: 1.4242 - val_loss: 13.1548 - val_mae: 2.6797\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8942 - mae: 1.4393 - val_loss: 13.0067 - val_mae: 2.6627\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8947 - mae: 1.4465 - val_loss: 12.9918 - val_mae: 2.6690\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8903 - mae: 1.4395 - val_loss: 13.0918 - val_mae: 2.6638\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8457 - mae: 1.4257 - val_loss: 13.2006 - val_mae: 2.6800\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8820 - mae: 1.4369 - val_loss: 12.8996 - val_mae: 2.6485\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.7523 - mae: 1.4053 - val_loss: 12.8598 - val_mae: 2.6546\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8129 - mae: 1.4156 - val_loss: 13.1602 - val_mae: 2.6747\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.8255 - mae: 1.4223 - val_loss: 12.9871 - val_mae: 2.6602\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6961 - mae: 1.4011 - val_loss: 13.0232 - val_mae: 2.6600\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7336 - mae: 1.4055 - val_loss: 12.7013 - val_mae: 2.6368\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6904 - mae: 1.3993 - val_loss: 12.8243 - val_mae: 2.6377\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6993 - mae: 1.3932 - val_loss: 12.9089 - val_mae: 2.6526\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6715 - mae: 1.3910 - val_loss: 12.9262 - val_mae: 2.6528\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.6602 - mae: 1.3888 - val_loss: 12.7872 - val_mae: 2.6343\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7041 - mae: 1.3911 - val_loss: 12.9146 - val_mae: 2.6449\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6686 - mae: 1.3952 - val_loss: 12.8749 - val_mae: 2.6539\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6168 - mae: 1.3788 - val_loss: 13.0076 - val_mae: 2.6569\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6547 - mae: 1.3841 - val_loss: 12.9139 - val_mae: 2.6408\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.6083 - mae: 1.3585 - val_loss: 12.8252 - val_mae: 2.6423\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5649 - mae: 1.3796 - val_loss: 12.9349 - val_mae: 2.6560\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5662 - mae: 1.3708 - val_loss: 12.9156 - val_mae: 2.6433\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5641 - mae: 1.3580 - val_loss: 12.7925 - val_mae: 2.6338\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5750 - mae: 1.3908 - val_loss: 12.9511 - val_mae: 2.6466\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5232 - mae: 1.3571 - val_loss: 12.8092 - val_mae: 2.6345\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5529 - mae: 1.3630 - val_loss: 12.9745 - val_mae: 2.6545\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5313 - mae: 1.3690 - val_loss: 12.8372 - val_mae: 2.6362\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5347 - mae: 1.3586 - val_loss: 12.7961 - val_mae: 2.6367\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5000 - mae: 1.3614 - val_loss: 12.9567 - val_mae: 2.6582\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4918 - mae: 1.3726 - val_loss: 12.8018 - val_mae: 2.6387\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5332 - mae: 1.3542 - val_loss: 12.9002 - val_mae: 2.6430\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4363 - mae: 1.3501 - val_loss: 12.9277 - val_mae: 2.6570\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4026 - mae: 1.3403 - val_loss: 12.7274 - val_mae: 2.6182\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4307 - mae: 1.3370 - val_loss: 12.9214 - val_mae: 2.6343\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4071 - mae: 1.3552 - val_loss: 12.7993 - val_mae: 2.6458\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.4410 - mae: 1.3344 - val_loss: 12.7226 - val_mae: 2.6236\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3780 - mae: 1.3314 - val_loss: 12.8061 - val_mae: 2.6306\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.3767 - mae: 1.3429 - val_loss: 13.0528 - val_mae: 2.6510\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4248 - mae: 1.3255 - val_loss: 12.7944 - val_mae: 2.6421\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3450 - mae: 1.3180 - val_loss: 12.7418 - val_mae: 2.6252\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4444 - mae: 1.3463 - val_loss: 12.6788 - val_mae: 2.6244\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3453 - mae: 1.3365 - val_loss: 12.8199 - val_mae: 2.6343\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3127 - mae: 1.3157 - val_loss: 12.8277 - val_mae: 2.6358\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2628 - mae: 1.3102 - val_loss: 12.7709 - val_mae: 2.6286\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6226562.5000 - mae: 2473.8926\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 566.3295 - mae: 22.0136 - val_loss: 608.6627 - val_mae: 22.6254\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 540.1443 - mae: 21.4343 - val_loss: 577.0900 - val_mae: 21.9776\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 512.4480 - mae: 20.8099 - val_loss: 538.3583 - val_mae: 21.1623\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 475.1642 - mae: 19.9705 - val_loss: 488.5473 - val_mae: 20.0835\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 429.8953 - mae: 18.8840 - val_loss: 426.5075 - val_mae: 18.6523\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 373.1227 - mae: 17.4619 - val_loss: 354.3947 - val_mae: 16.8112\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 307.7324 - mae: 15.6605 - val_loss: 275.2636 - val_mae: 14.4823\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 239.0428 - mae: 13.4721 - val_loss: 199.4012 - val_mae: 11.8977\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 174.5185 - mae: 11.0181 - val_loss: 139.6048 - val_mae: 9.4840\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 125.4068 - mae: 8.9411 - val_loss: 100.3912 - val_mae: 7.6836\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 92.7893 - mae: 7.5331 - val_loss: 78.8139 - val_mae: 6.7773\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 73.7495 - mae: 6.5566 - val_loss: 64.7495 - val_mae: 6.1657\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 58.6327 - mae: 5.7821 - val_loss: 54.0397 - val_mae: 5.6189\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 48.0563 - mae: 5.1812 - val_loss: 46.0283 - val_mae: 5.1109\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 40.5444 - mae: 4.6858 - val_loss: 40.5891 - val_mae: 4.6701\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 35.2505 - mae: 4.3315 - val_loss: 37.0168 - val_mae: 4.3702\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.4245 - mae: 4.0589 - val_loss: 35.0186 - val_mae: 4.1811\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 28.9951 - mae: 3.8617 - val_loss: 33.4248 - val_mae: 4.0616\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 27.2478 - mae: 3.7253 - val_loss: 32.2622 - val_mae: 3.9720\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.8724 - mae: 3.6127 - val_loss: 31.3659 - val_mae: 3.9012\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.8344 - mae: 3.5370 - val_loss: 30.4898 - val_mae: 3.8421\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.8325 - mae: 3.4676 - val_loss: 29.7570 - val_mae: 3.7803\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.0231 - mae: 3.3984 - val_loss: 29.2075 - val_mae: 3.7378\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.3430 - mae: 3.3241 - val_loss: 28.7614 - val_mae: 3.6932\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.6671 - mae: 3.2807 - val_loss: 28.0108 - val_mae: 3.6611\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 21.0518 - mae: 3.2563 - val_loss: 27.3751 - val_mae: 3.6250\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 20.4753 - mae: 3.2189 - val_loss: 26.8569 - val_mae: 3.5924\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 19.9023 - mae: 3.1520 - val_loss: 26.4901 - val_mae: 3.5466\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 19.3669 - mae: 3.0923 - val_loss: 26.0669 - val_mae: 3.5127\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 18.9987 - mae: 3.0722 - val_loss: 25.4391 - val_mae: 3.4774\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 18.3930 - mae: 3.0176 - val_loss: 25.1386 - val_mae: 3.4425\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 17.9354 - mae: 2.9736 - val_loss: 24.7345 - val_mae: 3.4094\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.5687 - mae: 2.9423 - val_loss: 24.3409 - val_mae: 3.3764\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.2225 - mae: 2.9407 - val_loss: 23.8885 - val_mae: 3.3666\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.7840 - mae: 2.9074 - val_loss: 23.5841 - val_mae: 3.3205\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.3540 - mae: 2.8456 - val_loss: 23.3600 - val_mae: 3.2895\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.0272 - mae: 2.8068 - val_loss: 22.9556 - val_mae: 3.2599\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.7234 - mae: 2.7827 - val_loss: 22.6147 - val_mae: 3.2303\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.3451 - mae: 2.7305 - val_loss: 22.4165 - val_mae: 3.2020\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.1104 - mae: 2.7419 - val_loss: 22.0042 - val_mae: 3.1813\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.7473 - mae: 2.7305 - val_loss: 21.7597 - val_mae: 3.1604\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.4259 - mae: 2.6884 - val_loss: 21.5057 - val_mae: 3.1232\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 14.2241 - mae: 2.6690 - val_loss: 21.2574 - val_mae: 3.1019\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.8959 - mae: 2.6261 - val_loss: 21.0003 - val_mae: 3.0680\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.6638 - mae: 2.6022 - val_loss: 20.8419 - val_mae: 3.0477\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.4323 - mae: 2.5812 - val_loss: 20.6270 - val_mae: 3.0210\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.2662 - mae: 2.5696 - val_loss: 20.4372 - val_mae: 3.0004\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.0782 - mae: 2.5410 - val_loss: 20.3504 - val_mae: 2.9762\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.8793 - mae: 2.5263 - val_loss: 20.1261 - val_mae: 2.9567\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.6271 - mae: 2.5166 - val_loss: 19.9491 - val_mae: 2.9318\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.4589 - mae: 2.4841 - val_loss: 19.8887 - val_mae: 2.9104\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.2974 - mae: 2.4747 - val_loss: 19.8490 - val_mae: 2.8994\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.1108 - mae: 2.4595 - val_loss: 19.7319 - val_mae: 2.8775\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.9589 - mae: 2.4417 - val_loss: 19.6504 - val_mae: 2.8644\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.8360 - mae: 2.4306 - val_loss: 19.5668 - val_mae: 2.8467\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.7871 - mae: 2.4408 - val_loss: 19.5787 - val_mae: 2.8330\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 11.5571 - mae: 2.4124 - val_loss: 19.4929 - val_mae: 2.8146\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.4476 - mae: 2.3932 - val_loss: 19.4028 - val_mae: 2.7999\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.2998 - mae: 2.3785 - val_loss: 19.3529 - val_mae: 2.7894\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.2409 - mae: 2.3881 - val_loss: 19.4006 - val_mae: 2.7852\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.0718 - mae: 2.3757 - val_loss: 19.3200 - val_mae: 2.7692\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.0030 - mae: 2.3536 - val_loss: 19.2357 - val_mae: 2.7548\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.9186 - mae: 2.3383 - val_loss: 19.1852 - val_mae: 2.7421\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.8986 - mae: 2.3330 - val_loss: 19.1638 - val_mae: 2.7264\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.7195 - mae: 2.3276 - val_loss: 19.2842 - val_mae: 2.7237\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6401 - mae: 2.3358 - val_loss: 19.2673 - val_mae: 2.7217\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.5215 - mae: 2.3237 - val_loss: 19.1646 - val_mae: 2.7073\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.4608 - mae: 2.3069 - val_loss: 19.1277 - val_mae: 2.6911\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.5578 - mae: 2.3061 - val_loss: 19.1122 - val_mae: 2.6910\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.2590 - mae: 2.2830 - val_loss: 19.2425 - val_mae: 2.6800\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.3665 - mae: 2.3164 - val_loss: 19.2638 - val_mae: 2.6794\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.2107 - mae: 2.2867 - val_loss: 19.1110 - val_mae: 2.6606\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.0979 - mae: 2.2593 - val_loss: 19.1404 - val_mae: 2.6589\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.0199 - mae: 2.2557 - val_loss: 19.0261 - val_mae: 2.6455\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.9342 - mae: 2.2539 - val_loss: 18.9457 - val_mae: 2.6355\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8602 - mae: 2.2447 - val_loss: 18.9558 - val_mae: 2.6243\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.7759 - mae: 2.2360 - val_loss: 19.0195 - val_mae: 2.6260\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.7392 - mae: 2.2352 - val_loss: 19.0166 - val_mae: 2.6203\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.6762 - mae: 2.2259 - val_loss: 18.9469 - val_mae: 2.6115\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6403 - mae: 2.2200 - val_loss: 19.0225 - val_mae: 2.6009\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.5930 - mae: 2.2102 - val_loss: 18.9718 - val_mae: 2.5982\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.5334 - mae: 2.2199 - val_loss: 18.9575 - val_mae: 2.5975\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.6058 - mae: 2.2432 - val_loss: 19.0180 - val_mae: 2.5990\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.4503 - mae: 2.2020 - val_loss: 18.8109 - val_mae: 2.5842\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3727 - mae: 2.1716 - val_loss: 18.7879 - val_mae: 2.5903\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3475 - mae: 2.1829 - val_loss: 18.7672 - val_mae: 2.5792\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.2633 - mae: 2.1951 - val_loss: 18.8769 - val_mae: 2.5642\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.2005 - mae: 2.1840 - val_loss: 18.8299 - val_mae: 2.5611\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.1556 - mae: 2.1575 - val_loss: 18.8194 - val_mae: 2.5787\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1108 - mae: 2.1562 - val_loss: 18.8988 - val_mae: 2.5735\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0393 - mae: 2.1606 - val_loss: 18.8190 - val_mae: 2.5523\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.0031 - mae: 2.1604 - val_loss: 18.8210 - val_mae: 2.5528\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.9508 - mae: 2.1392 - val_loss: 18.7290 - val_mae: 2.5673\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8993 - mae: 2.1201 - val_loss: 18.7431 - val_mae: 2.5438\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8300 - mae: 2.1158 - val_loss: 18.7585 - val_mae: 2.5403\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8075 - mae: 2.1315 - val_loss: 18.8408 - val_mae: 2.5411\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7941 - mae: 2.1190 - val_loss: 18.8056 - val_mae: 2.5456\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7429 - mae: 2.1198 - val_loss: 19.0437 - val_mae: 2.5751\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.7223 - mae: 2.1386 - val_loss: 18.9744 - val_mae: 2.5554\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.6211 - mae: 2.1184 - val_loss: 18.7088 - val_mae: 2.5311\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5763 - mae: 2.0918 - val_loss: 18.6922 - val_mae: 2.5170\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.5762 - mae: 2.0833 - val_loss: 18.6831 - val_mae: 2.5242\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.5606 - mae: 2.0911 - val_loss: 18.7876 - val_mae: 2.5404\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4520 - mae: 2.0865 - val_loss: 18.7726 - val_mae: 2.5188\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.4412 - mae: 2.0934 - val_loss: 18.6862 - val_mae: 2.5144\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3498 - mae: 2.0772 - val_loss: 18.6692 - val_mae: 2.5229\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3356 - mae: 2.0654 - val_loss: 18.6917 - val_mae: 2.5102\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3548 - mae: 2.0604 - val_loss: 18.6894 - val_mae: 2.5176\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.2386 - mae: 2.0437 - val_loss: 18.6081 - val_mae: 2.5034\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2302 - mae: 2.0625 - val_loss: 18.6128 - val_mae: 2.5183\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2277 - mae: 2.0737 - val_loss: 18.6497 - val_mae: 2.5075\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.1361 - mae: 2.0465 - val_loss: 18.6406 - val_mae: 2.5006\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1020 - mae: 2.0421 - val_loss: 18.5134 - val_mae: 2.5161\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.0952 - mae: 2.0430 - val_loss: 18.6155 - val_mae: 2.5081\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.0225 - mae: 2.0332 - val_loss: 18.5308 - val_mae: 2.4987\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.9999 - mae: 2.0262 - val_loss: 18.4864 - val_mae: 2.4955\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0703 - mae: 2.0234 - val_loss: 18.4060 - val_mae: 2.4876\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9337 - mae: 2.0130 - val_loss: 18.5521 - val_mae: 2.5009\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8880 - mae: 2.0278 - val_loss: 18.8279 - val_mae: 2.5305\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9034 - mae: 2.0224 - val_loss: 18.5968 - val_mae: 2.5059\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8520 - mae: 2.0002 - val_loss: 18.5071 - val_mae: 2.5054\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7903 - mae: 1.9988 - val_loss: 18.6368 - val_mae: 2.5039\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7873 - mae: 2.0005 - val_loss: 18.5798 - val_mae: 2.4930\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.7682 - mae: 2.0045 - val_loss: 18.9041 - val_mae: 2.5138\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.7107 - mae: 1.9992 - val_loss: 18.7287 - val_mae: 2.5069\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6539 - mae: 1.9831 - val_loss: 18.7180 - val_mae: 2.5018\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.6553 - mae: 1.9868 - val_loss: 18.5888 - val_mae: 2.5005\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6984 - mae: 1.9841 - val_loss: 18.4648 - val_mae: 2.4811\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6088 - mae: 1.9636 - val_loss: 18.6099 - val_mae: 2.5055\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.5620 - mae: 1.9832 - val_loss: 18.7313 - val_mae: 2.5374\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.5534 - mae: 1.9970 - val_loss: 18.5890 - val_mae: 2.5086\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.5034 - mae: 1.9685 - val_loss: 18.7163 - val_mae: 2.5111\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4670 - mae: 1.9590 - val_loss: 18.6453 - val_mae: 2.5007\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4763 - mae: 1.9442 - val_loss: 18.6782 - val_mae: 2.5163\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4912 - mae: 1.9735 - val_loss: 19.2269 - val_mae: 2.5566\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4158 - mae: 1.9734 - val_loss: 18.8647 - val_mae: 2.5193\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4459 - mae: 1.9578 - val_loss: 18.7062 - val_mae: 2.4894\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3421 - mae: 1.9209 - val_loss: 18.6558 - val_mae: 2.5019\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3100 - mae: 1.9421 - val_loss: 18.6566 - val_mae: 2.5034\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.3004 - mae: 1.9457 - val_loss: 18.7165 - val_mae: 2.5055\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.2340 - mae: 1.9306 - val_loss: 18.5867 - val_mae: 2.4985\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2183 - mae: 1.9239 - val_loss: 18.6990 - val_mae: 2.5089\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2155 - mae: 1.9242 - val_loss: 18.7247 - val_mae: 2.5172\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.2107 - mae: 1.9206 - val_loss: 18.7476 - val_mae: 2.4971\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1535 - mae: 1.9026 - val_loss: 18.6278 - val_mae: 2.4972\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1382 - mae: 1.9136 - val_loss: 18.7332 - val_mae: 2.5101\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.1420 - mae: 1.9091 - val_loss: 18.6502 - val_mae: 2.4982\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1753 - mae: 1.9252 - val_loss: 18.8319 - val_mae: 2.5000\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.0334 - mae: 1.8955 - val_loss: 18.8189 - val_mae: 2.5182\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1256 - mae: 1.8978 - val_loss: 18.6787 - val_mae: 2.5010\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0650 - mae: 1.9114 - val_loss: 18.9877 - val_mae: 2.5448\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0485 - mae: 1.9099 - val_loss: 18.6840 - val_mae: 2.4852\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.2051 - mae: 1.9214 - val_loss: 19.2750 - val_mae: 2.5451\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9881 - mae: 1.9036 - val_loss: 18.6474 - val_mae: 2.4824\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.9386 - mae: 1.8649 - val_loss: 18.4073 - val_mae: 2.4693\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8680 - mae: 1.8751 - val_loss: 18.6716 - val_mae: 2.5025\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9079 - mae: 1.8756 - val_loss: 18.6890 - val_mae: 2.4785\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.7962 - mae: 1.8651 - val_loss: 18.9572 - val_mae: 2.5039\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7392 - mae: 1.8647 - val_loss: 18.8498 - val_mae: 2.5097\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7998 - mae: 1.8764 - val_loss: 18.8186 - val_mae: 2.4988\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8747 - mae: 1.8520 - val_loss: 18.5181 - val_mae: 2.4563\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7368 - mae: 1.8445 - val_loss: 18.7321 - val_mae: 2.4785\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6638 - mae: 1.8401 - val_loss: 18.8221 - val_mae: 2.5038\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7005 - mae: 1.8735 - val_loss: 19.1013 - val_mae: 2.5180\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6188 - mae: 1.8474 - val_loss: 18.9542 - val_mae: 2.4892\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5781 - mae: 1.8253 - val_loss: 18.8293 - val_mae: 2.4748\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5149 - mae: 1.8156 - val_loss: 18.7443 - val_mae: 2.4809\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7027 - mae: 1.8758 - val_loss: 18.9911 - val_mae: 2.5095\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.5829 - mae: 1.7979 - val_loss: 18.7758 - val_mae: 2.4686\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.5069 - mae: 1.8063 - val_loss: 18.8304 - val_mae: 2.4936\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4367 - mae: 1.8081 - val_loss: 18.7737 - val_mae: 2.4783\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4288 - mae: 1.8023 - val_loss: 18.7020 - val_mae: 2.4717\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3852 - mae: 1.7878 - val_loss: 18.6531 - val_mae: 2.4672\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.3746 - mae: 1.7951 - val_loss: 18.8260 - val_mae: 2.4741\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3263 - mae: 1.7874 - val_loss: 19.1129 - val_mae: 2.4925\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2994 - mae: 1.7871 - val_loss: 18.7789 - val_mae: 2.4775\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.3144 - mae: 1.7752 - val_loss: 18.7652 - val_mae: 2.4781\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2405 - mae: 1.7731 - val_loss: 19.2225 - val_mae: 2.5010\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2318 - mae: 1.7877 - val_loss: 18.9537 - val_mae: 2.4828\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2781 - mae: 1.7741 - val_loss: 18.9986 - val_mae: 2.4774\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1893 - mae: 1.7696 - val_loss: 19.1806 - val_mae: 2.4976\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2109 - mae: 1.7755 - val_loss: 18.9638 - val_mae: 2.4666\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1417 - mae: 1.7475 - val_loss: 18.9958 - val_mae: 2.4682\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1255 - mae: 1.7549 - val_loss: 19.3115 - val_mae: 2.4938\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1567 - mae: 1.7761 - val_loss: 19.1118 - val_mae: 2.4807\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0606 - mae: 1.7556 - val_loss: 18.8870 - val_mae: 2.4661\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0549 - mae: 1.7424 - val_loss: 18.7294 - val_mae: 2.4487\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0267 - mae: 1.7278 - val_loss: 18.8421 - val_mae: 2.4771\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0739 - mae: 1.7712 - val_loss: 19.1248 - val_mae: 2.4965\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9556 - mae: 1.7341 - val_loss: 18.8715 - val_mae: 2.4707\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9741 - mae: 1.7257 - val_loss: 18.8903 - val_mae: 2.4673\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9539 - mae: 1.7394 - val_loss: 19.0653 - val_mae: 2.4876\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9676 - mae: 1.7302 - val_loss: 19.0571 - val_mae: 2.4815\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.8428 - mae: 1.7103 - val_loss: 19.0004 - val_mae: 2.4700\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8787 - mae: 1.7320 - val_loss: 18.9899 - val_mae: 2.4729\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9065 - mae: 1.7111 - val_loss: 18.9273 - val_mae: 2.4593\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8094 - mae: 1.7064 - val_loss: 19.4781 - val_mae: 2.4957\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.8015 - mae: 1.7127 - val_loss: 19.1755 - val_mae: 2.4776\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8713 - mae: 1.7343 - val_loss: 19.0759 - val_mae: 2.4726\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7611 - mae: 1.6940 - val_loss: 19.0422 - val_mae: 2.4628\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.6753 - mae: 1.7046 - val_loss: 19.5877 - val_mae: 2.5190\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7121 - mae: 1.7049 - val_loss: 19.5031 - val_mae: 2.4973\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7014 - mae: 1.7136 - val_loss: 19.1091 - val_mae: 2.4760\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7351 - mae: 1.6771 - val_loss: 18.8026 - val_mae: 2.4530\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6143 - mae: 1.6968 - val_loss: 19.0815 - val_mae: 2.5071\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6485 - mae: 1.6771 - val_loss: 18.6388 - val_mae: 2.4614\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5763 - mae: 1.6680 - val_loss: 19.1944 - val_mae: 2.5044\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5182 - mae: 1.6761 - val_loss: 19.1986 - val_mae: 2.4877\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5164 - mae: 1.6381 - val_loss: 18.8064 - val_mae: 2.4679\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5118 - mae: 1.6693 - val_loss: 19.2985 - val_mae: 2.5274\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4572 - mae: 1.6540 - val_loss: 18.7814 - val_mae: 2.4746\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4697 - mae: 1.6642 - val_loss: 19.0748 - val_mae: 2.5004\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3792 - mae: 1.6331 - val_loss: 18.9036 - val_mae: 2.4812\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3486 - mae: 1.6443 - val_loss: 19.1652 - val_mae: 2.5140\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3622 - mae: 1.6373 - val_loss: 18.9667 - val_mae: 2.4853\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2726 - mae: 1.6045 - val_loss: 19.0363 - val_mae: 2.5051\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2709 - mae: 1.6355 - val_loss: 19.1507 - val_mae: 2.4976\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2793 - mae: 1.6311 - val_loss: 18.9908 - val_mae: 2.4878\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1934 - mae: 1.6153 - val_loss: 18.9348 - val_mae: 2.5033\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1837 - mae: 1.5964 - val_loss: 18.8706 - val_mae: 2.4782\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1367 - mae: 1.5991 - val_loss: 18.9300 - val_mae: 2.5126\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1834 - mae: 1.6123 - val_loss: 18.6807 - val_mae: 2.4940\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1329 - mae: 1.5946 - val_loss: 18.7924 - val_mae: 2.4939\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0728 - mae: 1.5858 - val_loss: 18.8702 - val_mae: 2.4870\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0929 - mae: 1.6044 - val_loss: 19.0537 - val_mae: 2.5180\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0530 - mae: 1.5860 - val_loss: 18.8829 - val_mae: 2.4912\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0099 - mae: 1.5682 - val_loss: 18.8212 - val_mae: 2.5006\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0254 - mae: 1.5903 - val_loss: 18.9391 - val_mae: 2.5187\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0032 - mae: 1.5730 - val_loss: 18.7893 - val_mae: 2.4981\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9554 - mae: 1.5646 - val_loss: 18.8049 - val_mae: 2.5033\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9154 - mae: 1.5531 - val_loss: 18.7408 - val_mae: 2.4983\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8931 - mae: 1.5539 - val_loss: 18.9492 - val_mae: 2.5150\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8746 - mae: 1.5491 - val_loss: 18.7425 - val_mae: 2.4895\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8503 - mae: 1.5373 - val_loss: 18.5930 - val_mae: 2.4912\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.8635 - mae: 1.5600 - val_loss: 18.7996 - val_mae: 2.5126\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8424 - mae: 1.5614 - val_loss: 18.8541 - val_mae: 2.5172\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8167 - mae: 1.5262 - val_loss: 18.7050 - val_mae: 2.4879\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8017 - mae: 1.5323 - val_loss: 18.8626 - val_mae: 2.5212\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7806 - mae: 1.5417 - val_loss: 18.8200 - val_mae: 2.5164\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8793 - mae: 1.5212 - val_loss: 18.6199 - val_mae: 2.4992\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7633 - mae: 1.5624 - val_loss: 18.8696 - val_mae: 2.5621\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7291 - mae: 1.5347 - val_loss: 18.5410 - val_mae: 2.5007\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6414 - mae: 1.5092 - val_loss: 18.7497 - val_mae: 2.5086\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6409 - mae: 1.5210 - val_loss: 18.7346 - val_mae: 2.5174\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7145 - mae: 1.4977 - val_loss: 18.2331 - val_mae: 2.4843\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.5913 - mae: 1.5074 - val_loss: 18.5806 - val_mae: 2.5366\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5712 - mae: 1.5048 - val_loss: 18.4418 - val_mae: 2.4992\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5385 - mae: 1.4821 - val_loss: 18.9046 - val_mae: 2.5442\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5305 - mae: 1.4945 - val_loss: 18.7226 - val_mae: 2.5085\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4902 - mae: 1.4675 - val_loss: 18.5052 - val_mae: 2.5019\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4825 - mae: 1.4839 - val_loss: 18.5270 - val_mae: 2.5307\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4908 - mae: 1.4885 - val_loss: 18.7795 - val_mae: 2.5269\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4983 - mae: 1.4911 - val_loss: 18.7531 - val_mae: 2.5498\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4702 - mae: 1.4729 - val_loss: 18.2922 - val_mae: 2.4972\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4443 - mae: 1.4978 - val_loss: 19.0259 - val_mae: 2.5526\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3511 - mae: 1.4688 - val_loss: 18.4687 - val_mae: 2.4834\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.2811 - mae: 1.4406 - val_loss: 18.3596 - val_mae: 2.5116\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3275 - mae: 1.4629 - val_loss: 18.2132 - val_mae: 2.5354\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2520 - mae: 1.4340 - val_loss: 18.4335 - val_mae: 2.4996\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2358 - mae: 1.4303 - val_loss: 18.7350 - val_mae: 2.5270\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3109 - mae: 1.4430 - val_loss: 18.2603 - val_mae: 2.5157\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1817 - mae: 1.4426 - val_loss: 18.7549 - val_mae: 2.5520\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2311 - mae: 1.4328 - val_loss: 18.4815 - val_mae: 2.5162\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1345 - mae: 1.4138 - val_loss: 18.6336 - val_mae: 2.5399\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2359 - mae: 1.4463 - val_loss: 18.0798 - val_mae: 2.5299\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1349 - mae: 1.4140 - val_loss: 18.3427 - val_mae: 2.5007\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1565 - mae: 1.4316 - val_loss: 18.7713 - val_mae: 2.5721\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0634 - mae: 1.3992 - val_loss: 17.8859 - val_mae: 2.5042\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0807 - mae: 1.3955 - val_loss: 18.2679 - val_mae: 2.5307\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0127 - mae: 1.3896 - val_loss: 18.2731 - val_mae: 2.5190\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0149 - mae: 1.3930 - val_loss: 18.7122 - val_mae: 2.5763\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0286 - mae: 1.3996 - val_loss: 18.4935 - val_mae: 2.5426\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9697 - mae: 1.4079 - val_loss: 18.4495 - val_mae: 2.5448\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0360 - mae: 1.4024 - val_loss: 18.0888 - val_mae: 2.5094\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9572 - mae: 1.3878 - val_loss: 18.2494 - val_mae: 2.5652\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9766 - mae: 1.3879 - val_loss: 18.0671 - val_mae: 2.5090\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9689 - mae: 1.4031 - val_loss: 18.6318 - val_mae: 2.5593\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8753 - mae: 1.3696 - val_loss: 17.9886 - val_mae: 2.5015\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8936 - mae: 1.3723 - val_loss: 18.0610 - val_mae: 2.5539\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8358 - mae: 1.3599 - val_loss: 18.3110 - val_mae: 2.5321\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7973 - mae: 1.3555 - val_loss: 18.3841 - val_mae: 2.5605\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7657 - mae: 1.3614 - val_loss: 18.0832 - val_mae: 2.5484\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7977 - mae: 1.3641 - val_loss: 18.2210 - val_mae: 2.5280\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8413 - mae: 1.3522 - val_loss: 18.2279 - val_mae: 2.5423\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.7742 - mae: 1.3608 - val_loss: 18.3796 - val_mae: 2.5820\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6719 - mae: 1.3393 - val_loss: 18.5464 - val_mae: 2.5599\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7612 - mae: 1.3672 - val_loss: 18.5616 - val_mae: 2.5948\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6819 - mae: 1.3278 - val_loss: 18.0656 - val_mae: 2.5179\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6532 - mae: 1.3237 - val_loss: 18.5193 - val_mae: 2.5787\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7174 - mae: 1.3554 - val_loss: 18.3390 - val_mae: 2.5580\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6215 - mae: 1.3211 - val_loss: 18.2993 - val_mae: 2.5614\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5515 - mae: 1.3186 - val_loss: 18.2103 - val_mae: 2.5440\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5974 - mae: 1.3247 - val_loss: 18.2379 - val_mae: 2.5355\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4958 - mae: 1.3061 - val_loss: 18.4469 - val_mae: 2.5685\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5611 - mae: 1.3110 - val_loss: 18.1817 - val_mae: 2.5503\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5017 - mae: 1.3131 - val_loss: 18.3489 - val_mae: 2.5687\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4390 - mae: 1.2929 - val_loss: 17.8894 - val_mae: 2.5286\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.4939 - mae: 1.2946 - val_loss: 18.4157 - val_mae: 2.5708\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4041 - mae: 1.2711 - val_loss: 18.2865 - val_mae: 2.5563\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4512 - mae: 1.2968 - val_loss: 18.3950 - val_mae: 2.6045\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2808834.0000 - mae: 1637.4797\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 18ms/step - loss: 570.6498 - mae: 22.0558 - val_loss: 611.0623 - val_mae: 22.8425\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 539.1810 - mae: 21.3247 - val_loss: 578.0416 - val_mae: 22.1181\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 508.1241 - mae: 20.6014 - val_loss: 542.9537 - val_mae: 21.3339\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 474.0273 - mae: 19.7842 - val_loss: 501.1664 - val_mae: 20.3749\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 431.6205 - mae: 18.7638 - val_loss: 452.5845 - val_mae: 19.2173\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 382.8150 - mae: 17.4963 - val_loss: 394.7972 - val_mae: 17.7793\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 326.0160 - mae: 15.9259 - val_loss: 329.3753 - val_mae: 16.0003\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 264.3460 - mae: 14.0149 - val_loss: 260.1996 - val_mae: 13.8520\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 203.6627 - mae: 11.9409 - val_loss: 194.0329 - val_mae: 11.3835\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 146.6605 - mae: 9.8673 - val_loss: 143.2116 - val_mae: 9.1499\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 107.7883 - mae: 8.1789 - val_loss: 106.9225 - val_mae: 7.8128\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 82.4353 - mae: 7.0063 - val_loss: 84.9579 - val_mae: 6.9887\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 65.9733 - mae: 6.2563 - val_loss: 70.4906 - val_mae: 6.2828\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 55.7892 - mae: 5.7211 - val_loss: 58.8510 - val_mae: 5.6440\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 47.2232 - mae: 5.1985 - val_loss: 49.2915 - val_mae: 5.0939\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 40.4727 - mae: 4.7543 - val_loss: 42.2221 - val_mae: 4.6646\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.7282 - mae: 4.4422 - val_loss: 36.8505 - val_mae: 4.3042\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.0453 - mae: 4.1925 - val_loss: 32.8967 - val_mae: 4.0057\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.3878 - mae: 4.0256 - val_loss: 30.0613 - val_mae: 3.7642\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 27.4598 - mae: 3.8798 - val_loss: 27.9832 - val_mae: 3.5975\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.2398 - mae: 3.7913 - val_loss: 26.2448 - val_mae: 3.4756\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.1239 - mae: 3.7066 - val_loss: 24.9209 - val_mae: 3.3962\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.3177 - mae: 3.6495 - val_loss: 23.8645 - val_mae: 3.3334\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.6340 - mae: 3.5840 - val_loss: 22.9585 - val_mae: 3.2458\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.9277 - mae: 3.5188 - val_loss: 22.1793 - val_mae: 3.2014\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.3881 - mae: 3.4729 - val_loss: 21.4833 - val_mae: 3.1421\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.8382 - mae: 3.4257 - val_loss: 20.9245 - val_mae: 3.1077\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.4342 - mae: 3.3980 - val_loss: 20.3507 - val_mae: 3.1022\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 20.9046 - mae: 3.3616 - val_loss: 19.8496 - val_mae: 3.0595\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 20.5203 - mae: 3.3165 - val_loss: 19.3003 - val_mae: 3.0075\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 20.1085 - mae: 3.2668 - val_loss: 18.9363 - val_mae: 2.9719\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 19.7547 - mae: 3.2314 - val_loss: 18.6204 - val_mae: 2.9445\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.3556 - mae: 3.1889 - val_loss: 18.2639 - val_mae: 2.9073\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 19.0289 - mae: 3.1668 - val_loss: 17.9527 - val_mae: 2.9000\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 18.6741 - mae: 3.1276 - val_loss: 17.5579 - val_mae: 2.8615\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 18.3274 - mae: 3.0971 - val_loss: 17.2159 - val_mae: 2.8561\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 18.0340 - mae: 3.0740 - val_loss: 16.8978 - val_mae: 2.8515\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.7401 - mae: 3.0417 - val_loss: 16.5825 - val_mae: 2.8202\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 17.5724 - mae: 3.0170 - val_loss: 16.3636 - val_mae: 2.8181\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.1216 - mae: 2.9722 - val_loss: 16.0984 - val_mae: 2.7723\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.8484 - mae: 2.9353 - val_loss: 15.9980 - val_mae: 2.7381\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.6418 - mae: 2.9012 - val_loss: 15.7780 - val_mae: 2.7284\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.4100 - mae: 2.8728 - val_loss: 15.5968 - val_mae: 2.7163\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.1253 - mae: 2.8529 - val_loss: 15.3582 - val_mae: 2.7423\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.9262 - mae: 2.8380 - val_loss: 15.1633 - val_mae: 2.7679\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.6991 - mae: 2.8205 - val_loss: 14.9785 - val_mae: 2.7466\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.4534 - mae: 2.7874 - val_loss: 14.7297 - val_mae: 2.7069\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.2165 - mae: 2.7470 - val_loss: 14.6376 - val_mae: 2.6799\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 15.0419 - mae: 2.7203 - val_loss: 14.4468 - val_mae: 2.6714\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.9695 - mae: 2.7169 - val_loss: 14.3339 - val_mae: 2.6941\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.5683 - mae: 2.6875 - val_loss: 14.2379 - val_mae: 2.6649\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.4332 - mae: 2.6646 - val_loss: 14.2217 - val_mae: 2.6532\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.3755 - mae: 2.6503 - val_loss: 14.1302 - val_mae: 2.6618\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.1481 - mae: 2.6245 - val_loss: 14.0147 - val_mae: 2.6685\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 13.9572 - mae: 2.6112 - val_loss: 13.8341 - val_mae: 2.6634\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.8088 - mae: 2.5906 - val_loss: 13.6768 - val_mae: 2.6356\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.6362 - mae: 2.5727 - val_loss: 13.5496 - val_mae: 2.6431\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.4866 - mae: 2.5632 - val_loss: 13.4272 - val_mae: 2.6417\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.3398 - mae: 2.5530 - val_loss: 13.2880 - val_mae: 2.6278\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.2366 - mae: 2.5422 - val_loss: 13.2561 - val_mae: 2.6228\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.0546 - mae: 2.5241 - val_loss: 13.1739 - val_mae: 2.6251\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.9334 - mae: 2.5043 - val_loss: 13.1238 - val_mae: 2.6308\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.8470 - mae: 2.4932 - val_loss: 13.0441 - val_mae: 2.6224\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.6613 - mae: 2.4758 - val_loss: 12.9416 - val_mae: 2.6384\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.5894 - mae: 2.4753 - val_loss: 12.8696 - val_mae: 2.6360\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.4413 - mae: 2.4620 - val_loss: 12.7882 - val_mae: 2.6198\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.3776 - mae: 2.4515 - val_loss: 12.7452 - val_mae: 2.6207\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.3463 - mae: 2.4463 - val_loss: 12.6564 - val_mae: 2.6405\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.1250 - mae: 2.4286 - val_loss: 12.5315 - val_mae: 2.6158\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.0329 - mae: 2.4046 - val_loss: 12.5351 - val_mae: 2.5876\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.0187 - mae: 2.4064 - val_loss: 12.5468 - val_mae: 2.6136\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.8375 - mae: 2.3927 - val_loss: 12.4838 - val_mae: 2.6197\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.7211 - mae: 2.3756 - val_loss: 12.4700 - val_mae: 2.6137\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.6991 - mae: 2.3708 - val_loss: 12.4457 - val_mae: 2.6293\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.5082 - mae: 2.3592 - val_loss: 12.4494 - val_mae: 2.6220\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.4394 - mae: 2.3500 - val_loss: 12.3982 - val_mae: 2.6247\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.3455 - mae: 2.3369 - val_loss: 12.3678 - val_mae: 2.6136\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.2748 - mae: 2.3179 - val_loss: 12.2953 - val_mae: 2.6097\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.2654 - mae: 2.3162 - val_loss: 12.2627 - val_mae: 2.6096\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.1158 - mae: 2.3229 - val_loss: 12.2621 - val_mae: 2.6335\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.0550 - mae: 2.3172 - val_loss: 12.1873 - val_mae: 2.6110\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.9389 - mae: 2.2920 - val_loss: 12.1697 - val_mae: 2.6093\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.8727 - mae: 2.2837 - val_loss: 12.2030 - val_mae: 2.6215\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.8155 - mae: 2.2726 - val_loss: 12.2387 - val_mae: 2.6080\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6979 - mae: 2.2553 - val_loss: 12.1711 - val_mae: 2.6149\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.6313 - mae: 2.2614 - val_loss: 12.1503 - val_mae: 2.6179\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.5766 - mae: 2.2551 - val_loss: 12.1517 - val_mae: 2.6156\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.5216 - mae: 2.2450 - val_loss: 12.1792 - val_mae: 2.6193\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.4526 - mae: 2.2340 - val_loss: 12.1622 - val_mae: 2.6121\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.4425 - mae: 2.2455 - val_loss: 12.2049 - val_mae: 2.6340\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3328 - mae: 2.2268 - val_loss: 12.1711 - val_mae: 2.6216\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.2660 - mae: 2.2157 - val_loss: 12.1749 - val_mae: 2.6235\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.2438 - mae: 2.2185 - val_loss: 12.0927 - val_mae: 2.6204\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.1466 - mae: 2.2024 - val_loss: 12.0802 - val_mae: 2.6121\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.0730 - mae: 2.1961 - val_loss: 12.1030 - val_mae: 2.6175\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.0486 - mae: 2.1856 - val_loss: 12.1153 - val_mae: 2.6197\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.0307 - mae: 2.1961 - val_loss: 12.1492 - val_mae: 2.6231\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.8982 - mae: 2.1800 - val_loss: 12.1479 - val_mae: 2.6271\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8490 - mae: 2.1779 - val_loss: 12.1069 - val_mae: 2.6164\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7998 - mae: 2.1657 - val_loss: 12.1442 - val_mae: 2.6281\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.7629 - mae: 2.1579 - val_loss: 12.2333 - val_mae: 2.6433\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8156 - mae: 2.1867 - val_loss: 12.2726 - val_mae: 2.6690\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.5843 - mae: 2.1505 - val_loss: 12.2581 - val_mae: 2.6345\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6658 - mae: 2.1422 - val_loss: 12.3139 - val_mae: 2.6435\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.6422 - mae: 2.1589 - val_loss: 12.2453 - val_mae: 2.6633\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.5714 - mae: 2.1477 - val_loss: 12.1965 - val_mae: 2.6347\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.4412 - mae: 2.1309 - val_loss: 12.1754 - val_mae: 2.6474\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.4088 - mae: 2.1369 - val_loss: 12.1880 - val_mae: 2.6564\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.3374 - mae: 2.1278 - val_loss: 12.1942 - val_mae: 2.6412\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3237 - mae: 2.1122 - val_loss: 12.1302 - val_mae: 2.6323\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.2338 - mae: 2.1142 - val_loss: 12.1014 - val_mae: 2.6444\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.2116 - mae: 2.1222 - val_loss: 12.1047 - val_mae: 2.6419\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1157 - mae: 2.1057 - val_loss: 12.0726 - val_mae: 2.6320\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0902 - mae: 2.1021 - val_loss: 12.0619 - val_mae: 2.6228\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.0436 - mae: 2.0912 - val_loss: 12.1507 - val_mae: 2.6375\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.9910 - mae: 2.0886 - val_loss: 12.1030 - val_mae: 2.6408\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0166 - mae: 2.0836 - val_loss: 12.1347 - val_mae: 2.6389\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9093 - mae: 2.0749 - val_loss: 12.1290 - val_mae: 2.6570\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8648 - mae: 2.0745 - val_loss: 12.0998 - val_mae: 2.6444\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.8643 - mae: 2.0696 - val_loss: 11.9663 - val_mae: 2.6315\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.7871 - mae: 2.0648 - val_loss: 11.9628 - val_mae: 2.6301\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.6908 - mae: 2.0572 - val_loss: 11.8958 - val_mae: 2.6306\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6524 - mae: 2.0537 - val_loss: 11.8757 - val_mae: 2.6258\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.5611 - mae: 2.0469 - val_loss: 11.8856 - val_mae: 2.6339\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5432 - mae: 2.0461 - val_loss: 11.8396 - val_mae: 2.6296\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5497 - mae: 2.0347 - val_loss: 11.8697 - val_mae: 2.6279\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.4569 - mae: 2.0429 - val_loss: 11.8034 - val_mae: 2.6320\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.4133 - mae: 2.0451 - val_loss: 11.7491 - val_mae: 2.6255\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3959 - mae: 2.0127 - val_loss: 11.6788 - val_mae: 2.6054\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3008 - mae: 2.0000 - val_loss: 11.6951 - val_mae: 2.6226\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2275 - mae: 2.0057 - val_loss: 11.7288 - val_mae: 2.6321\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1849 - mae: 2.0091 - val_loss: 11.7177 - val_mae: 2.6363\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2154 - mae: 2.0038 - val_loss: 11.6250 - val_mae: 2.6136\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1669 - mae: 1.9999 - val_loss: 11.6800 - val_mae: 2.6280\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0564 - mae: 1.9825 - val_loss: 11.6489 - val_mae: 2.6194\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0529 - mae: 1.9729 - val_loss: 11.6730 - val_mae: 2.6160\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0110 - mae: 1.9731 - val_loss: 11.7506 - val_mae: 2.6503\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0462 - mae: 1.9958 - val_loss: 11.6968 - val_mae: 2.6401\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9128 - mae: 1.9586 - val_loss: 11.7666 - val_mae: 2.6288\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9595 - mae: 1.9522 - val_loss: 11.7036 - val_mae: 2.6237\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7952 - mae: 1.9502 - val_loss: 11.6534 - val_mae: 2.6272\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.7386 - mae: 1.9410 - val_loss: 11.5700 - val_mae: 2.6187\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.7314 - mae: 1.9478 - val_loss: 11.6112 - val_mae: 2.6394\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6462 - mae: 1.9408 - val_loss: 11.6384 - val_mae: 2.6266\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6415 - mae: 1.9221 - val_loss: 11.6166 - val_mae: 2.6227\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5748 - mae: 1.9227 - val_loss: 11.6446 - val_mae: 2.6442\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5921 - mae: 1.9447 - val_loss: 11.6751 - val_mae: 2.6352\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.4795 - mae: 1.9086 - val_loss: 11.5144 - val_mae: 2.6069\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.4506 - mae: 1.9067 - val_loss: 11.7045 - val_mae: 2.6515\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.4315 - mae: 1.9194 - val_loss: 11.6835 - val_mae: 2.6392\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2813 - mae: 1.8876 - val_loss: 11.6514 - val_mae: 2.6229\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3900 - mae: 1.8842 - val_loss: 11.5228 - val_mae: 2.6117\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2650 - mae: 1.8841 - val_loss: 11.4478 - val_mae: 2.6243\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2254 - mae: 1.8991 - val_loss: 11.4443 - val_mae: 2.6279\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1338 - mae: 1.8780 - val_loss: 11.3692 - val_mae: 2.6032\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0853 - mae: 1.8648 - val_loss: 11.4715 - val_mae: 2.6189\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0470 - mae: 1.8660 - val_loss: 11.6039 - val_mae: 2.6315\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.0523 - mae: 1.8752 - val_loss: 11.5192 - val_mae: 2.6242\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0016 - mae: 1.8422 - val_loss: 11.3491 - val_mae: 2.5998\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9897 - mae: 1.8573 - val_loss: 11.3732 - val_mae: 2.6223\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8911 - mae: 1.8461 - val_loss: 11.3306 - val_mae: 2.6007\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8921 - mae: 1.8373 - val_loss: 11.3106 - val_mae: 2.6009\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8179 - mae: 1.8363 - val_loss: 11.2720 - val_mae: 2.6005\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8636 - mae: 1.8395 - val_loss: 11.4867 - val_mae: 2.6202\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7687 - mae: 1.8412 - val_loss: 11.5555 - val_mae: 2.6357\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7354 - mae: 1.8279 - val_loss: 11.2764 - val_mae: 2.5929\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.6402 - mae: 1.8159 - val_loss: 11.3234 - val_mae: 2.6050\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.6271 - mae: 1.8195 - val_loss: 11.4107 - val_mae: 2.6109\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6306 - mae: 1.8067 - val_loss: 11.2928 - val_mae: 2.5991\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5708 - mae: 1.8169 - val_loss: 11.5155 - val_mae: 2.6297\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4822 - mae: 1.7998 - val_loss: 11.4038 - val_mae: 2.6031\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4902 - mae: 1.7909 - val_loss: 11.2806 - val_mae: 2.6005\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5046 - mae: 1.8019 - val_loss: 11.3521 - val_mae: 2.6084\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3823 - mae: 1.7756 - val_loss: 11.2592 - val_mae: 2.5880\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3619 - mae: 1.7689 - val_loss: 11.2968 - val_mae: 2.5985\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3852 - mae: 1.7884 - val_loss: 11.4038 - val_mae: 2.6151\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.3315 - mae: 1.7698 - val_loss: 11.2274 - val_mae: 2.5823\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2385 - mae: 1.7660 - val_loss: 11.4009 - val_mae: 2.6139\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1913 - mae: 1.7697 - val_loss: 11.0903 - val_mae: 2.5718\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.1593 - mae: 1.7459 - val_loss: 11.0083 - val_mae: 2.5576\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0407 - mae: 1.7351 - val_loss: 11.2375 - val_mae: 2.5925\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1515 - mae: 1.7800 - val_loss: 11.1837 - val_mae: 2.5914\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0091 - mae: 1.7359 - val_loss: 10.8997 - val_mae: 2.5435\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0477 - mae: 1.7388 - val_loss: 10.9515 - val_mae: 2.5517\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9746 - mae: 1.7486 - val_loss: 11.2271 - val_mae: 2.5920\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8842 - mae: 1.7218 - val_loss: 11.0282 - val_mae: 2.5580\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8843 - mae: 1.7208 - val_loss: 11.0470 - val_mae: 2.5604\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8314 - mae: 1.7172 - val_loss: 11.1603 - val_mae: 2.5703\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8327 - mae: 1.7081 - val_loss: 11.1260 - val_mae: 2.5613\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.7528 - mae: 1.7006 - val_loss: 11.0881 - val_mae: 2.5619\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8236 - mae: 1.7035 - val_loss: 11.0907 - val_mae: 2.5613\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7391 - mae: 1.7287 - val_loss: 11.2674 - val_mae: 2.5800\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.6724 - mae: 1.7136 - val_loss: 11.0861 - val_mae: 2.5550\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6266 - mae: 1.6834 - val_loss: 11.0600 - val_mae: 2.5503\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6253 - mae: 1.6949 - val_loss: 11.4305 - val_mae: 2.5868\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6307 - mae: 1.7121 - val_loss: 11.4013 - val_mae: 2.5759\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.5477 - mae: 1.6850 - val_loss: 11.3458 - val_mae: 2.5767\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5192 - mae: 1.6823 - val_loss: 11.3874 - val_mae: 2.5774\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5401 - mae: 1.6806 - val_loss: 11.1252 - val_mae: 2.5470\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.4940 - mae: 1.6657 - val_loss: 11.0317 - val_mae: 2.5384\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4608 - mae: 1.6754 - val_loss: 11.2822 - val_mae: 2.5664\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3839 - mae: 1.6585 - val_loss: 10.9807 - val_mae: 2.5201\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4530 - mae: 1.6744 - val_loss: 10.9738 - val_mae: 2.5273\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.3711 - mae: 1.6653 - val_loss: 11.0295 - val_mae: 2.5230\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3423 - mae: 1.6552 - val_loss: 11.1081 - val_mae: 2.5399\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2596 - mae: 1.6468 - val_loss: 11.0655 - val_mae: 2.5293\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2571 - mae: 1.6372 - val_loss: 11.0537 - val_mae: 2.5218\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1827 - mae: 1.6279 - val_loss: 11.0735 - val_mae: 2.5293\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2187 - mae: 1.6510 - val_loss: 11.0470 - val_mae: 2.5242\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.2375 - mae: 1.6500 - val_loss: 11.1244 - val_mae: 2.5282\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1262 - mae: 1.6268 - val_loss: 11.3146 - val_mae: 2.5358\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0813 - mae: 1.6189 - val_loss: 11.1748 - val_mae: 2.5341\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0461 - mae: 1.6219 - val_loss: 10.9288 - val_mae: 2.4959\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.0240 - mae: 1.6114 - val_loss: 10.9553 - val_mae: 2.5053\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0239 - mae: 1.6116 - val_loss: 10.9321 - val_mae: 2.5016\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9916 - mae: 1.6212 - val_loss: 11.0411 - val_mae: 2.5081\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.9324 - mae: 1.6001 - val_loss: 11.0414 - val_mae: 2.5050\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9150 - mae: 1.5964 - val_loss: 11.0618 - val_mae: 2.5019\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9004 - mae: 1.6023 - val_loss: 11.1776 - val_mae: 2.5074\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8515 - mae: 1.5942 - val_loss: 11.1449 - val_mae: 2.5008\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8267 - mae: 1.5862 - val_loss: 11.1555 - val_mae: 2.5063\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8163 - mae: 1.5757 - val_loss: 11.0623 - val_mae: 2.4886\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7730 - mae: 1.5756 - val_loss: 11.2374 - val_mae: 2.5151\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7994 - mae: 1.5966 - val_loss: 11.1488 - val_mae: 2.4946\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7628 - mae: 1.5758 - val_loss: 11.2418 - val_mae: 2.5039\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7037 - mae: 1.5545 - val_loss: 11.1940 - val_mae: 2.4974\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7001 - mae: 1.5707 - val_loss: 11.2649 - val_mae: 2.5101\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6482 - mae: 1.5566 - val_loss: 11.0256 - val_mae: 2.4772\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5982 - mae: 1.5514 - val_loss: 11.1743 - val_mae: 2.4979\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5799 - mae: 1.5509 - val_loss: 10.9049 - val_mae: 2.4596\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6539 - mae: 1.5474 - val_loss: 11.1220 - val_mae: 2.4793\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6056 - mae: 1.5704 - val_loss: 11.1564 - val_mae: 2.4891\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5204 - mae: 1.5341 - val_loss: 10.9716 - val_mae: 2.4557\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5255 - mae: 1.5425 - val_loss: 11.0753 - val_mae: 2.4778\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4841 - mae: 1.5314 - val_loss: 11.0288 - val_mae: 2.4695\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4941 - mae: 1.5238 - val_loss: 10.9817 - val_mae: 2.4616\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.5540 - mae: 1.5627 - val_loss: 10.9612 - val_mae: 2.4637\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5644 - mae: 1.5487 - val_loss: 10.9375 - val_mae: 2.4680\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4155 - mae: 1.5162 - val_loss: 11.1234 - val_mae: 2.4573\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3771 - mae: 1.5285 - val_loss: 10.9454 - val_mae: 2.4539\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3432 - mae: 1.5099 - val_loss: 10.8192 - val_mae: 2.4380\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.3187 - mae: 1.4951 - val_loss: 10.9777 - val_mae: 2.4492\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2937 - mae: 1.5065 - val_loss: 10.9365 - val_mae: 2.4375\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3358 - mae: 1.5110 - val_loss: 11.0093 - val_mae: 2.4473\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2998 - mae: 1.5120 - val_loss: 10.9487 - val_mae: 2.4490\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2000 - mae: 1.4891 - val_loss: 11.0219 - val_mae: 2.4324\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2782 - mae: 1.5208 - val_loss: 11.1622 - val_mae: 2.4502\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1865 - mae: 1.4822 - val_loss: 10.8941 - val_mae: 2.4273\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2187 - mae: 1.4800 - val_loss: 10.9668 - val_mae: 2.4329\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1399 - mae: 1.4832 - val_loss: 11.3171 - val_mae: 2.4616\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1188 - mae: 1.4705 - val_loss: 10.9050 - val_mae: 2.4232\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1413 - mae: 1.4705 - val_loss: 11.0885 - val_mae: 2.4353\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1162 - mae: 1.4738 - val_loss: 11.0923 - val_mae: 2.4361\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0354 - mae: 1.4586 - val_loss: 11.0968 - val_mae: 2.4386\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0026 - mae: 1.4534 - val_loss: 11.0043 - val_mae: 2.4265\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0017 - mae: 1.4572 - val_loss: 11.2073 - val_mae: 2.4360\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0497 - mae: 1.4652 - val_loss: 11.0990 - val_mae: 2.4251\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0042 - mae: 1.4632 - val_loss: 11.0053 - val_mae: 2.4063\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0632 - mae: 1.4918 - val_loss: 11.0454 - val_mae: 2.4128\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9611 - mae: 1.4455 - val_loss: 11.0083 - val_mae: 2.4074\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8936 - mae: 1.4196 - val_loss: 11.2294 - val_mae: 2.4325\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9383 - mae: 1.4552 - val_loss: 11.1076 - val_mae: 2.4138\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9068 - mae: 1.4284 - val_loss: 10.8039 - val_mae: 2.3916\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8703 - mae: 1.4300 - val_loss: 11.2002 - val_mae: 2.4208\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8473 - mae: 1.4161 - val_loss: 11.0012 - val_mae: 2.4002\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8001 - mae: 1.4130 - val_loss: 11.1836 - val_mae: 2.4159\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8208 - mae: 1.4270 - val_loss: 10.9917 - val_mae: 2.3910\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7604 - mae: 1.4146 - val_loss: 10.8230 - val_mae: 2.3806\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8574 - mae: 1.4110 - val_loss: 11.1248 - val_mae: 2.4156\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7962 - mae: 1.4316 - val_loss: 11.2262 - val_mae: 2.4098\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8344 - mae: 1.4160 - val_loss: 10.9110 - val_mae: 2.3802\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7111 - mae: 1.4077 - val_loss: 11.5012 - val_mae: 2.4232\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.7016 - mae: 1.4095 - val_loss: 11.2958 - val_mae: 2.4000\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6868 - mae: 1.3879 - val_loss: 11.2571 - val_mae: 2.4044\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6182 - mae: 1.3776 - val_loss: 11.2220 - val_mae: 2.4006\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6403 - mae: 1.3896 - val_loss: 11.2201 - val_mae: 2.4059\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7721 - mae: 1.4304 - val_loss: 10.9983 - val_mae: 2.3753\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6789 - mae: 1.3819 - val_loss: 11.2690 - val_mae: 2.4017\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6479 - mae: 1.3918 - val_loss: 11.2630 - val_mae: 2.3890\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6015 - mae: 1.3895 - val_loss: 11.1432 - val_mae: 2.3861\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5600 - mae: 1.3609 - val_loss: 11.2242 - val_mae: 2.4015\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.6005 - mae: 1.3760 - val_loss: 11.3017 - val_mae: 2.3975\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5198 - mae: 1.3649 - val_loss: 11.1895 - val_mae: 2.3963\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5100 - mae: 1.3647 - val_loss: 11.0708 - val_mae: 2.3781\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5246 - mae: 1.3715 - val_loss: 11.1096 - val_mae: 2.3776\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5099 - mae: 1.3455 - val_loss: 11.0665 - val_mae: 2.3729\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.5472 - mae: 1.3808 - val_loss: 11.5528 - val_mae: 2.4073\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.4839 - mae: 1.3587 - val_loss: 11.2944 - val_mae: 2.3883\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.4589 - mae: 1.3610 - val_loss: 11.4521 - val_mae: 2.3934\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4670 - mae: 1.3532 - val_loss: 11.1300 - val_mae: 2.3722\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3905 - mae: 1.3345 - val_loss: 11.3579 - val_mae: 2.3863\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3902 - mae: 1.3366 - val_loss: 11.3754 - val_mae: 2.3748\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3769 - mae: 1.3264 - val_loss: 11.5343 - val_mae: 2.3920\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3468 - mae: 1.3290 - val_loss: 11.3058 - val_mae: 2.3735\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3181 - mae: 1.3332 - val_loss: 11.4302 - val_mae: 2.3750\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3376 - mae: 1.3262 - val_loss: 11.1438 - val_mae: 2.3479\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3494 - mae: 1.3474 - val_loss: 11.4417 - val_mae: 2.3736\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.2731 - mae: 1.3229 - val_loss: 11.2642 - val_mae: 2.3586\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3085 - mae: 1.3163 - val_loss: 11.4998 - val_mae: 2.3880\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3091 - mae: 1.3305 - val_loss: 11.3230 - val_mae: 2.3618\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2700610.0000 - mae: 1619.3019\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 2s 27ms/step - loss: 560.0315 - mae: 21.7246 - val_loss: 456.4236 - val_mae: 19.5876\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 525.8564 - mae: 20.9874 - val_loss: 423.4274 - val_mae: 18.8054\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 482.7923 - mae: 20.0389 - val_loss: 381.8656 - val_mae: 17.7715\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 427.5982 - mae: 18.7490 - val_loss: 328.9740 - val_mae: 16.3566\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 361.1621 - mae: 17.0429 - val_loss: 265.5703 - val_mae: 14.5328\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 283.5370 - mae: 14.8456 - val_loss: 197.5457 - val_mae: 12.3316\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 205.9039 - mae: 12.1692 - val_loss: 135.0890 - val_mae: 10.0545\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 137.1335 - mae: 9.5340 - val_loss: 90.5995 - val_mae: 8.2596\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 95.2242 - mae: 7.7472 - val_loss: 64.9447 - val_mae: 6.8238\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 72.1348 - mae: 6.6268 - val_loss: 52.1765 - val_mae: 5.8791\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 59.8692 - mae: 5.8896 - val_loss: 43.4063 - val_mae: 5.3158\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 49.7864 - mae: 5.3536 - val_loss: 36.6751 - val_mae: 4.8804\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 42.8048 - mae: 4.9294 - val_loss: 31.0841 - val_mae: 4.4895\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 37.5573 - mae: 4.5803 - val_loss: 27.3101 - val_mae: 4.1502\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.6505 - mae: 4.2899 - val_loss: 24.7101 - val_mae: 3.9208\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.9689 - mae: 4.0616 - val_loss: 22.8247 - val_mae: 3.7289\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 28.9789 - mae: 3.8831 - val_loss: 21.6053 - val_mae: 3.5980\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.4431 - mae: 3.7503 - val_loss: 20.6911 - val_mae: 3.4917\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.2600 - mae: 3.6739 - val_loss: 20.0999 - val_mae: 3.4356\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.2203 - mae: 3.5926 - val_loss: 19.4798 - val_mae: 3.3953\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.4700 - mae: 3.5257 - val_loss: 18.9319 - val_mae: 3.3408\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.6453 - mae: 3.4591 - val_loss: 18.4859 - val_mae: 3.3112\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.9336 - mae: 3.4173 - val_loss: 18.1779 - val_mae: 3.2755\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.2255 - mae: 3.3709 - val_loss: 17.7960 - val_mae: 3.2411\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.6419 - mae: 3.3176 - val_loss: 17.3115 - val_mae: 3.1872\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.0717 - mae: 3.2602 - val_loss: 16.7806 - val_mae: 3.1189\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.6284 - mae: 3.2072 - val_loss: 16.3533 - val_mae: 3.0649\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.1017 - mae: 3.1615 - val_loss: 16.0927 - val_mae: 3.0341\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 19.6044 - mae: 3.1326 - val_loss: 15.9962 - val_mae: 3.0264\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 19.1634 - mae: 3.1073 - val_loss: 15.9255 - val_mae: 2.9950\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 18.7154 - mae: 3.0787 - val_loss: 15.9135 - val_mae: 2.9827\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 18.3343 - mae: 3.0476 - val_loss: 15.5122 - val_mae: 2.9274\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.9694 - mae: 2.9911 - val_loss: 14.9045 - val_mae: 2.8679\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.6661 - mae: 2.9580 - val_loss: 14.7251 - val_mae: 2.8324\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.2270 - mae: 2.9254 - val_loss: 14.7324 - val_mae: 2.8319\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.9773 - mae: 2.9101 - val_loss: 14.6168 - val_mae: 2.8137\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.7059 - mae: 2.8882 - val_loss: 14.5823 - val_mae: 2.8198\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.4234 - mae: 2.8617 - val_loss: 14.3074 - val_mae: 2.7840\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.1793 - mae: 2.8397 - val_loss: 14.2441 - val_mae: 2.7528\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.9236 - mae: 2.8285 - val_loss: 14.1678 - val_mae: 2.7271\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.6782 - mae: 2.8060 - val_loss: 13.9486 - val_mae: 2.7129\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.6100 - mae: 2.7994 - val_loss: 13.9140 - val_mae: 2.7336\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.2711 - mae: 2.7700 - val_loss: 13.7682 - val_mae: 2.6976\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.0548 - mae: 2.7507 - val_loss: 13.5259 - val_mae: 2.6581\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.9159 - mae: 2.7237 - val_loss: 13.3958 - val_mae: 2.6536\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.6996 - mae: 2.7117 - val_loss: 13.5680 - val_mae: 2.6521\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.4659 - mae: 2.7086 - val_loss: 13.5041 - val_mae: 2.6456\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.3266 - mae: 2.6979 - val_loss: 13.5152 - val_mae: 2.6522\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.2193 - mae: 2.6818 - val_loss: 13.4403 - val_mae: 2.6413\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 14.0605 - mae: 2.6682 - val_loss: 13.4041 - val_mae: 2.6281\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.9945 - mae: 2.6704 - val_loss: 13.9432 - val_mae: 2.6942\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.6978 - mae: 2.6625 - val_loss: 13.6175 - val_mae: 2.6575\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.5891 - mae: 2.6387 - val_loss: 13.2135 - val_mae: 2.6193\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 13.4381 - mae: 2.6010 - val_loss: 12.8991 - val_mae: 2.5990\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.3191 - mae: 2.5840 - val_loss: 12.8189 - val_mae: 2.5875\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.1655 - mae: 2.5811 - val_loss: 13.0631 - val_mae: 2.6076\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.9971 - mae: 2.5759 - val_loss: 13.1953 - val_mae: 2.6223\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.9087 - mae: 2.5847 - val_loss: 13.4469 - val_mae: 2.6637\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.8691 - mae: 2.5823 - val_loss: 13.2013 - val_mae: 2.6395\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.7851 - mae: 2.5605 - val_loss: 12.8599 - val_mae: 2.5849\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.6102 - mae: 2.5385 - val_loss: 12.8420 - val_mae: 2.5921\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.5680 - mae: 2.5400 - val_loss: 13.2281 - val_mae: 2.6466\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 12.4158 - mae: 2.5425 - val_loss: 13.0605 - val_mae: 2.6132\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.3013 - mae: 2.5100 - val_loss: 12.6975 - val_mae: 2.5681\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.3335 - mae: 2.5180 - val_loss: 12.6135 - val_mae: 2.5414\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.1789 - mae: 2.5027 - val_loss: 12.8155 - val_mae: 2.5876\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.1217 - mae: 2.4965 - val_loss: 12.5550 - val_mae: 2.5560\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.0822 - mae: 2.5014 - val_loss: 12.7869 - val_mae: 2.5748\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.8659 - mae: 2.4746 - val_loss: 12.4820 - val_mae: 2.5426\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.7952 - mae: 2.4545 - val_loss: 12.3509 - val_mae: 2.5229\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 11.6649 - mae: 2.4493 - val_loss: 12.5969 - val_mae: 2.5652\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.6111 - mae: 2.4523 - val_loss: 12.6357 - val_mae: 2.5697\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.5486 - mae: 2.4485 - val_loss: 12.5468 - val_mae: 2.5564\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.4464 - mae: 2.4438 - val_loss: 12.8217 - val_mae: 2.5913\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.3914 - mae: 2.4342 - val_loss: 12.6900 - val_mae: 2.5682\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.3287 - mae: 2.4294 - val_loss: 12.9617 - val_mae: 2.6107\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.2344 - mae: 2.4299 - val_loss: 12.7777 - val_mae: 2.5828\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.1473 - mae: 2.4139 - val_loss: 12.5356 - val_mae: 2.5459\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.1107 - mae: 2.4017 - val_loss: 12.5536 - val_mae: 2.5559\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.0374 - mae: 2.3925 - val_loss: 12.5703 - val_mae: 2.5565\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.9493 - mae: 2.3865 - val_loss: 12.4797 - val_mae: 2.5418\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.8810 - mae: 2.3749 - val_loss: 12.5304 - val_mae: 2.5450\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.8031 - mae: 2.3755 - val_loss: 12.7671 - val_mae: 2.5833\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.7597 - mae: 2.3777 - val_loss: 12.8437 - val_mae: 2.5870\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.7087 - mae: 2.3681 - val_loss: 12.6464 - val_mae: 2.5659\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6450 - mae: 2.3640 - val_loss: 12.7568 - val_mae: 2.5737\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.5595 - mae: 2.3536 - val_loss: 12.6666 - val_mae: 2.5601\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.4697 - mae: 2.3427 - val_loss: 12.4820 - val_mae: 2.5496\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.4554 - mae: 2.3422 - val_loss: 12.6000 - val_mae: 2.5566\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3803 - mae: 2.3288 - val_loss: 12.3579 - val_mae: 2.5349\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3125 - mae: 2.3218 - val_loss: 12.6102 - val_mae: 2.5625\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.2279 - mae: 2.3188 - val_loss: 12.4719 - val_mae: 2.5441\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.2171 - mae: 2.3090 - val_loss: 12.3875 - val_mae: 2.5371\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.1369 - mae: 2.3020 - val_loss: 12.5968 - val_mae: 2.5608\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.0399 - mae: 2.2988 - val_loss: 12.8193 - val_mae: 2.5780\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.0326 - mae: 2.2967 - val_loss: 12.7537 - val_mae: 2.5723\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.9597 - mae: 2.2879 - val_loss: 12.6521 - val_mae: 2.5680\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.9468 - mae: 2.2836 - val_loss: 12.5767 - val_mae: 2.5560\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8374 - mae: 2.2695 - val_loss: 12.3298 - val_mae: 2.5294\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.8316 - mae: 2.2641 - val_loss: 12.4466 - val_mae: 2.5347\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7937 - mae: 2.2656 - val_loss: 12.4118 - val_mae: 2.5432\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.7217 - mae: 2.2608 - val_loss: 12.4429 - val_mae: 2.5457\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7496 - mae: 2.2785 - val_loss: 12.5883 - val_mae: 2.5655\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6364 - mae: 2.2505 - val_loss: 12.8322 - val_mae: 2.5771\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.6334 - mae: 2.2520 - val_loss: 12.7592 - val_mae: 2.5690\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.5327 - mae: 2.2416 - val_loss: 12.7032 - val_mae: 2.5646\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.4979 - mae: 2.2443 - val_loss: 12.9945 - val_mae: 2.6045\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.4899 - mae: 2.2360 - val_loss: 12.6319 - val_mae: 2.5521\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3633 - mae: 2.2237 - val_loss: 12.7700 - val_mae: 2.5652\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.3113 - mae: 2.2151 - val_loss: 12.7985 - val_mae: 2.5736\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.2624 - mae: 2.2112 - val_loss: 12.7863 - val_mae: 2.5741\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.2680 - mae: 2.2290 - val_loss: 13.2249 - val_mae: 2.6335\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9.2191 - mae: 2.2230 - val_loss: 12.9185 - val_mae: 2.5933\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.1346 - mae: 2.2024 - val_loss: 12.6456 - val_mae: 2.5590\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.1559 - mae: 2.2039 - val_loss: 12.6432 - val_mae: 2.5637\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.0911 - mae: 2.1875 - val_loss: 12.4050 - val_mae: 2.5398\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.0634 - mae: 2.1823 - val_loss: 12.6139 - val_mae: 2.5543\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.9803 - mae: 2.1774 - val_loss: 12.8284 - val_mae: 2.5735\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.9237 - mae: 2.1734 - val_loss: 12.8069 - val_mae: 2.5754\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.8917 - mae: 2.1730 - val_loss: 12.8038 - val_mae: 2.5769\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.8422 - mae: 2.1700 - val_loss: 12.8489 - val_mae: 2.5759\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.8389 - mae: 2.1643 - val_loss: 12.7570 - val_mae: 2.5665\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7754 - mae: 2.1614 - val_loss: 13.0139 - val_mae: 2.5895\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.7941 - mae: 2.1731 - val_loss: 12.9763 - val_mae: 2.6013\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6784 - mae: 2.1504 - val_loss: 12.7970 - val_mae: 2.5692\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6779 - mae: 2.1467 - val_loss: 12.5925 - val_mae: 2.5537\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6131 - mae: 2.1307 - val_loss: 12.6936 - val_mae: 2.5579\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5582 - mae: 2.1337 - val_loss: 12.9123 - val_mae: 2.5840\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5416 - mae: 2.1315 - val_loss: 12.8302 - val_mae: 2.5686\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5249 - mae: 2.1253 - val_loss: 12.8660 - val_mae: 2.5687\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.4540 - mae: 2.1188 - val_loss: 12.8012 - val_mae: 2.5805\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.4208 - mae: 2.1220 - val_loss: 12.8596 - val_mae: 2.5726\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3950 - mae: 2.1198 - val_loss: 12.8839 - val_mae: 2.5778\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3698 - mae: 2.1091 - val_loss: 12.6459 - val_mae: 2.5580\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3680 - mae: 2.1014 - val_loss: 12.6234 - val_mae: 2.5449\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2764 - mae: 2.0974 - val_loss: 12.9292 - val_mae: 2.5749\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.2511 - mae: 2.1024 - val_loss: 12.9570 - val_mae: 2.5762\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.2133 - mae: 2.1014 - val_loss: 12.9674 - val_mae: 2.5897\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1441 - mae: 2.0906 - val_loss: 12.8577 - val_mae: 2.5688\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.1034 - mae: 2.0811 - val_loss: 12.5838 - val_mae: 2.5429\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0792 - mae: 2.0675 - val_loss: 12.6048 - val_mae: 2.5429\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0717 - mae: 2.0688 - val_loss: 12.5731 - val_mae: 2.5486\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1263 - mae: 2.0824 - val_loss: 12.9881 - val_mae: 2.5794\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0100 - mae: 2.0768 - val_loss: 12.7947 - val_mae: 2.5736\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9438 - mae: 2.0602 - val_loss: 12.4927 - val_mae: 2.5392\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9454 - mae: 2.0682 - val_loss: 12.8210 - val_mae: 2.5637\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.0093 - mae: 2.0629 - val_loss: 12.5279 - val_mae: 2.5369\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8470 - mae: 2.0484 - val_loss: 12.9460 - val_mae: 2.5811\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8920 - mae: 2.0649 - val_loss: 12.8363 - val_mae: 2.5784\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8179 - mae: 2.0415 - val_loss: 12.4241 - val_mae: 2.5284\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8412 - mae: 2.0289 - val_loss: 12.6377 - val_mae: 2.5377\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.7545 - mae: 2.0358 - val_loss: 12.9390 - val_mae: 2.5816\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.6683 - mae: 2.0301 - val_loss: 12.7855 - val_mae: 2.5627\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6451 - mae: 2.0206 - val_loss: 12.6562 - val_mae: 2.5532\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.7027 - mae: 2.0198 - val_loss: 12.4403 - val_mae: 2.5294\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6241 - mae: 2.0233 - val_loss: 12.6311 - val_mae: 2.5513\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.5192 - mae: 2.0099 - val_loss: 12.7126 - val_mae: 2.5421\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.5559 - mae: 2.0112 - val_loss: 12.7616 - val_mae: 2.5458\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4567 - mae: 1.9919 - val_loss: 12.5170 - val_mae: 2.5402\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4997 - mae: 2.0006 - val_loss: 12.6869 - val_mae: 2.5502\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.4179 - mae: 1.9946 - val_loss: 12.5660 - val_mae: 2.5417\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.5070 - mae: 2.0081 - val_loss: 12.7493 - val_mae: 2.5543\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.3418 - mae: 1.9866 - val_loss: 12.5069 - val_mae: 2.5197\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3331 - mae: 1.9730 - val_loss: 12.5576 - val_mae: 2.5242\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.2750 - mae: 1.9735 - val_loss: 12.7168 - val_mae: 2.5312\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2523 - mae: 1.9788 - val_loss: 12.5899 - val_mae: 2.5291\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2062 - mae: 1.9668 - val_loss: 12.5302 - val_mae: 2.5318\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.1880 - mae: 1.9518 - val_loss: 12.4587 - val_mae: 2.5230\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1519 - mae: 1.9366 - val_loss: 12.6451 - val_mae: 2.5309\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1341 - mae: 1.9494 - val_loss: 12.8937 - val_mae: 2.5645\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1086 - mae: 1.9571 - val_loss: 12.6350 - val_mae: 2.5381\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0263 - mae: 1.9382 - val_loss: 12.5467 - val_mae: 2.5312\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0159 - mae: 1.9389 - val_loss: 12.6545 - val_mae: 2.5347\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.0396 - mae: 1.9193 - val_loss: 12.5146 - val_mae: 2.5138\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.9300 - mae: 1.9196 - val_loss: 12.7033 - val_mae: 2.5390\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9093 - mae: 1.9251 - val_loss: 12.4873 - val_mae: 2.5261\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8608 - mae: 1.9189 - val_loss: 12.6881 - val_mae: 2.5317\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8447 - mae: 1.9201 - val_loss: 12.6217 - val_mae: 2.5306\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7851 - mae: 1.9071 - val_loss: 12.6233 - val_mae: 2.5296\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7825 - mae: 1.9008 - val_loss: 12.2835 - val_mae: 2.4949\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7656 - mae: 1.8973 - val_loss: 12.6786 - val_mae: 2.5205\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.7309 - mae: 1.8946 - val_loss: 12.4964 - val_mae: 2.5177\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7072 - mae: 1.8823 - val_loss: 12.3801 - val_mae: 2.5005\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.6459 - mae: 1.8715 - val_loss: 12.3885 - val_mae: 2.5046\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6342 - mae: 1.8828 - val_loss: 12.6463 - val_mae: 2.5363\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.7054 - mae: 1.8891 - val_loss: 12.5126 - val_mae: 2.5196\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.6374 - mae: 1.8816 - val_loss: 12.7200 - val_mae: 2.5548\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6055 - mae: 1.8667 - val_loss: 12.4193 - val_mae: 2.5050\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5183 - mae: 1.8624 - val_loss: 12.9506 - val_mae: 2.5756\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4902 - mae: 1.8627 - val_loss: 12.7016 - val_mae: 2.5238\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4117 - mae: 1.8470 - val_loss: 12.5293 - val_mae: 2.5201\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3870 - mae: 1.8474 - val_loss: 12.4892 - val_mae: 2.5335\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3349 - mae: 1.8489 - val_loss: 12.6395 - val_mae: 2.5377\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.3206 - mae: 1.8471 - val_loss: 12.3752 - val_mae: 2.5044\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2742 - mae: 1.8354 - val_loss: 12.6231 - val_mae: 2.5227\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2713 - mae: 1.8394 - val_loss: 12.3405 - val_mae: 2.5062\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2449 - mae: 1.8227 - val_loss: 12.3086 - val_mae: 2.4998\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2407 - mae: 1.8278 - val_loss: 12.4746 - val_mae: 2.5178\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1640 - mae: 1.8306 - val_loss: 12.7593 - val_mae: 2.5572\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.2075 - mae: 1.8349 - val_loss: 12.6376 - val_mae: 2.5353\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1058 - mae: 1.8076 - val_loss: 12.4943 - val_mae: 2.5185\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0242 - mae: 1.7944 - val_loss: 12.4555 - val_mae: 2.5213\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0922 - mae: 1.8161 - val_loss: 12.6750 - val_mae: 2.5412\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9656 - mae: 1.7880 - val_loss: 12.2126 - val_mae: 2.5018\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0557 - mae: 1.7989 - val_loss: 12.4386 - val_mae: 2.5017\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0135 - mae: 1.7975 - val_loss: 12.4693 - val_mae: 2.5292\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0098 - mae: 1.7966 - val_loss: 12.3537 - val_mae: 2.5103\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8858 - mae: 1.7768 - val_loss: 12.5571 - val_mae: 2.5285\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.8439 - mae: 1.7668 - val_loss: 12.3628 - val_mae: 2.4989\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8644 - mae: 1.7678 - val_loss: 12.3059 - val_mae: 2.5075\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7853 - mae: 1.7581 - val_loss: 12.2675 - val_mae: 2.5023\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7806 - mae: 1.7448 - val_loss: 12.1313 - val_mae: 2.4880\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7257 - mae: 1.7513 - val_loss: 12.4268 - val_mae: 2.5236\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7152 - mae: 1.7539 - val_loss: 12.3112 - val_mae: 2.5058\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7380 - mae: 1.7352 - val_loss: 11.9771 - val_mae: 2.4750\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6192 - mae: 1.7421 - val_loss: 12.7402 - val_mae: 2.5854\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6638 - mae: 1.7603 - val_loss: 12.3224 - val_mae: 2.5304\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5458 - mae: 1.7237 - val_loss: 12.2232 - val_mae: 2.4962\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.6038 - mae: 1.7345 - val_loss: 12.3302 - val_mae: 2.5091\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.5383 - mae: 1.7304 - val_loss: 12.4611 - val_mae: 2.5486\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4551 - mae: 1.7200 - val_loss: 11.9562 - val_mae: 2.4799\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4850 - mae: 1.7068 - val_loss: 12.0253 - val_mae: 2.4794\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3750 - mae: 1.6866 - val_loss: 12.1121 - val_mae: 2.4979\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3926 - mae: 1.6977 - val_loss: 12.1259 - val_mae: 2.5013\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3452 - mae: 1.6911 - val_loss: 11.8648 - val_mae: 2.4634\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3522 - mae: 1.6849 - val_loss: 11.9214 - val_mae: 2.4729\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3402 - mae: 1.6828 - val_loss: 12.0669 - val_mae: 2.5033\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2962 - mae: 1.6861 - val_loss: 12.0335 - val_mae: 2.5013\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2988 - mae: 1.6841 - val_loss: 11.8801 - val_mae: 2.4762\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2923 - mae: 1.6761 - val_loss: 11.9975 - val_mae: 2.4741\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2241 - mae: 1.6729 - val_loss: 12.0656 - val_mae: 2.4904\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1935 - mae: 1.6602 - val_loss: 11.9096 - val_mae: 2.4925\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.1840 - mae: 1.6572 - val_loss: 11.6898 - val_mae: 2.4708\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0917 - mae: 1.6419 - val_loss: 11.7257 - val_mae: 2.4706\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1095 - mae: 1.6328 - val_loss: 11.7281 - val_mae: 2.4581\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0759 - mae: 1.6417 - val_loss: 11.9709 - val_mae: 2.4840\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0606 - mae: 1.6384 - val_loss: 11.8383 - val_mae: 2.4609\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0218 - mae: 1.6222 - val_loss: 11.7096 - val_mae: 2.4506\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0498 - mae: 1.6306 - val_loss: 11.9207 - val_mae: 2.4731\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9436 - mae: 1.6229 - val_loss: 11.8096 - val_mae: 2.4834\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0102 - mae: 1.6417 - val_loss: 11.7994 - val_mae: 2.4658\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9899 - mae: 1.6102 - val_loss: 11.5392 - val_mae: 2.4391\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9545 - mae: 1.6367 - val_loss: 12.1672 - val_mae: 2.5200\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8496 - mae: 1.6066 - val_loss: 11.5749 - val_mae: 2.4357\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8206 - mae: 1.5906 - val_loss: 11.8622 - val_mae: 2.4911\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.8452 - mae: 1.6098 - val_loss: 11.5185 - val_mae: 2.4473\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8601 - mae: 1.6005 - val_loss: 11.3986 - val_mae: 2.4271\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7643 - mae: 1.5711 - val_loss: 11.4804 - val_mae: 2.4382\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7880 - mae: 1.6012 - val_loss: 11.9071 - val_mae: 2.4875\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7481 - mae: 1.5844 - val_loss: 11.6005 - val_mae: 2.4356\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7822 - mae: 1.6003 - val_loss: 11.8159 - val_mae: 2.4711\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.6529 - mae: 1.5695 - val_loss: 11.6330 - val_mae: 2.4492\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6836 - mae: 1.5793 - val_loss: 11.7104 - val_mae: 2.4715\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6575 - mae: 1.5808 - val_loss: 11.4828 - val_mae: 2.4398\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7917 - mae: 1.5908 - val_loss: 11.4293 - val_mae: 2.4236\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6323 - mae: 1.5775 - val_loss: 11.6815 - val_mae: 2.4625\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5483 - mae: 1.5613 - val_loss: 11.3936 - val_mae: 2.4149\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6077 - mae: 1.5413 - val_loss: 11.4420 - val_mae: 2.4122\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4920 - mae: 1.5332 - val_loss: 11.6997 - val_mae: 2.4605\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.4965 - mae: 1.5435 - val_loss: 11.3938 - val_mae: 2.4194\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4510 - mae: 1.5306 - val_loss: 11.2004 - val_mae: 2.3927\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4559 - mae: 1.5355 - val_loss: 11.4397 - val_mae: 2.4333\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4252 - mae: 1.5268 - val_loss: 11.5898 - val_mae: 2.4446\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4350 - mae: 1.5295 - val_loss: 11.3246 - val_mae: 2.3988\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3231 - mae: 1.4975 - val_loss: 11.2928 - val_mae: 2.4183\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3556 - mae: 1.4961 - val_loss: 11.3722 - val_mae: 2.4321\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.3360 - mae: 1.5176 - val_loss: 11.4780 - val_mae: 2.4405\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3307 - mae: 1.4970 - val_loss: 11.0144 - val_mae: 2.3743\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2649 - mae: 1.5037 - val_loss: 11.3682 - val_mae: 2.4321\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3335 - mae: 1.5178 - val_loss: 11.2244 - val_mae: 2.4031\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2360 - mae: 1.4937 - val_loss: 11.3971 - val_mae: 2.4139\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2906 - mae: 1.4922 - val_loss: 11.3521 - val_mae: 2.4033\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2155 - mae: 1.4846 - val_loss: 11.4334 - val_mae: 2.4158\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2230 - mae: 1.5039 - val_loss: 11.2069 - val_mae: 2.3920\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.1642 - mae: 1.4616 - val_loss: 11.2227 - val_mae: 2.3987\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1416 - mae: 1.4684 - val_loss: 11.0802 - val_mae: 2.3830\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0986 - mae: 1.4680 - val_loss: 11.1492 - val_mae: 2.3879\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1314 - mae: 1.4771 - val_loss: 11.2318 - val_mae: 2.4002\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0716 - mae: 1.4414 - val_loss: 11.0964 - val_mae: 2.3773\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0916 - mae: 1.4564 - val_loss: 11.1201 - val_mae: 2.3930\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0348 - mae: 1.4605 - val_loss: 11.1469 - val_mae: 2.3922\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9957 - mae: 1.4336 - val_loss: 11.1603 - val_mae: 2.3834\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0521 - mae: 1.4376 - val_loss: 11.0453 - val_mae: 2.3857\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0218 - mae: 1.4444 - val_loss: 11.1989 - val_mae: 2.4251\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0227 - mae: 1.4386 - val_loss: 10.8215 - val_mae: 2.3613\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9455 - mae: 1.4185 - val_loss: 11.0648 - val_mae: 2.4003\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9829 - mae: 1.4428 - val_loss: 11.1733 - val_mae: 2.3978\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.0440 - mae: 1.4581 - val_loss: 11.0136 - val_mae: 2.3803\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9534 - mae: 1.4375 - val_loss: 10.8793 - val_mae: 2.3707\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.9128 - mae: 1.4194 - val_loss: 11.0564 - val_mae: 2.3898\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8889 - mae: 1.4240 - val_loss: 10.9642 - val_mae: 2.3755\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8555 - mae: 1.4100 - val_loss: 11.1477 - val_mae: 2.4023\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.8058 - mae: 1.3948 - val_loss: 10.8295 - val_mae: 2.3635\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8738 - mae: 1.4355 - val_loss: 10.8759 - val_mae: 2.3931\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.7913 - mae: 1.3912 - val_loss: 10.8521 - val_mae: 2.3664\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.8066 - mae: 1.4171 - val_loss: 11.4276 - val_mae: 2.4531\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9165 - mae: 1.4326 - val_loss: 10.7771 - val_mae: 2.3580\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8796 - mae: 1.4102 - val_loss: 11.2025 - val_mae: 2.4596\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8687 - mae: 1.4322 - val_loss: 10.9573 - val_mae: 2.4039\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.6672 - mae: 1.3708 - val_loss: 11.0843 - val_mae: 2.4138\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7055939.0000 - mae: 2635.2490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EO4kVsAUgpr",
        "outputId": "657c0839-7311-4c87-bf85-8459e50f9b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2091.4808044433594"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-Fold를 사용한 모델 성능평가"
      ],
      "metadata": {
        "id": "63moefrNT98D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 3-Fold 로 나눠서 검증데이터셋 사용하여 학습\n",
        "k = 5\n",
        "\n",
        "kfold = KFold(n_splits=k)\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape=(13,)))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1)) # 연속적인 값 -> linear -> defalut 가 linear 함수임, activation=linear\n",
        "\n",
        "  model.compile(optimizer='adam', loss ='mse', metrics=['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(KFold)의 평가 정보를 담는 리스트 선언\n",
        "mae_list =[]\n",
        "\n",
        "# K번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "\n",
        "  # 학습데이터, 검증데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기\n",
        "  model.fit(X_train_fold, y_train_fold, epochs=300, validation_data=(X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1raC7-OaT5fg",
        "outputId": "42512cd1-1618-44d4-d67c-861821f7c216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 13ms/step - loss: 592.7110 - mae: 22.4373 - val_loss: 541.9431 - val_mae: 21.6764\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 565.7013 - mae: 21.8387 - val_loss: 517.8642 - val_mae: 21.1090\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 535.0556 - mae: 21.1541 - val_loss: 489.5283 - val_mae: 20.4241\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 498.9878 - mae: 20.3098 - val_loss: 454.4507 - val_mae: 19.5478\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 454.3457 - mae: 19.2481 - val_loss: 410.8806 - val_mae: 18.4260\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 397.7724 - mae: 17.8407 - val_loss: 357.1427 - val_mae: 16.9898\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 332.6931 - mae: 16.0646 - val_loss: 297.3926 - val_mae: 15.2057\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 262.8950 - mae: 13.9511 - val_loss: 236.2710 - val_mae: 13.0770\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 196.7586 - mae: 11.7351 - val_loss: 179.1733 - val_mae: 10.9293\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 141.5461 - mae: 9.5864 - val_loss: 132.7185 - val_mae: 9.1096\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 104.5499 - mae: 7.9877 - val_loss: 103.1955 - val_mae: 7.9964\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 82.8612 - mae: 7.0712 - val_loss: 84.3766 - val_mae: 7.1402\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 68.6540 - mae: 6.4332 - val_loss: 68.8682 - val_mae: 6.3260\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.2233 - mae: 5.8675 - val_loss: 57.6934 - val_mae: 5.6582\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 48.3643 - mae: 5.3797 - val_loss: 50.4507 - val_mae: 5.1787\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.7176 - mae: 4.9621 - val_loss: 44.6169 - val_mae: 4.7014\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 36.8503 - mae: 4.6221 - val_loss: 40.0933 - val_mae: 4.4267\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 33.0143 - mae: 4.3458 - val_loss: 36.6654 - val_mae: 4.2980\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 30.4934 - mae: 4.1282 - val_loss: 33.6298 - val_mae: 4.1996\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.8717 - mae: 3.9293 - val_loss: 31.1939 - val_mae: 4.0187\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.6767 - mae: 3.7199 - val_loss: 29.8444 - val_mae: 3.9175\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.1446 - mae: 3.5649 - val_loss: 29.0703 - val_mae: 3.8377\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 23.1566 - mae: 3.4663 - val_loss: 28.3194 - val_mae: 3.7834\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 22.1685 - mae: 3.3769 - val_loss: 27.6255 - val_mae: 3.7323\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.2995 - mae: 3.2914 - val_loss: 27.1486 - val_mae: 3.6832\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.5569 - mae: 3.2143 - val_loss: 26.7910 - val_mae: 3.6396\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.8450 - mae: 3.1343 - val_loss: 26.5461 - val_mae: 3.6169\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 19.1786 - mae: 3.0697 - val_loss: 26.1657 - val_mae: 3.6010\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.5958 - mae: 3.0277 - val_loss: 25.9286 - val_mae: 3.6267\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 18.1118 - mae: 3.0035 - val_loss: 25.6037 - val_mae: 3.6178\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 17.6659 - mae: 2.9664 - val_loss: 25.4630 - val_mae: 3.6297\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.0938 - mae: 2.9057 - val_loss: 25.5518 - val_mae: 3.6523\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.7440 - mae: 2.8738 - val_loss: 25.0853 - val_mae: 3.6421\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.2472 - mae: 2.8476 - val_loss: 24.9785 - val_mae: 3.6446\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.8682 - mae: 2.8059 - val_loss: 24.6699 - val_mae: 3.6188\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.5638 - mae: 2.7761 - val_loss: 24.4134 - val_mae: 3.5998\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.2345 - mae: 2.7407 - val_loss: 24.2634 - val_mae: 3.5748\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0002 - mae: 2.7055 - val_loss: 23.9236 - val_mae: 3.5507\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.7717 - mae: 2.6796 - val_loss: 23.7025 - val_mae: 3.5311\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.4386 - mae: 2.6439 - val_loss: 23.3766 - val_mae: 3.5022\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.1751 - mae: 2.6177 - val_loss: 22.8821 - val_mae: 3.4763\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.0507 - mae: 2.6764 - val_loss: 22.1905 - val_mae: 3.4538\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.0334 - mae: 2.6998 - val_loss: 21.9881 - val_mae: 3.4466\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.4608 - mae: 2.6063 - val_loss: 22.3087 - val_mae: 3.4601\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.2424 - mae: 2.5466 - val_loss: 22.4681 - val_mae: 3.4640\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.0792 - mae: 2.5348 - val_loss: 22.1781 - val_mae: 3.4506\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.9950 - mae: 2.5304 - val_loss: 21.9125 - val_mae: 3.4124\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8022 - mae: 2.5175 - val_loss: 21.5166 - val_mae: 3.3886\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.5693 - mae: 2.5087 - val_loss: 21.3909 - val_mae: 3.3973\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7723 - mae: 2.5551 - val_loss: 20.6925 - val_mae: 3.3568\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5405 - mae: 2.5447 - val_loss: 20.7345 - val_mae: 3.3602\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4433 - mae: 2.4888 - val_loss: 21.1300 - val_mae: 3.3686\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.0908 - mae: 2.4508 - val_loss: 21.5439 - val_mae: 3.4296\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.8657 - mae: 2.4367 - val_loss: 21.0648 - val_mae: 3.3888\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7617 - mae: 2.4228 - val_loss: 20.7417 - val_mae: 3.3490\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5316 - mae: 2.3991 - val_loss: 21.0174 - val_mae: 3.3826\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4993 - mae: 2.3831 - val_loss: 21.0518 - val_mae: 3.3835\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3340 - mae: 2.3678 - val_loss: 20.6184 - val_mae: 3.3520\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.2244 - mae: 2.3747 - val_loss: 20.4317 - val_mae: 3.3456\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.1535 - mae: 2.3667 - val_loss: 20.3221 - val_mae: 3.3188\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.0330 - mae: 2.3431 - val_loss: 20.5387 - val_mae: 3.3462\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.9991 - mae: 2.3309 - val_loss: 20.6156 - val_mae: 3.3440\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.8750 - mae: 2.3072 - val_loss: 20.1286 - val_mae: 3.2992\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7279 - mae: 2.3204 - val_loss: 19.8413 - val_mae: 3.2939\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.7187 - mae: 2.3300 - val_loss: 19.7171 - val_mae: 3.2725\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.5738 - mae: 2.2890 - val_loss: 19.9625 - val_mae: 3.2771\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.5889 - mae: 2.2894 - val_loss: 19.7432 - val_mae: 3.2648\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 10.4185 - mae: 2.2567 - val_loss: 19.7183 - val_mae: 3.2365\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4138 - mae: 2.2531 - val_loss: 19.4422 - val_mae: 3.2153\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3035 - mae: 2.2526 - val_loss: 19.5104 - val_mae: 3.2198\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3053 - mae: 2.2524 - val_loss: 19.3544 - val_mae: 3.1985\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.2553 - mae: 2.2404 - val_loss: 19.6513 - val_mae: 3.2235\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.0587 - mae: 2.2308 - val_loss: 19.2598 - val_mae: 3.2205\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.9299 - mae: 2.2476 - val_loss: 18.7323 - val_mae: 3.1985\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.8824 - mae: 2.2417 - val_loss: 18.7257 - val_mae: 3.1767\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.7973 - mae: 2.2235 - val_loss: 18.7854 - val_mae: 3.1814\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6894 - mae: 2.2075 - val_loss: 19.0199 - val_mae: 3.1981\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6577 - mae: 2.2007 - val_loss: 18.9610 - val_mae: 3.1897\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6464 - mae: 2.2023 - val_loss: 18.7794 - val_mae: 3.1897\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.5377 - mae: 2.1928 - val_loss: 18.5721 - val_mae: 3.1618\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.5450 - mae: 2.1946 - val_loss: 18.4206 - val_mae: 3.1442\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4604 - mae: 2.1826 - val_loss: 18.6712 - val_mae: 3.1714\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.6422 - mae: 2.1686 - val_loss: 19.2285 - val_mae: 3.1874\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4843 - mae: 2.1668 - val_loss: 18.6212 - val_mae: 3.1769\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3566 - mae: 2.1739 - val_loss: 18.1631 - val_mae: 3.1511\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.2516 - mae: 2.1736 - val_loss: 18.2882 - val_mae: 3.1528\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1742 - mae: 2.1541 - val_loss: 18.2695 - val_mae: 3.1329\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.1250 - mae: 2.1406 - val_loss: 17.9738 - val_mae: 3.1220\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1535 - mae: 2.1680 - val_loss: 17.9481 - val_mae: 3.1394\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0512 - mae: 2.1693 - val_loss: 18.0604 - val_mae: 3.1369\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9581 - mae: 2.1393 - val_loss: 17.9852 - val_mae: 3.1109\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9103 - mae: 2.1300 - val_loss: 17.9083 - val_mae: 3.1165\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8541 - mae: 2.1256 - val_loss: 17.8765 - val_mae: 3.1096\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9351 - mae: 2.1255 - val_loss: 18.4894 - val_mae: 3.1520\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9739 - mae: 2.1352 - val_loss: 17.7893 - val_mae: 3.1165\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8331 - mae: 2.1208 - val_loss: 18.0502 - val_mae: 3.1265\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7785 - mae: 2.1181 - val_loss: 18.3210 - val_mae: 3.1499\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8001 - mae: 2.1027 - val_loss: 18.2959 - val_mae: 3.1132\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7157 - mae: 2.0991 - val_loss: 17.9530 - val_mae: 3.1431\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6066 - mae: 2.1113 - val_loss: 17.7318 - val_mae: 3.1085\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5715 - mae: 2.0975 - val_loss: 17.5786 - val_mae: 3.0831\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6900 - mae: 2.1380 - val_loss: 17.5727 - val_mae: 3.0880\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5263 - mae: 2.1120 - val_loss: 18.1224 - val_mae: 3.1263\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5757 - mae: 2.0981 - val_loss: 18.2056 - val_mae: 3.1152\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4317 - mae: 2.0801 - val_loss: 17.6381 - val_mae: 3.0872\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3097 - mae: 2.0824 - val_loss: 17.5594 - val_mae: 3.1164\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3122 - mae: 2.0884 - val_loss: 17.6273 - val_mae: 3.1283\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2667 - mae: 2.0954 - val_loss: 17.3440 - val_mae: 3.1074\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.2457 - mae: 2.0857 - val_loss: 17.7172 - val_mae: 3.1053\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.1881 - mae: 2.0663 - val_loss: 17.9290 - val_mae: 3.1368\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1542 - mae: 2.0527 - val_loss: 17.8418 - val_mae: 3.1096\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.1205 - mae: 2.0482 - val_loss: 17.5311 - val_mae: 3.0666\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0163 - mae: 2.0301 - val_loss: 17.6840 - val_mae: 3.0895\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0376 - mae: 2.0380 - val_loss: 17.5406 - val_mae: 3.0816\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.9456 - mae: 2.0203 - val_loss: 16.9491 - val_mae: 3.0317\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.1500 - mae: 2.0657 - val_loss: 16.6865 - val_mae: 3.0420\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.9727 - mae: 2.0416 - val_loss: 17.4194 - val_mae: 3.0789\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8307 - mae: 2.0148 - val_loss: 17.5647 - val_mae: 3.1003\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8991 - mae: 2.0448 - val_loss: 17.6291 - val_mae: 3.1005\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.7113 - mae: 2.0143 - val_loss: 16.9565 - val_mae: 3.0564\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8993 - mae: 2.0437 - val_loss: 16.8047 - val_mae: 3.0503\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.7041 - mae: 2.0066 - val_loss: 17.2505 - val_mae: 3.0687\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.7726 - mae: 2.0042 - val_loss: 17.8359 - val_mae: 3.0710\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.7262 - mae: 1.9983 - val_loss: 17.2001 - val_mae: 3.0599\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5716 - mae: 1.9837 - val_loss: 17.0545 - val_mae: 3.0572\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5426 - mae: 1.9920 - val_loss: 16.8223 - val_mae: 3.0170\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4829 - mae: 1.9819 - val_loss: 16.8872 - val_mae: 3.0344\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4986 - mae: 1.9784 - val_loss: 16.8368 - val_mae: 3.0230\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4318 - mae: 1.9662 - val_loss: 16.7254 - val_mae: 3.0362\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3597 - mae: 1.9683 - val_loss: 16.7972 - val_mae: 3.0289\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.3497 - mae: 1.9637 - val_loss: 16.7234 - val_mae: 2.9961\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.3621 - mae: 1.9706 - val_loss: 16.5220 - val_mae: 3.0034\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2517 - mae: 1.9569 - val_loss: 17.0509 - val_mae: 3.0290\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8189 - mae: 2.0016 - val_loss: 17.8441 - val_mae: 3.0378\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3290 - mae: 1.9782 - val_loss: 16.7578 - val_mae: 3.0919\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4779 - mae: 2.0472 - val_loss: 16.5637 - val_mae: 3.0778\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2777 - mae: 1.9718 - val_loss: 16.5861 - val_mae: 3.0001\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3242 - mae: 1.9597 - val_loss: 17.0809 - val_mae: 2.9850\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2525 - mae: 1.9458 - val_loss: 17.2749 - val_mae: 3.0337\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0944 - mae: 1.9362 - val_loss: 16.8935 - val_mae: 3.0339\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.9762 - mae: 1.9281 - val_loss: 16.8449 - val_mae: 3.0363\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9420 - mae: 1.9262 - val_loss: 16.9336 - val_mae: 3.0298\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9465 - mae: 1.9117 - val_loss: 16.6178 - val_mae: 2.9808\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8682 - mae: 1.9101 - val_loss: 16.8707 - val_mae: 2.9866\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8629 - mae: 1.9060 - val_loss: 16.7338 - val_mae: 2.9540\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8183 - mae: 1.9048 - val_loss: 16.5790 - val_mae: 2.9659\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7332 - mae: 1.8940 - val_loss: 16.5556 - val_mae: 2.9745\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7617 - mae: 1.9016 - val_loss: 16.5266 - val_mae: 2.9778\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6994 - mae: 1.8849 - val_loss: 16.2875 - val_mae: 2.9305\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6966 - mae: 1.8844 - val_loss: 16.3666 - val_mae: 2.9500\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6610 - mae: 1.8864 - val_loss: 16.4620 - val_mae: 2.9762\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6221 - mae: 1.8839 - val_loss: 16.4526 - val_mae: 2.9874\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5758 - mae: 1.8839 - val_loss: 16.5398 - val_mae: 2.9988\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5726 - mae: 1.8815 - val_loss: 16.3865 - val_mae: 2.9467\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5177 - mae: 1.8620 - val_loss: 16.4731 - val_mae: 2.9627\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5399 - mae: 1.8578 - val_loss: 16.4661 - val_mae: 2.9616\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4869 - mae: 1.8471 - val_loss: 16.1945 - val_mae: 2.9310\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5277 - mae: 1.8588 - val_loss: 16.1529 - val_mae: 2.9341\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4994 - mae: 1.8730 - val_loss: 16.3098 - val_mae: 2.9771\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8339 - mae: 1.9085 - val_loss: 15.1455 - val_mae: 2.8922\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7556 - mae: 1.8990 - val_loss: 16.0744 - val_mae: 2.9528\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3958 - mae: 1.8597 - val_loss: 15.9935 - val_mae: 2.9374\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4170 - mae: 1.8409 - val_loss: 15.7180 - val_mae: 2.8907\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4412 - mae: 1.8416 - val_loss: 15.8807 - val_mae: 2.8919\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3252 - mae: 1.8643 - val_loss: 16.2246 - val_mae: 2.9738\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1557 - mae: 1.8328 - val_loss: 15.8263 - val_mae: 2.8835\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2339 - mae: 1.8226 - val_loss: 15.7591 - val_mae: 2.9023\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1623 - mae: 1.8325 - val_loss: 16.0065 - val_mae: 2.9436\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5581 - mae: 1.8627 - val_loss: 15.1216 - val_mae: 2.8827\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4155 - mae: 1.8373 - val_loss: 15.6382 - val_mae: 2.8897\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1668 - mae: 1.7925 - val_loss: 16.0283 - val_mae: 2.8771\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4468 - mae: 1.8484 - val_loss: 17.0320 - val_mae: 2.9330\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3755 - mae: 1.8489 - val_loss: 16.0392 - val_mae: 2.9311\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.0932 - mae: 1.8228 - val_loss: 16.0747 - val_mae: 2.9482\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9721 - mae: 1.8047 - val_loss: 15.9401 - val_mae: 2.9265\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8870 - mae: 1.7697 - val_loss: 15.8734 - val_mae: 2.8835\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.8482 - mae: 1.7575 - val_loss: 15.9768 - val_mae: 2.9077\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9480 - mae: 1.7883 - val_loss: 16.2555 - val_mae: 2.9661\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9073 - mae: 1.7809 - val_loss: 15.5187 - val_mae: 2.8870\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7442 - mae: 1.7463 - val_loss: 15.8652 - val_mae: 2.8973\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7225 - mae: 1.7371 - val_loss: 15.8635 - val_mae: 2.8952\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7126 - mae: 1.7433 - val_loss: 15.5995 - val_mae: 2.8988\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6578 - mae: 1.7259 - val_loss: 15.7719 - val_mae: 2.8776\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6726 - mae: 1.7440 - val_loss: 15.8400 - val_mae: 2.9102\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5735 - mae: 1.7336 - val_loss: 15.5683 - val_mae: 2.8780\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5969 - mae: 1.7144 - val_loss: 15.5196 - val_mae: 2.8507\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5552 - mae: 1.7091 - val_loss: 15.6280 - val_mae: 2.8470\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5409 - mae: 1.7154 - val_loss: 15.7553 - val_mae: 2.8595\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5605 - mae: 1.7344 - val_loss: 15.7605 - val_mae: 2.8867\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7873 - mae: 1.7387 - val_loss: 16.1978 - val_mae: 2.8670\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7470 - mae: 1.7257 - val_loss: 15.6495 - val_mae: 2.8382\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5384 - mae: 1.7216 - val_loss: 15.7081 - val_mae: 2.8553\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4314 - mae: 1.7163 - val_loss: 15.2725 - val_mae: 2.8211\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.4206 - mae: 1.6862 - val_loss: 15.5998 - val_mae: 2.8321\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4352 - mae: 1.7084 - val_loss: 15.4817 - val_mae: 2.8978\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3365 - mae: 1.7041 - val_loss: 15.6151 - val_mae: 2.8980\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3504 - mae: 1.6860 - val_loss: 15.5496 - val_mae: 2.8893\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2756 - mae: 1.6612 - val_loss: 15.3616 - val_mae: 2.8783\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2243 - mae: 1.6640 - val_loss: 15.4960 - val_mae: 2.8895\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2070 - mae: 1.6555 - val_loss: 15.5113 - val_mae: 2.8597\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.1873 - mae: 1.6503 - val_loss: 15.2152 - val_mae: 2.8345\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.1760 - mae: 1.6532 - val_loss: 15.2295 - val_mae: 2.8073\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1130 - mae: 1.6430 - val_loss: 15.2935 - val_mae: 2.8302\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0546 - mae: 1.6347 - val_loss: 15.0908 - val_mae: 2.8163\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2173 - mae: 1.6593 - val_loss: 14.6688 - val_mae: 2.8373\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.1355 - mae: 1.6466 - val_loss: 15.3502 - val_mae: 2.8519\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0656 - mae: 1.6432 - val_loss: 15.2232 - val_mae: 2.8367\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1481 - mae: 1.6710 - val_loss: 14.7799 - val_mae: 2.8133\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0964 - mae: 1.6402 - val_loss: 15.1764 - val_mae: 2.8216\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9602 - mae: 1.6112 - val_loss: 15.0636 - val_mae: 2.8106\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9549 - mae: 1.6131 - val_loss: 14.9854 - val_mae: 2.8245\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9353 - mae: 1.6191 - val_loss: 15.2150 - val_mae: 2.8503\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8884 - mae: 1.5988 - val_loss: 15.2092 - val_mae: 2.7968\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8380 - mae: 1.5893 - val_loss: 15.0477 - val_mae: 2.7965\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8180 - mae: 1.6073 - val_loss: 15.1146 - val_mae: 2.8024\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7962 - mae: 1.5895 - val_loss: 15.0107 - val_mae: 2.8004\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7621 - mae: 1.5978 - val_loss: 14.8937 - val_mae: 2.8152\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0002 - mae: 1.6698 - val_loss: 14.6627 - val_mae: 2.8223\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7638 - mae: 1.5849 - val_loss: 14.5303 - val_mae: 2.7388\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8762 - mae: 1.5846 - val_loss: 14.8034 - val_mae: 2.7774\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7807 - mae: 1.6043 - val_loss: 14.8538 - val_mae: 2.8118\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6264 - mae: 1.5548 - val_loss: 14.7478 - val_mae: 2.7442\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6534 - mae: 1.5579 - val_loss: 14.9031 - val_mae: 2.7798\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7082 - mae: 1.6067 - val_loss: 14.9252 - val_mae: 2.7965\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6950 - mae: 1.5744 - val_loss: 15.1386 - val_mae: 2.7698\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6349 - mae: 1.5523 - val_loss: 14.8833 - val_mae: 2.7806\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5619 - mae: 1.5655 - val_loss: 14.9304 - val_mae: 2.8173\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6018 - mae: 1.5439 - val_loss: 15.2225 - val_mae: 2.7878\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5014 - mae: 1.5295 - val_loss: 14.9608 - val_mae: 2.8151\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6878 - mae: 1.5976 - val_loss: 14.8838 - val_mae: 2.8495\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6170 - mae: 1.5624 - val_loss: 14.9722 - val_mae: 2.8267\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5047 - mae: 1.5199 - val_loss: 15.0618 - val_mae: 2.8153\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4348 - mae: 1.5176 - val_loss: 15.2283 - val_mae: 2.8360\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4106 - mae: 1.5210 - val_loss: 15.1956 - val_mae: 2.8035\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3707 - mae: 1.5127 - val_loss: 15.0967 - val_mae: 2.7965\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3710 - mae: 1.4986 - val_loss: 14.9229 - val_mae: 2.7845\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3857 - mae: 1.4931 - val_loss: 15.2142 - val_mae: 2.7900\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3883 - mae: 1.5240 - val_loss: 15.0239 - val_mae: 2.8046\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2974 - mae: 1.5048 - val_loss: 15.1887 - val_mae: 2.7833\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3089 - mae: 1.4861 - val_loss: 15.1639 - val_mae: 2.7909\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3679 - mae: 1.5206 - val_loss: 15.0856 - val_mae: 2.8255\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2850 - mae: 1.5050 - val_loss: 15.1316 - val_mae: 2.7904\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2686 - mae: 1.4723 - val_loss: 15.0381 - val_mae: 2.8064\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2781 - mae: 1.4792 - val_loss: 14.6307 - val_mae: 2.7918\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2536 - mae: 1.4790 - val_loss: 14.6049 - val_mae: 2.7648\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7537 - mae: 1.5971 - val_loss: 13.9142 - val_mae: 2.7429\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5802 - mae: 1.5533 - val_loss: 14.7813 - val_mae: 2.7465\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3273 - mae: 1.5062 - val_loss: 14.9709 - val_mae: 2.7782\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2234 - mae: 1.4973 - val_loss: 15.0827 - val_mae: 2.7837\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.1860 - mae: 1.4773 - val_loss: 15.3866 - val_mae: 2.8028\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1511 - mae: 1.4754 - val_loss: 15.2931 - val_mae: 2.7855\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1217 - mae: 1.4523 - val_loss: 15.2889 - val_mae: 2.7831\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1193 - mae: 1.4518 - val_loss: 14.9799 - val_mae: 2.7873\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0804 - mae: 1.4716 - val_loss: 15.3180 - val_mae: 2.8068\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0672 - mae: 1.4453 - val_loss: 15.2417 - val_mae: 2.7731\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0936 - mae: 1.4508 - val_loss: 14.9851 - val_mae: 2.7680\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9968 - mae: 1.4357 - val_loss: 15.0219 - val_mae: 2.7722\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0241 - mae: 1.4355 - val_loss: 14.8025 - val_mae: 2.7450\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9614 - mae: 1.4318 - val_loss: 14.6733 - val_mae: 2.7581\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2226 - mae: 1.5239 - val_loss: 14.2045 - val_mae: 2.7586\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2837 - mae: 1.5234 - val_loss: 14.8274 - val_mae: 2.7691\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0737 - mae: 1.4503 - val_loss: 14.8012 - val_mae: 2.7507\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9452 - mae: 1.4258 - val_loss: 14.7693 - val_mae: 2.7955\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1123 - mae: 1.4698 - val_loss: 14.6644 - val_mae: 2.7839\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0845 - mae: 1.4474 - val_loss: 15.1157 - val_mae: 2.7463\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9957 - mae: 1.4627 - val_loss: 15.0422 - val_mae: 2.8238\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1731 - mae: 1.5134 - val_loss: 15.1262 - val_mae: 2.7577\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0939 - mae: 1.4622 - val_loss: 14.8573 - val_mae: 2.7628\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9247 - mae: 1.4300 - val_loss: 14.7419 - val_mae: 2.7435\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.8733 - mae: 1.4299 - val_loss: 14.7310 - val_mae: 2.7534\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8428 - mae: 1.4211 - val_loss: 14.7496 - val_mae: 2.7360\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7918 - mae: 1.4029 - val_loss: 15.0473 - val_mae: 2.7344\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8408 - mae: 1.4077 - val_loss: 14.6694 - val_mae: 2.7354\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8207 - mae: 1.4244 - val_loss: 14.7744 - val_mae: 2.7363\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7530 - mae: 1.3957 - val_loss: 14.7088 - val_mae: 2.7159\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7589 - mae: 1.3957 - val_loss: 14.5980 - val_mae: 2.7283\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7318 - mae: 1.3899 - val_loss: 14.8106 - val_mae: 2.7329\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7761 - mae: 1.3892 - val_loss: 15.0125 - val_mae: 2.7411\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7190 - mae: 1.3932 - val_loss: 14.5975 - val_mae: 2.7269\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6977 - mae: 1.3934 - val_loss: 14.6557 - val_mae: 2.7353\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9068 - mae: 1.4354 - val_loss: 15.0139 - val_mae: 2.7958\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7990 - mae: 1.4112 - val_loss: 14.9538 - val_mae: 2.7556\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7089 - mae: 1.3963 - val_loss: 15.1532 - val_mae: 2.8039\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.6483 - mae: 1.3662 - val_loss: 14.8528 - val_mae: 2.7392\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.6708 - mae: 1.3661 - val_loss: 14.7714 - val_mae: 2.7589\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.6169 - mae: 1.3644 - val_loss: 14.8829 - val_mae: 2.7425\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6378 - mae: 1.3803 - val_loss: 14.9851 - val_mae: 2.7680\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6048 - mae: 1.3600 - val_loss: 14.7454 - val_mae: 2.7263\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5695 - mae: 1.3612 - val_loss: 14.7466 - val_mae: 2.7479\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5945 - mae: 1.3640 - val_loss: 14.6133 - val_mae: 2.7456\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8012 - mae: 1.4326 - val_loss: 14.2249 - val_mae: 2.7557\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7286 - mae: 1.4054 - val_loss: 14.5431 - val_mae: 2.7092\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6209 - mae: 1.3749 - val_loss: 14.5928 - val_mae: 2.7513\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5764 - mae: 1.3789 - val_loss: 14.5914 - val_mae: 2.7192\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.5758 - mae: 1.3642 - val_loss: 14.7648 - val_mae: 2.7197\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6726 - mae: 1.3739 - val_loss: 14.7513 - val_mae: 2.7183\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6143 - mae: 1.3663 - val_loss: 15.0046 - val_mae: 2.7487\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6670 - mae: 1.4000 - val_loss: 14.6052 - val_mae: 2.7566\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.6687 - mae: 1.3966 - val_loss: 14.7845 - val_mae: 2.7224\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5961 - mae: 1.3727 - val_loss: 14.5791 - val_mae: 2.7437\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4700714.0000 - mae: 2136.0562\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 13ms/step - loss: 555.8965 - mae: 21.7095 - val_loss: 627.5421 - val_mae: 22.7700\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 518.6794 - mae: 20.8840 - val_loss: 585.9135 - val_mae: 21.8937\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 481.4132 - mae: 20.0242 - val_loss: 540.6898 - val_mae: 20.8870\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 438.2716 - mae: 18.9498 - val_loss: 485.3906 - val_mae: 19.5805\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 382.8431 - mae: 17.5287 - val_loss: 414.8232 - val_mae: 17.8144\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 316.4955 - mae: 15.6779 - val_loss: 334.4961 - val_mae: 15.6161\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 245.1579 - mae: 13.4857 - val_loss: 251.9877 - val_mae: 13.0773\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 177.6765 - mae: 11.0593 - val_loss: 177.0382 - val_mae: 10.4224\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 120.0085 - mae: 8.6147 - val_loss: 122.1243 - val_mae: 8.1694\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 83.6631 - mae: 6.8266 - val_loss: 88.2533 - val_mae: 6.7392\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 62.5709 - mae: 5.8651 - val_loss: 70.8478 - val_mae: 6.0572\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 52.8835 - mae: 5.3366 - val_loss: 58.5470 - val_mae: 5.4809\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45.2042 - mae: 4.8917 - val_loss: 49.0386 - val_mae: 4.9980\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 38.7333 - mae: 4.5121 - val_loss: 42.9363 - val_mae: 4.6429\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.4257 - mae: 4.2196 - val_loss: 39.2037 - val_mae: 4.3644\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 31.2283 - mae: 3.9786 - val_loss: 36.1213 - val_mae: 4.1435\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.2038 - mae: 3.8422 - val_loss: 32.7929 - val_mae: 3.9125\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.1928 - mae: 3.7154 - val_loss: 30.4329 - val_mae: 3.7058\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9507 - mae: 3.6327 - val_loss: 29.4668 - val_mae: 3.6169\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.7216 - mae: 3.5430 - val_loss: 27.7706 - val_mae: 3.4993\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.8081 - mae: 3.4803 - val_loss: 26.7455 - val_mae: 3.4230\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.9308 - mae: 3.4162 - val_loss: 26.0420 - val_mae: 3.3771\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.0463 - mae: 3.3210 - val_loss: 26.3081 - val_mae: 3.3710\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.4004 - mae: 3.2492 - val_loss: 25.8639 - val_mae: 3.3445\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.8147 - mae: 3.1958 - val_loss: 25.2264 - val_mae: 3.3040\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.2899 - mae: 3.2339 - val_loss: 23.0942 - val_mae: 3.2482\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.6500 - mae: 3.3523 - val_loss: 22.6859 - val_mae: 3.2978\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.9912 - mae: 3.2680 - val_loss: 22.8037 - val_mae: 3.1967\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 18.7977 - mae: 3.1164 - val_loss: 23.0976 - val_mae: 3.1935\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.2646 - mae: 3.0173 - val_loss: 23.7134 - val_mae: 3.2122\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.9390 - mae: 2.9571 - val_loss: 24.1543 - val_mae: 3.2362\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.6160 - mae: 2.9104 - val_loss: 23.7381 - val_mae: 3.1874\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.2481 - mae: 2.8762 - val_loss: 23.1165 - val_mae: 3.1414\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.9746 - mae: 2.8664 - val_loss: 22.9121 - val_mae: 3.1228\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.7513 - mae: 2.8134 - val_loss: 23.3656 - val_mae: 3.1313\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3901 - mae: 2.7841 - val_loss: 22.5630 - val_mae: 3.0790\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.0710 - mae: 2.7651 - val_loss: 21.9634 - val_mae: 3.0403\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.8461 - mae: 2.7801 - val_loss: 21.0355 - val_mae: 3.0011\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.4468 - mae: 2.7598 - val_loss: 21.0364 - val_mae: 2.9889\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.1874 - mae: 2.7077 - val_loss: 21.4278 - val_mae: 2.9879\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.0031 - mae: 2.6842 - val_loss: 20.9028 - val_mae: 2.9754\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.7113 - mae: 2.6626 - val_loss: 21.1741 - val_mae: 2.9761\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.5102 - mae: 2.6537 - val_loss: 20.5716 - val_mae: 2.9545\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.2542 - mae: 2.6358 - val_loss: 20.4312 - val_mae: 2.9385\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0454 - mae: 2.6088 - val_loss: 20.3510 - val_mae: 2.9283\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.8897 - mae: 2.5940 - val_loss: 20.2326 - val_mae: 2.9248\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.7208 - mae: 2.5746 - val_loss: 20.0830 - val_mae: 2.9140\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.5206 - mae: 2.5563 - val_loss: 20.1323 - val_mae: 2.9139\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4275 - mae: 2.5374 - val_loss: 20.3663 - val_mae: 2.9178\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.3157 - mae: 2.5160 - val_loss: 19.8141 - val_mae: 2.8896\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.1225 - mae: 2.5144 - val_loss: 19.5814 - val_mae: 2.8675\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9711 - mae: 2.4961 - val_loss: 19.4398 - val_mae: 2.8589\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9278 - mae: 2.4947 - val_loss: 18.8048 - val_mae: 2.8239\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7126 - mae: 2.4909 - val_loss: 18.9802 - val_mae: 2.8259\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6350 - mae: 2.4740 - val_loss: 19.5584 - val_mae: 2.8445\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6153 - mae: 2.4525 - val_loss: 19.5599 - val_mae: 2.8226\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.5037 - mae: 2.4333 - val_loss: 19.3999 - val_mae: 2.8135\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.2718 - mae: 2.4218 - val_loss: 18.9042 - val_mae: 2.8014\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.1296 - mae: 2.4202 - val_loss: 18.4475 - val_mae: 2.7923\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0532 - mae: 2.4123 - val_loss: 18.7301 - val_mae: 2.8115\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.0006 - mae: 2.4098 - val_loss: 18.0800 - val_mae: 2.7671\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8249 - mae: 2.4012 - val_loss: 18.2086 - val_mae: 2.7716\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.8977 - mae: 2.3988 - val_loss: 18.8376 - val_mae: 2.7980\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7361 - mae: 2.3725 - val_loss: 18.9415 - val_mae: 2.8019\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.6306 - mae: 2.3650 - val_loss: 18.2844 - val_mae: 2.7714\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.6244 - mae: 2.3830 - val_loss: 18.0526 - val_mae: 2.7535\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3854 - mae: 2.3504 - val_loss: 18.4991 - val_mae: 2.7569\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4941 - mae: 2.3444 - val_loss: 18.8967 - val_mae: 2.7720\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.2531 - mae: 2.3253 - val_loss: 18.4866 - val_mae: 2.7557\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2501 - mae: 2.3471 - val_loss: 17.9515 - val_mae: 2.7534\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2869 - mae: 2.3407 - val_loss: 18.4327 - val_mae: 2.7577\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0073 - mae: 2.3218 - val_loss: 18.2252 - val_mae: 2.7267\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.9483 - mae: 2.2976 - val_loss: 18.4271 - val_mae: 2.7237\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.9268 - mae: 2.2887 - val_loss: 18.2515 - val_mae: 2.7213\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.7892 - mae: 2.2929 - val_loss: 17.9688 - val_mae: 2.7098\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9362 - mae: 2.3330 - val_loss: 18.1701 - val_mae: 2.7411\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7194 - mae: 2.3027 - val_loss: 18.1627 - val_mae: 2.7202\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.6539 - mae: 2.2849 - val_loss: 17.9779 - val_mae: 2.7071\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5508 - mae: 2.2654 - val_loss: 18.2626 - val_mae: 2.6992\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.5738 - mae: 2.2512 - val_loss: 18.5714 - val_mae: 2.7020\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5559 - mae: 2.2419 - val_loss: 18.4912 - val_mae: 2.7106\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4821 - mae: 2.2549 - val_loss: 18.1377 - val_mae: 2.7168\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3763 - mae: 2.2459 - val_loss: 18.4064 - val_mae: 2.7161\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3028 - mae: 2.2402 - val_loss: 18.2221 - val_mae: 2.7154\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2593 - mae: 2.2453 - val_loss: 18.3830 - val_mae: 2.7214\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.2333 - mae: 2.2203 - val_loss: 18.2854 - val_mae: 2.7048\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4541 - mae: 2.2490 - val_loss: 17.3316 - val_mae: 2.6905\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3180 - mae: 2.2475 - val_loss: 17.4250 - val_mae: 2.6680\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1313 - mae: 2.2197 - val_loss: 17.5272 - val_mae: 2.6722\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.0662 - mae: 2.1989 - val_loss: 18.0166 - val_mae: 2.6909\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4965 - mae: 2.2391 - val_loss: 19.1376 - val_mae: 2.8032\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2541 - mae: 2.2244 - val_loss: 17.9736 - val_mae: 2.7413\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.9867 - mae: 2.2149 - val_loss: 17.8527 - val_mae: 2.7241\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.8541 - mae: 2.2081 - val_loss: 17.7790 - val_mae: 2.7194\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.8077 - mae: 2.1994 - val_loss: 17.8301 - val_mae: 2.7073\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.7751 - mae: 2.1935 - val_loss: 18.0275 - val_mae: 2.7000\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6922 - mae: 2.1748 - val_loss: 17.5063 - val_mae: 2.6733\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7146 - mae: 2.1805 - val_loss: 16.9384 - val_mae: 2.6456\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7720 - mae: 2.1854 - val_loss: 17.0706 - val_mae: 2.6516\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6800 - mae: 2.1579 - val_loss: 17.3750 - val_mae: 2.6466\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6437 - mae: 2.1556 - val_loss: 17.5372 - val_mae: 2.6629\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4951 - mae: 2.1433 - val_loss: 17.6722 - val_mae: 2.6574\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4878 - mae: 2.1453 - val_loss: 17.2858 - val_mae: 2.6490\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.5111 - mae: 2.1949 - val_loss: 17.2689 - val_mae: 2.6985\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6024 - mae: 2.2054 - val_loss: 17.5366 - val_mae: 2.6860\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.3875 - mae: 2.1544 - val_loss: 17.7439 - val_mae: 2.6644\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4373 - mae: 2.1289 - val_loss: 18.0810 - val_mae: 2.6911\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4242 - mae: 2.1284 - val_loss: 17.6213 - val_mae: 2.6745\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4820 - mae: 2.1684 - val_loss: 17.6146 - val_mae: 2.7815\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6321 - mae: 2.2225 - val_loss: 17.5028 - val_mae: 2.7248\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.1881 - mae: 2.1463 - val_loss: 17.8776 - val_mae: 2.6899\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2606 - mae: 2.1258 - val_loss: 17.7781 - val_mae: 2.6668\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.1347 - mae: 2.1225 - val_loss: 17.2624 - val_mae: 2.6799\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0949 - mae: 2.1246 - val_loss: 17.4219 - val_mae: 2.6606\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1874 - mae: 2.1008 - val_loss: 18.1213 - val_mae: 2.6606\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.0164 - mae: 2.0875 - val_loss: 17.8084 - val_mae: 2.6508\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9988 - mae: 2.1023 - val_loss: 17.4103 - val_mae: 2.6518\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0421 - mae: 2.0836 - val_loss: 17.9369 - val_mae: 2.6746\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9129 - mae: 2.1036 - val_loss: 17.2550 - val_mae: 2.6625\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8399 - mae: 2.0840 - val_loss: 17.5344 - val_mae: 2.6819\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7933 - mae: 2.0732 - val_loss: 17.5630 - val_mae: 2.6931\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8145 - mae: 2.0721 - val_loss: 18.0845 - val_mae: 2.6798\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7721 - mae: 2.0730 - val_loss: 17.6767 - val_mae: 2.6840\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7096 - mae: 2.0811 - val_loss: 17.3372 - val_mae: 2.6594\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6929 - mae: 2.0699 - val_loss: 17.7017 - val_mae: 2.6413\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6673 - mae: 2.0308 - val_loss: 17.7532 - val_mae: 2.6545\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6212 - mae: 2.0329 - val_loss: 17.0452 - val_mae: 2.6334\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6720 - mae: 2.0802 - val_loss: 17.0643 - val_mae: 2.6723\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5674 - mae: 2.0627 - val_loss: 17.2588 - val_mae: 2.6354\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5512 - mae: 2.0289 - val_loss: 17.5641 - val_mae: 2.6315\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4932 - mae: 2.0396 - val_loss: 17.4094 - val_mae: 2.6314\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3890 - mae: 2.0327 - val_loss: 17.0860 - val_mae: 2.6378\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3939 - mae: 2.0480 - val_loss: 16.9306 - val_mae: 2.6354\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3385 - mae: 2.0397 - val_loss: 17.1154 - val_mae: 2.6297\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3180 - mae: 2.0209 - val_loss: 17.2772 - val_mae: 2.6288\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3403 - mae: 2.0025 - val_loss: 17.4082 - val_mae: 2.6242\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2727 - mae: 2.0064 - val_loss: 16.8740 - val_mae: 2.6218\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2258 - mae: 2.0277 - val_loss: 16.9329 - val_mae: 2.6246\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2384 - mae: 2.0032 - val_loss: 17.1640 - val_mae: 2.6189\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2130 - mae: 1.9938 - val_loss: 16.8375 - val_mae: 2.6074\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1746 - mae: 2.0046 - val_loss: 16.6405 - val_mae: 2.6286\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2541 - mae: 2.0451 - val_loss: 16.7182 - val_mae: 2.6371\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0848 - mae: 2.0173 - val_loss: 16.6826 - val_mae: 2.6200\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4533 - mae: 2.0803 - val_loss: 16.8077 - val_mae: 2.7243\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1473 - mae: 2.0264 - val_loss: 17.0298 - val_mae: 2.6398\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0381 - mae: 2.0037 - val_loss: 16.4858 - val_mae: 2.6300\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9930 - mae: 2.0185 - val_loss: 16.4095 - val_mae: 2.6228\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9552 - mae: 2.0132 - val_loss: 16.7043 - val_mae: 2.6014\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8677 - mae: 1.9756 - val_loss: 16.5545 - val_mae: 2.5989\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.9053 - mae: 1.9870 - val_loss: 16.5698 - val_mae: 2.6140\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9223 - mae: 1.9899 - val_loss: 16.5369 - val_mae: 2.6152\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8494 - mae: 1.9947 - val_loss: 16.5540 - val_mae: 2.6915\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.9795 - mae: 2.0073 - val_loss: 16.7908 - val_mae: 2.6147\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8362 - mae: 1.9433 - val_loss: 16.8094 - val_mae: 2.6230\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7685 - mae: 1.9536 - val_loss: 16.6647 - val_mae: 2.6253\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6582 - mae: 1.9485 - val_loss: 16.6169 - val_mae: 2.6241\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.6501 - mae: 1.9487 - val_loss: 16.3959 - val_mae: 2.6217\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6341 - mae: 1.9514 - val_loss: 16.3662 - val_mae: 2.5891\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6482 - mae: 1.9552 - val_loss: 16.3396 - val_mae: 2.5926\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5866 - mae: 1.9337 - val_loss: 16.3149 - val_mae: 2.6032\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.6919 - mae: 1.9700 - val_loss: 16.0532 - val_mae: 2.6529\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5120 - mae: 1.9329 - val_loss: 16.4494 - val_mae: 2.6160\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6820 - mae: 1.9849 - val_loss: 16.4671 - val_mae: 2.6659\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5216 - mae: 1.9448 - val_loss: 16.8083 - val_mae: 2.6529\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5570 - mae: 1.9531 - val_loss: 16.4151 - val_mae: 2.6883\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.3766 - mae: 1.9412 - val_loss: 16.2286 - val_mae: 2.6380\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5576 - mae: 1.9429 - val_loss: 16.2244 - val_mae: 2.6481\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5974 - mae: 1.9212 - val_loss: 16.5404 - val_mae: 2.6308\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5463 - mae: 1.9495 - val_loss: 16.2057 - val_mae: 2.6543\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4063 - mae: 1.9172 - val_loss: 16.8777 - val_mae: 2.6230\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2851 - mae: 1.9111 - val_loss: 16.1250 - val_mae: 2.6571\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4280 - mae: 1.9065 - val_loss: 16.5750 - val_mae: 2.6123\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7706 - mae: 1.9656 - val_loss: 16.8090 - val_mae: 2.7447\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4707 - mae: 1.9452 - val_loss: 17.0550 - val_mae: 2.6963\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3750 - mae: 1.9558 - val_loss: 16.7332 - val_mae: 2.6890\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3310 - mae: 1.9168 - val_loss: 16.5403 - val_mae: 2.6386\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1598 - mae: 1.8732 - val_loss: 16.2195 - val_mae: 2.6020\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1728 - mae: 1.8848 - val_loss: 16.1063 - val_mae: 2.5943\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.3089 - mae: 1.8900 - val_loss: 15.6811 - val_mae: 2.6235\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.0854 - mae: 1.8839 - val_loss: 15.8094 - val_mae: 2.5918\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0736 - mae: 1.8877 - val_loss: 16.4692 - val_mae: 2.6096\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2038 - mae: 1.8765 - val_loss: 16.3480 - val_mae: 2.6418\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.1904 - mae: 1.8852 - val_loss: 16.2111 - val_mae: 2.6244\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9553 - mae: 1.8694 - val_loss: 15.8882 - val_mae: 2.6289\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9405 - mae: 1.8728 - val_loss: 16.0189 - val_mae: 2.6035\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9710 - mae: 1.8631 - val_loss: 16.1202 - val_mae: 2.5804\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9779 - mae: 1.8401 - val_loss: 16.0709 - val_mae: 2.5970\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9013 - mae: 1.8512 - val_loss: 15.6885 - val_mae: 2.6108\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9167 - mae: 1.8713 - val_loss: 15.5663 - val_mae: 2.5938\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.0807 - mae: 1.8796 - val_loss: 16.0927 - val_mae: 2.6544\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9196 - mae: 1.8616 - val_loss: 15.8570 - val_mae: 2.6377\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8217 - mae: 1.8516 - val_loss: 15.5806 - val_mae: 2.6219\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7591 - mae: 1.8227 - val_loss: 15.7565 - val_mae: 2.5966\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7136 - mae: 1.8288 - val_loss: 15.5837 - val_mae: 2.6111\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7044 - mae: 1.8141 - val_loss: 15.7350 - val_mae: 2.5765\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7693 - mae: 1.8064 - val_loss: 15.9882 - val_mae: 2.5804\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7513 - mae: 1.8088 - val_loss: 15.6328 - val_mae: 2.5888\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6730 - mae: 1.8128 - val_loss: 15.4837 - val_mae: 2.5914\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6715 - mae: 1.8187 - val_loss: 15.4253 - val_mae: 2.6034\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5769 - mae: 1.8007 - val_loss: 15.7404 - val_mae: 2.6095\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7221 - mae: 1.8232 - val_loss: 15.8274 - val_mae: 2.6185\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6671 - mae: 1.8216 - val_loss: 17.8301 - val_mae: 2.6772\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1232 - mae: 1.8550 - val_loss: 17.1016 - val_mae: 2.6911\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8054 - mae: 1.8728 - val_loss: 16.4527 - val_mae: 2.6723\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5797 - mae: 1.8315 - val_loss: 16.2722 - val_mae: 2.6220\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5391 - mae: 1.7960 - val_loss: 15.9302 - val_mae: 2.6459\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5952 - mae: 1.8463 - val_loss: 15.7246 - val_mae: 2.6753\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5885 - mae: 1.8142 - val_loss: 16.0788 - val_mae: 2.6652\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4781 - mae: 1.8029 - val_loss: 15.6424 - val_mae: 2.6611\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5847 - mae: 1.8373 - val_loss: 15.6369 - val_mae: 2.6481\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4468 - mae: 1.8028 - val_loss: 15.9910 - val_mae: 2.6441\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4035 - mae: 1.7859 - val_loss: 15.4209 - val_mae: 2.6072\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2582 - mae: 1.7859 - val_loss: 15.0860 - val_mae: 2.6143\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2489 - mae: 1.7790 - val_loss: 15.1646 - val_mae: 2.5788\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2031 - mae: 1.7500 - val_loss: 15.2643 - val_mae: 2.5793\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4166 - mae: 1.7903 - val_loss: 15.3191 - val_mae: 2.5856\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3020 - mae: 1.7940 - val_loss: 15.0296 - val_mae: 2.6009\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1821 - mae: 1.7687 - val_loss: 15.2539 - val_mae: 2.6370\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.2454 - mae: 1.7754 - val_loss: 14.9348 - val_mae: 2.6038\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1937 - mae: 1.7603 - val_loss: 15.0401 - val_mae: 2.5826\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.0496 - mae: 1.7552 - val_loss: 14.9433 - val_mae: 2.6368\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1625 - mae: 1.7826 - val_loss: 15.2008 - val_mae: 2.6204\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1415 - mae: 1.7570 - val_loss: 15.4108 - val_mae: 2.6518\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1249 - mae: 1.7616 - val_loss: 15.2139 - val_mae: 2.6223\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0668 - mae: 1.7331 - val_loss: 16.1135 - val_mae: 2.6123\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2801 - mae: 1.7684 - val_loss: 15.9188 - val_mae: 2.6059\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2460 - mae: 1.7738 - val_loss: 15.5538 - val_mae: 2.6625\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1079 - mae: 1.8140 - val_loss: 15.1747 - val_mae: 2.6616\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0001 - mae: 1.7548 - val_loss: 15.1227 - val_mae: 2.6015\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0639 - mae: 1.7309 - val_loss: 14.8849 - val_mae: 2.5592\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.2682 - mae: 1.8023 - val_loss: 15.3357 - val_mae: 2.6985\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.0344 - mae: 1.7882 - val_loss: 15.3117 - val_mae: 2.6382\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9373 - mae: 1.7294 - val_loss: 15.2314 - val_mae: 2.6201\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.8030 - mae: 1.7175 - val_loss: 14.9304 - val_mae: 2.6135\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7765 - mae: 1.7166 - val_loss: 14.8924 - val_mae: 2.5910\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7454 - mae: 1.7009 - val_loss: 14.7976 - val_mae: 2.5871\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7610 - mae: 1.7293 - val_loss: 14.8301 - val_mae: 2.6184\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7260 - mae: 1.7197 - val_loss: 14.9658 - val_mae: 2.5984\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6911 - mae: 1.6883 - val_loss: 14.8541 - val_mae: 2.6196\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7319 - mae: 1.7144 - val_loss: 14.5659 - val_mae: 2.6171\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7117 - mae: 1.6800 - val_loss: 14.8626 - val_mae: 2.5791\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7430 - mae: 1.6887 - val_loss: 14.6525 - val_mae: 2.5803\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6598 - mae: 1.7078 - val_loss: 14.8862 - val_mae: 2.5940\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5558 - mae: 1.6658 - val_loss: 15.1604 - val_mae: 2.5599\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6496 - mae: 1.6725 - val_loss: 14.7620 - val_mae: 2.5515\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7099 - mae: 1.6790 - val_loss: 14.8032 - val_mae: 2.5600\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5976 - mae: 1.6802 - val_loss: 14.5107 - val_mae: 2.5809\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6629 - mae: 1.7183 - val_loss: 14.4580 - val_mae: 2.5948\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5005 - mae: 1.6781 - val_loss: 14.6350 - val_mae: 2.5577\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4892 - mae: 1.6567 - val_loss: 14.6451 - val_mae: 2.5794\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.4628 - mae: 1.6598 - val_loss: 14.5703 - val_mae: 2.6052\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9453 - mae: 1.7766 - val_loss: 15.2050 - val_mae: 2.6901\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5738 - mae: 1.7364 - val_loss: 15.1288 - val_mae: 2.6248\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5047 - mae: 1.6814 - val_loss: 15.0501 - val_mae: 2.6014\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4313 - mae: 1.6722 - val_loss: 14.6853 - val_mae: 2.5981\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4155 - mae: 1.6745 - val_loss: 14.6605 - val_mae: 2.5818\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.4792 - mae: 1.6999 - val_loss: 15.0015 - val_mae: 2.6441\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5446 - mae: 1.7055 - val_loss: 14.9187 - val_mae: 2.6043\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1125 - mae: 1.8196 - val_loss: 15.2423 - val_mae: 2.7358\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7908 - mae: 1.7479 - val_loss: 14.9826 - val_mae: 2.5980\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4765 - mae: 1.6746 - val_loss: 14.5580 - val_mae: 2.5583\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5586 - mae: 1.7346 - val_loss: 13.5762 - val_mae: 2.5842\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.4608 - mae: 1.7051 - val_loss: 13.5957 - val_mae: 2.5135\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2507 - mae: 1.6440 - val_loss: 13.5554 - val_mae: 2.5154\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3370 - mae: 1.7035 - val_loss: 13.7652 - val_mae: 2.5436\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1925 - mae: 1.6350 - val_loss: 14.1492 - val_mae: 2.5280\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.1324 - mae: 1.6397 - val_loss: 13.8856 - val_mae: 2.5531\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1220 - mae: 1.6473 - val_loss: 14.2472 - val_mae: 2.5184\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3163 - mae: 1.6184 - val_loss: 14.2963 - val_mae: 2.5197\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2020 - mae: 1.6319 - val_loss: 13.6783 - val_mae: 2.5559\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1324 - mae: 1.6603 - val_loss: 13.8253 - val_mae: 2.5401\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0278 - mae: 1.6098 - val_loss: 14.0475 - val_mae: 2.5234\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0466 - mae: 1.5987 - val_loss: 14.0389 - val_mae: 2.5446\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0478 - mae: 1.5976 - val_loss: 13.6923 - val_mae: 2.5287\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9158 - mae: 1.5962 - val_loss: 13.7950 - val_mae: 2.5543\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0337 - mae: 1.6457 - val_loss: 13.9919 - val_mae: 2.5704\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9309 - mae: 1.6019 - val_loss: 13.9124 - val_mae: 2.5337\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8525 - mae: 1.5924 - val_loss: 13.6549 - val_mae: 2.5444\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8634 - mae: 1.5873 - val_loss: 13.5836 - val_mae: 2.5405\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9132 - mae: 1.6187 - val_loss: 13.7185 - val_mae: 2.5461\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8400 - mae: 1.5796 - val_loss: 13.6405 - val_mae: 2.5172\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8010 - mae: 1.5801 - val_loss: 13.5830 - val_mae: 2.5250\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7854 - mae: 1.5760 - val_loss: 13.6894 - val_mae: 2.5302\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8837 - mae: 1.5910 - val_loss: 13.7910 - val_mae: 2.5683\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7971 - mae: 1.5907 - val_loss: 13.6809 - val_mae: 2.5677\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7530 - mae: 1.5761 - val_loss: 14.0628 - val_mae: 2.5614\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7236 - mae: 1.5739 - val_loss: 14.0966 - val_mae: 2.5593\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7037 - mae: 1.5662 - val_loss: 13.7905 - val_mae: 2.5297\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7241 - mae: 1.5480 - val_loss: 13.6745 - val_mae: 2.5198\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6394 - mae: 1.5553 - val_loss: 13.4075 - val_mae: 2.5390\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6218 - mae: 1.5682 - val_loss: 13.5884 - val_mae: 2.5449\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6373 - mae: 1.5800 - val_loss: 13.6683 - val_mae: 2.5442\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6301 - mae: 1.5595 - val_loss: 13.8311 - val_mae: 2.5400\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6675 - mae: 1.5575 - val_loss: 13.6960 - val_mae: 2.5397\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5758 - mae: 1.5484 - val_loss: 13.6102 - val_mae: 2.5271\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5139 - mae: 1.5281 - val_loss: 13.6486 - val_mae: 2.5065\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7593 - mae: 1.5220 - val_loss: 13.7310 - val_mae: 2.5208\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7067 - mae: 1.5722 - val_loss: 13.4393 - val_mae: 2.5611\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7104 - mae: 1.5941 - val_loss: 13.6584 - val_mae: 2.5648\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6399 - mae: 1.5891 - val_loss: 13.6429 - val_mae: 2.5483\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5235676.5000 - mae: 2279.1807\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 15ms/step - loss: 554.5662 - mae: 21.8321 - val_loss: 595.2111 - val_mae: 22.4165\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 521.0891 - mae: 21.0843 - val_loss: 559.3753 - val_mae: 21.6423\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 486.7445 - mae: 20.3026 - val_loss: 517.6524 - val_mae: 20.7266\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 444.8632 - mae: 19.3279 - val_loss: 465.6474 - val_mae: 19.5422\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 394.6091 - mae: 18.0538 - val_loss: 401.6363 - val_mae: 17.9985\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 334.3546 - mae: 16.3703 - val_loss: 325.9217 - val_mae: 15.9984\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 262.6761 - mae: 14.2240 - val_loss: 248.1776 - val_mae: 13.5941\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 194.4013 - mae: 11.8261 - val_loss: 179.0487 - val_mae: 10.9685\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 139.5778 - mae: 9.6788 - val_loss: 132.5781 - val_mae: 9.0523\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 103.3853 - mae: 8.1761 - val_loss: 106.2856 - val_mae: 7.9935\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 81.5772 - mae: 7.1308 - val_loss: 90.8777 - val_mae: 7.4507\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 68.2941 - mae: 6.4859 - val_loss: 78.9146 - val_mae: 6.9492\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 57.0003 - mae: 5.9017 - val_loss: 68.0475 - val_mae: 6.4369\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.4942 - mae: 5.4477 - val_loss: 60.1949 - val_mae: 6.0032\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41.5183 - mae: 5.0342 - val_loss: 53.4007 - val_mae: 5.5874\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36.0538 - mae: 4.6406 - val_loss: 48.7415 - val_mae: 5.2416\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.3099 - mae: 4.3458 - val_loss: 45.1188 - val_mae: 4.9556\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 29.6463 - mae: 4.1425 - val_loss: 42.5738 - val_mae: 4.7135\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.5745 - mae: 3.9660 - val_loss: 40.5501 - val_mae: 4.5235\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9386 - mae: 3.8287 - val_loss: 39.0452 - val_mae: 4.3791\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 24.7014 - mae: 3.7154 - val_loss: 37.4919 - val_mae: 4.2461\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.4285 - mae: 3.5802 - val_loss: 35.8658 - val_mae: 4.1088\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 22.5842 - mae: 3.4882 - val_loss: 34.4920 - val_mae: 3.9943\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.8972 - mae: 3.4180 - val_loss: 33.5618 - val_mae: 3.9333\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 21.1622 - mae: 3.3533 - val_loss: 32.8641 - val_mae: 3.8642\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.3076 - mae: 3.3187 - val_loss: 33.4036 - val_mae: 3.9088\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.9914 - mae: 3.3084 - val_loss: 32.2563 - val_mae: 3.8096\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.1622 - mae: 3.1776 - val_loss: 30.5543 - val_mae: 3.6661\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.7743 - mae: 3.1187 - val_loss: 29.6346 - val_mae: 3.5868\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.4430 - mae: 3.0910 - val_loss: 29.9159 - val_mae: 3.5983\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.8948 - mae: 3.0557 - val_loss: 29.3238 - val_mae: 3.5445\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.5176 - mae: 3.0238 - val_loss: 28.7310 - val_mae: 3.4877\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 17.2050 - mae: 2.9973 - val_loss: 28.5708 - val_mae: 3.4680\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.8630 - mae: 2.9729 - val_loss: 28.4844 - val_mae: 3.4463\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.5320 - mae: 2.9486 - val_loss: 28.3338 - val_mae: 3.4236\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.2767 - mae: 2.9154 - val_loss: 28.2540 - val_mae: 3.4198\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.0753 - mae: 2.8792 - val_loss: 27.5483 - val_mae: 3.3634\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.6472 - mae: 2.8457 - val_loss: 27.2447 - val_mae: 3.3038\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.5096 - mae: 2.8463 - val_loss: 27.6525 - val_mae: 3.3401\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.3147 - mae: 2.8078 - val_loss: 26.8673 - val_mae: 3.3005\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.0692 - mae: 2.8035 - val_loss: 26.8109 - val_mae: 3.2493\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.7394 - mae: 2.7864 - val_loss: 26.4980 - val_mae: 3.2299\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4239 - mae: 2.7399 - val_loss: 25.9902 - val_mae: 3.1853\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.2184 - mae: 2.7061 - val_loss: 25.7422 - val_mae: 3.1497\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.1042 - mae: 2.7204 - val_loss: 25.6417 - val_mae: 3.1464\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.8124 - mae: 2.6890 - val_loss: 25.3756 - val_mae: 3.1221\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6642 - mae: 2.6716 - val_loss: 25.6750 - val_mae: 3.1196\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5370 - mae: 2.6816 - val_loss: 25.9238 - val_mae: 3.1752\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.3604 - mae: 2.6357 - val_loss: 25.5562 - val_mae: 3.1654\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.1087 - mae: 2.5903 - val_loss: 24.8189 - val_mae: 3.0687\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8810 - mae: 2.5729 - val_loss: 24.6968 - val_mae: 3.0117\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6857 - mae: 2.5686 - val_loss: 25.0577 - val_mae: 3.0146\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4903 - mae: 2.5567 - val_loss: 25.2292 - val_mae: 3.0235\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4766 - mae: 2.5502 - val_loss: 24.6199 - val_mae: 2.9797\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.2422 - mae: 2.5302 - val_loss: 25.0825 - val_mae: 3.0244\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.0955 - mae: 2.5084 - val_loss: 25.1280 - val_mae: 3.0054\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9303 - mae: 2.4916 - val_loss: 25.1022 - val_mae: 2.9959\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.8241 - mae: 2.4851 - val_loss: 25.7026 - val_mae: 3.0606\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7912 - mae: 2.4864 - val_loss: 25.5126 - val_mae: 3.0798\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4787 - mae: 2.4677 - val_loss: 24.6981 - val_mae: 2.9792\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4120 - mae: 2.4325 - val_loss: 24.8374 - val_mae: 3.0254\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.2752 - mae: 2.4067 - val_loss: 24.6605 - val_mae: 3.0137\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0638 - mae: 2.4106 - val_loss: 25.9579 - val_mae: 3.0766\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0374 - mae: 2.4155 - val_loss: 25.6285 - val_mae: 3.0288\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8827 - mae: 2.3881 - val_loss: 25.0876 - val_mae: 3.0100\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7974 - mae: 2.3616 - val_loss: 24.8945 - val_mae: 2.9986\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.7007 - mae: 2.3527 - val_loss: 24.9754 - val_mae: 2.9922\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5178 - mae: 2.3349 - val_loss: 24.8389 - val_mae: 2.9812\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4483 - mae: 2.3352 - val_loss: 24.8393 - val_mae: 2.9753\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3523 - mae: 2.3086 - val_loss: 23.8035 - val_mae: 2.8988\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.4219 - mae: 2.3072 - val_loss: 24.2152 - val_mae: 2.9288\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.2507 - mae: 2.2994 - val_loss: 25.0508 - val_mae: 3.0007\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2087 - mae: 2.3005 - val_loss: 24.9446 - val_mae: 3.0030\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1898 - mae: 2.2813 - val_loss: 24.1084 - val_mae: 2.9435\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1345 - mae: 2.2948 - val_loss: 24.4373 - val_mae: 2.9512\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.9492 - mae: 2.2734 - val_loss: 25.1019 - val_mae: 3.0283\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8721 - mae: 2.2568 - val_loss: 24.6101 - val_mae: 2.9525\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.9273 - mae: 2.2624 - val_loss: 24.3580 - val_mae: 2.9508\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7054 - mae: 2.2349 - val_loss: 24.8759 - val_mae: 3.0053\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.7148 - mae: 2.2411 - val_loss: 24.7055 - val_mae: 2.9781\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6185 - mae: 2.2319 - val_loss: 24.2346 - val_mae: 2.9270\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6475 - mae: 2.2114 - val_loss: 24.2388 - val_mae: 2.9506\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.5515 - mae: 2.2176 - val_loss: 24.9526 - val_mae: 3.0253\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4585 - mae: 2.1973 - val_loss: 24.5480 - val_mae: 2.9802\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3620 - mae: 2.1925 - val_loss: 24.2875 - val_mae: 2.9360\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5699 - mae: 2.1980 - val_loss: 24.3316 - val_mae: 2.9458\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3480 - mae: 2.1776 - val_loss: 25.3095 - val_mae: 3.0302\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.2887 - mae: 2.1803 - val_loss: 24.5530 - val_mae: 2.9635\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.3507 - mae: 2.1782 - val_loss: 24.3446 - val_mae: 2.9623\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1774 - mae: 2.1642 - val_loss: 25.4987 - val_mae: 3.0579\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.1843 - mae: 2.1885 - val_loss: 24.9071 - val_mae: 3.0214\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.2669 - mae: 2.1437 - val_loss: 22.4271 - val_mae: 2.8884\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2284 - mae: 2.1665 - val_loss: 23.2443 - val_mae: 2.9290\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0395 - mae: 2.1606 - val_loss: 23.2724 - val_mae: 2.9206\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9208 - mae: 2.1398 - val_loss: 23.9391 - val_mae: 2.9533\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8106 - mae: 2.1211 - val_loss: 24.2114 - val_mae: 2.9825\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8102 - mae: 2.1027 - val_loss: 24.0447 - val_mae: 2.9660\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8046 - mae: 2.1023 - val_loss: 24.3848 - val_mae: 2.9503\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.7027 - mae: 2.1099 - val_loss: 24.5234 - val_mae: 2.9443\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7052 - mae: 2.1217 - val_loss: 24.3621 - val_mae: 2.9433\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.6615 - mae: 2.1124 - val_loss: 24.4459 - val_mae: 2.9594\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5926 - mae: 2.0930 - val_loss: 23.9963 - val_mae: 2.9276\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5882 - mae: 2.0881 - val_loss: 24.5732 - val_mae: 2.9966\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6246 - mae: 2.0705 - val_loss: 23.7953 - val_mae: 2.9360\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5127 - mae: 2.0874 - val_loss: 24.5723 - val_mae: 2.9753\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3969 - mae: 2.0798 - val_loss: 24.4596 - val_mae: 2.9733\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4566 - mae: 2.0892 - val_loss: 25.0012 - val_mae: 3.0096\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4110 - mae: 2.0597 - val_loss: 24.0662 - val_mae: 2.9638\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3561 - mae: 2.0338 - val_loss: 24.5856 - val_mae: 2.9811\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7992 - mae: 2.1962 - val_loss: 27.4093 - val_mae: 3.1819\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5722 - mae: 2.1282 - val_loss: 24.9279 - val_mae: 2.9449\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4392 - mae: 2.0640 - val_loss: 24.5030 - val_mae: 2.9563\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2982 - mae: 2.0483 - val_loss: 24.3883 - val_mae: 2.9756\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2843 - mae: 2.0376 - val_loss: 23.2991 - val_mae: 2.9281\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0630 - mae: 2.0199 - val_loss: 23.8009 - val_mae: 2.9498\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0016 - mae: 2.0287 - val_loss: 24.2551 - val_mae: 2.9495\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9142 - mae: 2.0229 - val_loss: 24.7143 - val_mae: 2.9625\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8569 - mae: 2.0096 - val_loss: 24.0443 - val_mae: 2.9202\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8337 - mae: 1.9949 - val_loss: 23.9429 - val_mae: 2.9166\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0231 - mae: 2.0594 - val_loss: 24.4910 - val_mae: 2.9411\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7812 - mae: 2.0026 - val_loss: 24.2396 - val_mae: 2.9556\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8042 - mae: 1.9838 - val_loss: 23.8826 - val_mae: 2.9349\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.8930 - mae: 2.0133 - val_loss: 24.3679 - val_mae: 2.9079\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.6834 - mae: 1.9744 - val_loss: 25.8361 - val_mae: 3.0528\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8425 - mae: 2.0106 - val_loss: 25.4606 - val_mae: 3.0156\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5630 - mae: 1.9453 - val_loss: 24.2501 - val_mae: 2.8949\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4939 - mae: 1.9423 - val_loss: 24.4255 - val_mae: 2.9359\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4919 - mae: 1.9534 - val_loss: 24.3739 - val_mae: 2.9626\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3863 - mae: 1.9405 - val_loss: 23.8714 - val_mae: 2.8873\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5497 - mae: 1.9467 - val_loss: 23.6374 - val_mae: 2.9069\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4491 - mae: 1.9432 - val_loss: 24.3340 - val_mae: 2.9724\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3806 - mae: 1.9398 - val_loss: 23.7150 - val_mae: 2.8899\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3521 - mae: 1.9474 - val_loss: 24.1333 - val_mae: 2.8753\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3586 - mae: 1.9299 - val_loss: 23.8619 - val_mae: 2.8737\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2683 - mae: 1.9193 - val_loss: 24.3964 - val_mae: 2.9206\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3493 - mae: 1.9338 - val_loss: 23.7041 - val_mae: 2.8346\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2487 - mae: 1.8988 - val_loss: 24.3544 - val_mae: 2.9752\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3318 - mae: 1.9342 - val_loss: 24.8243 - val_mae: 2.9632\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0891 - mae: 1.9096 - val_loss: 23.9996 - val_mae: 2.8641\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2919 - mae: 1.9318 - val_loss: 24.0532 - val_mae: 2.8601\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1403 - mae: 1.9195 - val_loss: 24.3286 - val_mae: 2.9544\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.0586 - mae: 1.8870 - val_loss: 23.5423 - val_mae: 2.8496\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0533 - mae: 1.8783 - val_loss: 23.8907 - val_mae: 2.8865\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.9594 - mae: 1.8730 - val_loss: 24.5118 - val_mae: 2.9545\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.1125 - mae: 1.8719 - val_loss: 24.0563 - val_mae: 2.9126\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9354 - mae: 1.8732 - val_loss: 24.4884 - val_mae: 2.9353\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8980 - mae: 1.8833 - val_loss: 24.0659 - val_mae: 2.8931\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9136 - mae: 1.8472 - val_loss: 23.7746 - val_mae: 2.8885\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8711 - mae: 1.8544 - val_loss: 24.1880 - val_mae: 2.9222\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8586 - mae: 1.8422 - val_loss: 23.7101 - val_mae: 2.8742\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8619 - mae: 1.8664 - val_loss: 24.5056 - val_mae: 2.9257\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7854 - mae: 1.8453 - val_loss: 23.7834 - val_mae: 2.8960\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7621 - mae: 1.8475 - val_loss: 24.3842 - val_mae: 2.9125\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9082 - mae: 1.8465 - val_loss: 24.3597 - val_mae: 2.9311\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7730 - mae: 1.8410 - val_loss: 24.2990 - val_mae: 2.8924\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6296 - mae: 1.8293 - val_loss: 23.9719 - val_mae: 2.8854\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7016 - mae: 1.8547 - val_loss: 24.1333 - val_mae: 2.8959\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6199 - mae: 1.8032 - val_loss: 23.3635 - val_mae: 2.8505\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5967 - mae: 1.8326 - val_loss: 23.9979 - val_mae: 2.8982\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5643 - mae: 1.8259 - val_loss: 23.9955 - val_mae: 2.8750\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4889 - mae: 1.8052 - val_loss: 24.0901 - val_mae: 2.8548\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4971 - mae: 1.8212 - val_loss: 24.1912 - val_mae: 2.8878\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4347 - mae: 1.7908 - val_loss: 23.4767 - val_mae: 2.8635\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7802 - mae: 1.8024 - val_loss: 22.3814 - val_mae: 2.8012\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5072 - mae: 1.8131 - val_loss: 23.1310 - val_mae: 2.8645\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5026 - mae: 1.7934 - val_loss: 23.6236 - val_mae: 2.8890\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6767 - mae: 1.8696 - val_loss: 24.8122 - val_mae: 2.9298\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6806 - mae: 1.8422 - val_loss: 23.0443 - val_mae: 2.7718\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4979 - mae: 1.8071 - val_loss: 24.4859 - val_mae: 2.9254\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3440 - mae: 1.7886 - val_loss: 23.5160 - val_mae: 2.8467\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2758 - mae: 1.7517 - val_loss: 23.6532 - val_mae: 2.8310\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2858 - mae: 1.7620 - val_loss: 23.5152 - val_mae: 2.8502\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3097 - mae: 1.7849 - val_loss: 23.7607 - val_mae: 2.8798\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2287 - mae: 1.7633 - val_loss: 23.5534 - val_mae: 2.8207\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.1554 - mae: 1.7362 - val_loss: 23.6973 - val_mae: 2.8750\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1326 - mae: 1.7323 - val_loss: 23.4383 - val_mae: 2.8424\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0939 - mae: 1.7436 - val_loss: 24.0797 - val_mae: 2.8759\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1225 - mae: 1.7666 - val_loss: 23.7615 - val_mae: 2.8458\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3867 - mae: 1.7393 - val_loss: 22.3148 - val_mae: 2.8226\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.2104 - mae: 1.7886 - val_loss: 23.3210 - val_mae: 2.8300\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4110 - mae: 1.8684 - val_loss: 22.8107 - val_mae: 2.7558\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1137 - mae: 1.7518 - val_loss: 22.6868 - val_mae: 2.7459\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.0149 - mae: 1.7260 - val_loss: 23.6670 - val_mae: 2.8440\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9744 - mae: 1.7419 - val_loss: 23.5108 - val_mae: 2.8114\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8858 - mae: 1.7052 - val_loss: 23.4433 - val_mae: 2.8509\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9341 - mae: 1.6954 - val_loss: 23.9740 - val_mae: 2.8981\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1057 - mae: 1.8012 - val_loss: 26.7680 - val_mae: 2.9929\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9960 - mae: 1.7507 - val_loss: 25.3130 - val_mae: 2.9551\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9133 - mae: 1.7172 - val_loss: 24.4576 - val_mae: 2.8848\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8233 - mae: 1.6928 - val_loss: 23.7745 - val_mae: 2.9048\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8682 - mae: 1.6720 - val_loss: 23.9623 - val_mae: 2.8768\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8769 - mae: 1.7225 - val_loss: 24.3912 - val_mae: 2.9037\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9245 - mae: 1.6848 - val_loss: 23.2975 - val_mae: 2.8739\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7802 - mae: 1.6758 - val_loss: 23.7549 - val_mae: 2.8327\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7682 - mae: 1.7213 - val_loss: 24.2745 - val_mae: 2.8301\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7099 - mae: 1.6684 - val_loss: 24.0765 - val_mae: 2.8676\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6980 - mae: 1.6732 - val_loss: 24.3477 - val_mae: 2.8514\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2328 - mae: 1.8270 - val_loss: 24.7152 - val_mae: 2.9079\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6623 - mae: 1.7194 - val_loss: 22.8544 - val_mae: 2.6793\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6602 - mae: 1.6903 - val_loss: 23.6571 - val_mae: 2.8582\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7171 - mae: 1.6910 - val_loss: 23.6205 - val_mae: 2.9035\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5646 - mae: 1.6568 - val_loss: 23.4745 - val_mae: 2.8196\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5715 - mae: 1.6816 - val_loss: 23.6840 - val_mae: 2.8361\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6345 - mae: 1.6644 - val_loss: 24.1471 - val_mae: 2.8735\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5443 - mae: 1.6746 - val_loss: 24.4737 - val_mae: 2.8519\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5135 - mae: 1.6608 - val_loss: 23.4319 - val_mae: 2.8003\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4810 - mae: 1.6342 - val_loss: 23.6088 - val_mae: 2.8457\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4564 - mae: 1.6706 - val_loss: 24.1478 - val_mae: 2.8492\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4646 - mae: 1.6715 - val_loss: 23.7718 - val_mae: 2.8404\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4664 - mae: 1.6296 - val_loss: 23.6993 - val_mae: 2.8436\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4709 - mae: 1.6751 - val_loss: 24.0126 - val_mae: 2.8525\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3915 - mae: 1.6370 - val_loss: 22.9272 - val_mae: 2.7633\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4442 - mae: 1.6337 - val_loss: 23.8480 - val_mae: 2.8960\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3613 - mae: 1.6632 - val_loss: 23.7396 - val_mae: 2.8399\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5136 - mae: 1.6449 - val_loss: 24.2559 - val_mae: 2.9257\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4287 - mae: 1.6579 - val_loss: 24.9979 - val_mae: 2.8735\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2794 - mae: 1.6308 - val_loss: 23.8906 - val_mae: 2.8177\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2337 - mae: 1.6047 - val_loss: 24.0044 - val_mae: 2.9017\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3240 - mae: 1.6083 - val_loss: 23.5455 - val_mae: 2.8551\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2137 - mae: 1.5908 - val_loss: 24.3257 - val_mae: 2.8753\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2663 - mae: 1.6288 - val_loss: 24.8686 - val_mae: 2.8991\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2030 - mae: 1.6111 - val_loss: 24.6076 - val_mae: 2.8908\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4285 - mae: 1.6625 - val_loss: 24.5269 - val_mae: 2.9361\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2992 - mae: 1.6047 - val_loss: 23.6796 - val_mae: 2.8546\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2077 - mae: 1.6276 - val_loss: 24.9905 - val_mae: 2.8879\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1744 - mae: 1.9007 - val_loss: 27.3068 - val_mae: 3.0918\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7561 - mae: 1.7428 - val_loss: 23.9193 - val_mae: 2.7422\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5288 - mae: 1.6900 - val_loss: 23.6666 - val_mae: 2.8457\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1800 - mae: 1.6586 - val_loss: 23.2077 - val_mae: 2.8150\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0816 - mae: 1.6064 - val_loss: 22.7807 - val_mae: 2.8097\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0978 - mae: 1.5965 - val_loss: 23.3659 - val_mae: 2.8028\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0210 - mae: 1.6003 - val_loss: 23.8683 - val_mae: 2.8565\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0288 - mae: 1.5973 - val_loss: 23.3829 - val_mae: 2.8168\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0561 - mae: 1.5822 - val_loss: 23.3877 - val_mae: 2.8561\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0393 - mae: 1.5541 - val_loss: 23.1318 - val_mae: 2.7850\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9671 - mae: 1.5699 - val_loss: 23.1637 - val_mae: 2.8096\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9191 - mae: 1.5829 - val_loss: 23.1554 - val_mae: 2.8214\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8797 - mae: 1.5590 - val_loss: 22.8162 - val_mae: 2.7889\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8422 - mae: 1.5511 - val_loss: 23.1799 - val_mae: 2.8061\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8596 - mae: 1.5677 - val_loss: 24.1356 - val_mae: 2.8573\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8617 - mae: 1.5905 - val_loss: 23.4393 - val_mae: 2.8277\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8615 - mae: 1.5452 - val_loss: 22.3363 - val_mae: 2.7828\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2627 - mae: 1.6938 - val_loss: 23.0688 - val_mae: 2.7384\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8723 - mae: 1.5859 - val_loss: 21.5828 - val_mae: 2.7591\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0666 - mae: 1.5692 - val_loss: 21.9011 - val_mae: 2.7718\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8990 - mae: 1.6182 - val_loss: 22.6928 - val_mae: 2.7477\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8250 - mae: 1.5702 - val_loss: 22.6050 - val_mae: 2.7763\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8803 - mae: 1.5366 - val_loss: 21.7158 - val_mae: 2.6835\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7314 - mae: 1.5484 - val_loss: 22.3831 - val_mae: 2.7612\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7645 - mae: 1.5574 - val_loss: 22.8622 - val_mae: 2.7533\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6698 - mae: 1.5273 - val_loss: 22.7186 - val_mae: 2.7632\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9381 - mae: 1.6398 - val_loss: 23.0170 - val_mae: 2.7729\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7894 - mae: 1.5385 - val_loss: 22.6613 - val_mae: 2.8034\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7618 - mae: 1.5271 - val_loss: 23.5027 - val_mae: 2.7887\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7285 - mae: 1.5707 - val_loss: 22.9391 - val_mae: 2.7598\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6812 - mae: 1.5210 - val_loss: 22.8610 - val_mae: 2.8461\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6699 - mae: 1.5238 - val_loss: 23.0413 - val_mae: 2.7392\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6992 - mae: 1.5732 - val_loss: 22.6903 - val_mae: 2.7461\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6298 - mae: 1.5151 - val_loss: 22.5432 - val_mae: 2.8313\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5494 - mae: 1.4866 - val_loss: 22.8550 - val_mae: 2.7902\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5700 - mae: 1.5337 - val_loss: 23.3306 - val_mae: 2.8069\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6507 - mae: 1.5651 - val_loss: 23.2937 - val_mae: 2.7976\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5933 - mae: 1.5594 - val_loss: 21.9688 - val_mae: 2.6509\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7928 - mae: 1.5831 - val_loss: 21.6529 - val_mae: 2.7603\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6872 - mae: 1.5398 - val_loss: 22.7623 - val_mae: 2.8364\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4871 - mae: 1.5326 - val_loss: 23.0231 - val_mae: 2.7847\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4914 - mae: 1.5405 - val_loss: 23.7972 - val_mae: 2.8698\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3033 - mae: 1.6976 - val_loss: 25.0768 - val_mae: 2.9434\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3941 - mae: 1.7581 - val_loss: 24.7141 - val_mae: 2.8122\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8387 - mae: 1.6459 - val_loss: 22.0519 - val_mae: 2.7440\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7514 - mae: 1.5711 - val_loss: 21.7925 - val_mae: 2.7419\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5670 - mae: 1.5415 - val_loss: 22.5620 - val_mae: 2.8106\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5502 - mae: 1.5118 - val_loss: 21.9723 - val_mae: 2.7549\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4906 - mae: 1.5454 - val_loss: 22.7343 - val_mae: 2.7477\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5545 - mae: 1.5986 - val_loss: 22.2996 - val_mae: 2.7700\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4047 - mae: 1.4937 - val_loss: 21.9110 - val_mae: 2.7210\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3337 - mae: 1.5114 - val_loss: 22.9162 - val_mae: 2.8020\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9482 - mae: 1.6842 - val_loss: 23.7397 - val_mae: 2.8248\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7826 - mae: 1.5985 - val_loss: 22.4713 - val_mae: 2.7564\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5158 - mae: 1.5491 - val_loss: 22.8149 - val_mae: 2.7914\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4078 - mae: 1.5366 - val_loss: 21.6241 - val_mae: 2.7442\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3109 - mae: 1.4789 - val_loss: 22.1138 - val_mae: 2.7527\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3077 - mae: 1.5199 - val_loss: 22.0657 - val_mae: 2.7193\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3242 - mae: 1.4917 - val_loss: 21.6048 - val_mae: 2.6753\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2971 - mae: 1.5017 - val_loss: 22.3079 - val_mae: 2.7282\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3477 - mae: 1.5700 - val_loss: 23.0457 - val_mae: 2.7753\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3865 - mae: 1.5001 - val_loss: 21.8447 - val_mae: 2.6933\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2150 - mae: 1.4824 - val_loss: 22.7797 - val_mae: 2.7898\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1842 - mae: 1.4800 - val_loss: 21.9315 - val_mae: 2.7244\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1687 - mae: 1.4459 - val_loss: 21.9111 - val_mae: 2.7824\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1643 - mae: 1.4872 - val_loss: 21.9508 - val_mae: 2.7245\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4660 - mae: 1.5196 - val_loss: 22.1742 - val_mae: 2.7104\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1440 - mae: 1.4701 - val_loss: 22.4051 - val_mae: 2.8165\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0527 - mae: 1.4542 - val_loss: 22.4460 - val_mae: 2.7401\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0750 - mae: 1.4546 - val_loss: 22.1048 - val_mae: 2.7281\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0225 - mae: 1.4571 - val_loss: 21.9269 - val_mae: 2.7296\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2803 - mae: 1.5267 - val_loss: 22.2110 - val_mae: 2.7586\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0635 - mae: 1.4351 - val_loss: 22.2331 - val_mae: 2.8321\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.2740 - mae: 1.5075 - val_loss: 22.6930 - val_mae: 2.7380\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3228 - mae: 1.5108 - val_loss: 21.5038 - val_mae: 2.6772\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1682912.5000 - mae: 1249.1179\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 14ms/step - loss: 555.8318 - mae: 21.5671 - val_loss: 497.4063 - val_mae: 20.5014\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 525.9417 - mae: 20.7978 - val_loss: 464.7268 - val_mae: 19.6290\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 491.4408 - mae: 19.8842 - val_loss: 425.0565 - val_mae: 18.5349\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 446.2063 - mae: 18.7222 - val_loss: 375.1318 - val_mae: 17.1865\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 389.4605 - mae: 17.2301 - val_loss: 313.4965 - val_mae: 15.4561\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 321.4371 - mae: 15.4747 - val_loss: 242.8472 - val_mae: 13.4588\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 242.8447 - mae: 13.2253 - val_loss: 171.6211 - val_mae: 11.2836\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 168.6156 - mae: 10.7161 - val_loss: 109.9037 - val_mae: 8.7358\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 109.3918 - mae: 8.3908 - val_loss: 71.7392 - val_mae: 6.8972\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 74.4220 - mae: 6.7410 - val_loss: 53.9940 - val_mae: 5.6582\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 58.6425 - mae: 5.6802 - val_loss: 44.7930 - val_mae: 4.9537\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 47.7471 - mae: 4.9975 - val_loss: 37.3426 - val_mae: 4.5251\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 39.6817 - mae: 4.4965 - val_loss: 31.3924 - val_mae: 4.1653\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34.9962 - mae: 4.2115 - val_loss: 28.2853 - val_mae: 3.9415\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31.9311 - mae: 4.0280 - val_loss: 26.2799 - val_mae: 3.7749\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30.0166 - mae: 3.8887 - val_loss: 24.9490 - val_mae: 3.6945\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.1893 - mae: 3.7635 - val_loss: 23.9020 - val_mae: 3.5823\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.9952 - mae: 3.6853 - val_loss: 23.3371 - val_mae: 3.5431\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 25.9054 - mae: 3.6397 - val_loss: 22.1079 - val_mae: 3.4017\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.8340 - mae: 3.5523 - val_loss: 21.4350 - val_mae: 3.3305\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.8898 - mae: 3.4649 - val_loss: 20.7692 - val_mae: 3.2474\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.0603 - mae: 3.4046 - val_loss: 20.3880 - val_mae: 3.2348\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.3123 - mae: 3.3537 - val_loss: 19.9193 - val_mae: 3.2102\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.6491 - mae: 3.3286 - val_loss: 19.7595 - val_mae: 3.2424\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 21.1771 - mae: 3.3292 - val_loss: 19.3942 - val_mae: 3.2923\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 20.5082 - mae: 3.2736 - val_loss: 18.5131 - val_mae: 3.1828\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.7007 - mae: 3.1677 - val_loss: 17.9289 - val_mae: 3.0233\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.2970 - mae: 3.1101 - val_loss: 17.6264 - val_mae: 3.0317\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.7764 - mae: 3.0817 - val_loss: 17.4679 - val_mae: 3.0893\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.3944 - mae: 3.0586 - val_loss: 17.2254 - val_mae: 3.0395\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.0858 - mae: 3.0087 - val_loss: 17.1026 - val_mae: 3.0080\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.7053 - mae: 2.9657 - val_loss: 16.9932 - val_mae: 2.9965\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17.4952 - mae: 2.9332 - val_loss: 16.8017 - val_mae: 2.9604\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.0680 - mae: 2.9081 - val_loss: 16.8112 - val_mae: 3.0115\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.0086 - mae: 2.9234 - val_loss: 16.6928 - val_mae: 3.0233\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 16.7167 - mae: 2.8855 - val_loss: 16.4337 - val_mae: 2.9646\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3855 - mae: 2.8307 - val_loss: 16.2198 - val_mae: 2.9368\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.1247 - mae: 2.7973 - val_loss: 15.8670 - val_mae: 2.8952\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.8699 - mae: 2.7946 - val_loss: 15.8997 - val_mae: 2.9355\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.6545 - mae: 2.7956 - val_loss: 15.8411 - val_mae: 2.9425\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.4470 - mae: 2.7741 - val_loss: 15.6480 - val_mae: 2.9148\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.2197 - mae: 2.7435 - val_loss: 15.4806 - val_mae: 2.8884\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0426 - mae: 2.7065 - val_loss: 15.6719 - val_mae: 2.9215\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.8348 - mae: 2.6856 - val_loss: 15.2933 - val_mae: 2.8731\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.6276 - mae: 2.6914 - val_loss: 15.0444 - val_mae: 2.8235\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.4447 - mae: 2.6570 - val_loss: 15.2036 - val_mae: 2.8318\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4248 - mae: 2.6521 - val_loss: 15.2416 - val_mae: 2.8687\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2473 - mae: 2.6506 - val_loss: 15.1926 - val_mae: 2.8676\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.1329 - mae: 2.6280 - val_loss: 15.1273 - val_mae: 2.8542\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.9193 - mae: 2.5792 - val_loss: 14.5076 - val_mae: 2.7670\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8513 - mae: 2.6078 - val_loss: 14.5325 - val_mae: 2.8113\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5515 - mae: 2.5750 - val_loss: 14.3336 - val_mae: 2.7864\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5293 - mae: 2.5849 - val_loss: 13.9637 - val_mae: 2.7563\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.4814 - mae: 2.5546 - val_loss: 14.1692 - val_mae: 2.7611\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2745 - mae: 2.5269 - val_loss: 14.0489 - val_mae: 2.7619\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0440 - mae: 2.5315 - val_loss: 14.1264 - val_mae: 2.7786\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9463 - mae: 2.5284 - val_loss: 13.9148 - val_mae: 2.7489\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.8118 - mae: 2.5129 - val_loss: 13.8626 - val_mae: 2.7417\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7307 - mae: 2.4980 - val_loss: 13.7263 - val_mae: 2.7099\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7284 - mae: 2.4671 - val_loss: 13.6247 - val_mae: 2.6785\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.7002 - mae: 2.4651 - val_loss: 13.3182 - val_mae: 2.6595\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4613 - mae: 2.4655 - val_loss: 13.5732 - val_mae: 2.7201\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2878 - mae: 2.4712 - val_loss: 13.3084 - val_mae: 2.6894\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.2887 - mae: 2.4976 - val_loss: 13.2872 - val_mae: 2.7086\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.2752 - mae: 2.5183 - val_loss: 13.1797 - val_mae: 2.6976\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2020 - mae: 2.4783 - val_loss: 13.1599 - val_mae: 2.6626\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.9623 - mae: 2.4212 - val_loss: 12.7746 - val_mae: 2.6197\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.8360 - mae: 2.4112 - val_loss: 12.6982 - val_mae: 2.6273\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.7574 - mae: 2.4116 - val_loss: 12.5064 - val_mae: 2.6066\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.6606 - mae: 2.3872 - val_loss: 12.3249 - val_mae: 2.5829\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7223 - mae: 2.3886 - val_loss: 12.5113 - val_mae: 2.6208\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4940 - mae: 2.3914 - val_loss: 12.2600 - val_mae: 2.6034\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.4303 - mae: 2.3943 - val_loss: 12.1353 - val_mae: 2.5773\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5400 - mae: 2.3670 - val_loss: 12.5359 - val_mae: 2.6198\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3394 - mae: 2.3510 - val_loss: 12.2489 - val_mae: 2.6021\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2523 - mae: 2.3642 - val_loss: 12.0436 - val_mae: 2.5539\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1631 - mae: 2.3570 - val_loss: 12.1007 - val_mae: 2.5880\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.1064 - mae: 2.3586 - val_loss: 12.2130 - val_mae: 2.6049\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2043 - mae: 2.3776 - val_loss: 11.8975 - val_mae: 2.5594\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.9957 - mae: 2.3302 - val_loss: 11.8580 - val_mae: 2.5495\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8332 - mae: 2.3007 - val_loss: 11.8244 - val_mae: 2.5613\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9018 - mae: 2.3563 - val_loss: 12.0551 - val_mae: 2.5815\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8541 - mae: 2.3322 - val_loss: 11.9682 - val_mae: 2.5782\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7210 - mae: 2.3174 - val_loss: 11.8926 - val_mae: 2.5711\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.5911 - mae: 2.2945 - val_loss: 11.9142 - val_mae: 2.5768\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5731 - mae: 2.2702 - val_loss: 11.5698 - val_mae: 2.5396\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4645 - mae: 2.2999 - val_loss: 11.6471 - val_mae: 2.5593\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4406 - mae: 2.2988 - val_loss: 11.3978 - val_mae: 2.5157\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3781 - mae: 2.2798 - val_loss: 11.5684 - val_mae: 2.5485\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2961 - mae: 2.2706 - val_loss: 11.4096 - val_mae: 2.5216\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2175 - mae: 2.2677 - val_loss: 11.4676 - val_mae: 2.5386\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1267 - mae: 2.2552 - val_loss: 11.3504 - val_mae: 2.5287\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1101 - mae: 2.2532 - val_loss: 11.0340 - val_mae: 2.4688\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1022 - mae: 2.2687 - val_loss: 11.2527 - val_mae: 2.5101\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1806 - mae: 2.2487 - val_loss: 11.2621 - val_mae: 2.5150\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0371 - mae: 2.2692 - val_loss: 11.1440 - val_mae: 2.5002\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9927 - mae: 2.2586 - val_loss: 10.9494 - val_mae: 2.4585\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.8820 - mae: 2.2102 - val_loss: 11.3207 - val_mae: 2.5269\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0652 - mae: 2.2263 - val_loss: 10.9897 - val_mae: 2.4956\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.7118 - mae: 2.2200 - val_loss: 11.0153 - val_mae: 2.4841\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0918 - mae: 2.3298 - val_loss: 11.2890 - val_mae: 2.5056\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1847 - mae: 2.2808 - val_loss: 12.0361 - val_mae: 2.6055\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7449 - mae: 2.2397 - val_loss: 10.7904 - val_mae: 2.4550\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8170 - mae: 2.2515 - val_loss: 10.5909 - val_mae: 2.4140\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6422 - mae: 2.2061 - val_loss: 10.6584 - val_mae: 2.4313\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4344 - mae: 2.1936 - val_loss: 10.7734 - val_mae: 2.4619\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4177 - mae: 2.1995 - val_loss: 10.8026 - val_mae: 2.4691\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3509 - mae: 2.1849 - val_loss: 10.5847 - val_mae: 2.4339\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.3774 - mae: 2.1823 - val_loss: 10.8520 - val_mae: 2.4761\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2744 - mae: 2.1814 - val_loss: 10.5249 - val_mae: 2.4233\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.2295 - mae: 2.1643 - val_loss: 10.5525 - val_mae: 2.4311\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1661 - mae: 2.1476 - val_loss: 10.6285 - val_mae: 2.4449\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2118 - mae: 2.1899 - val_loss: 10.3134 - val_mae: 2.4208\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2225 - mae: 2.1932 - val_loss: 10.3607 - val_mae: 2.4311\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0589 - mae: 2.1578 - val_loss: 10.3087 - val_mae: 2.4200\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9652 - mae: 2.1406 - val_loss: 10.5355 - val_mae: 2.4593\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0200 - mae: 2.1702 - val_loss: 10.1869 - val_mae: 2.3928\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8757 - mae: 2.1321 - val_loss: 10.4072 - val_mae: 2.4188\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9336 - mae: 2.1399 - val_loss: 10.5679 - val_mae: 2.4390\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8865 - mae: 2.1484 - val_loss: 10.2080 - val_mae: 2.3927\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7986 - mae: 2.1066 - val_loss: 10.6589 - val_mae: 2.4563\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8496 - mae: 2.1099 - val_loss: 10.0874 - val_mae: 2.3768\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.6450 - mae: 2.1161 - val_loss: 10.2407 - val_mae: 2.3972\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8015 - mae: 2.1412 - val_loss: 10.4823 - val_mae: 2.4334\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6973 - mae: 2.1315 - val_loss: 10.0599 - val_mae: 2.3738\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5437 - mae: 2.1019 - val_loss: 10.0383 - val_mae: 2.3763\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4962 - mae: 2.0817 - val_loss: 10.0785 - val_mae: 2.3775\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.4198 - mae: 2.0744 - val_loss: 10.0791 - val_mae: 2.3778\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3813 - mae: 2.0988 - val_loss: 10.1461 - val_mae: 2.3938\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3748 - mae: 2.0850 - val_loss: 9.8737 - val_mae: 2.3483\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6519 - mae: 2.1320 - val_loss: 9.7361 - val_mae: 2.3266\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3477 - mae: 2.1089 - val_loss: 10.1225 - val_mae: 2.3825\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2938 - mae: 2.0772 - val_loss: 9.9448 - val_mae: 2.3649\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2165 - mae: 2.0789 - val_loss: 10.0550 - val_mae: 2.3824\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2262 - mae: 2.0893 - val_loss: 10.1413 - val_mae: 2.3891\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1827 - mae: 2.0682 - val_loss: 10.1069 - val_mae: 2.3842\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4366 - mae: 2.0786 - val_loss: 10.3397 - val_mae: 2.3975\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1006 - mae: 2.0481 - val_loss: 9.6188 - val_mae: 2.3034\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2088 - mae: 2.0711 - val_loss: 9.9994 - val_mae: 2.3456\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0072 - mae: 2.0486 - val_loss: 9.9960 - val_mae: 2.3390\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9569 - mae: 2.0519 - val_loss: 9.8630 - val_mae: 2.3213\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0233 - mae: 2.0992 - val_loss: 9.9410 - val_mae: 2.3251\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9980 - mae: 2.0536 - val_loss: 9.8627 - val_mae: 2.3140\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9323 - mae: 2.0348 - val_loss: 9.8155 - val_mae: 2.3106\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7793 - mae: 2.0425 - val_loss: 9.8076 - val_mae: 2.3149\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7841 - mae: 2.1151 - val_loss: 11.1770 - val_mae: 2.3791\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9761 - mae: 2.0634 - val_loss: 10.3205 - val_mae: 2.3876\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0180 - mae: 2.1050 - val_loss: 10.2037 - val_mae: 2.3585\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9116 - mae: 2.0436 - val_loss: 10.2745 - val_mae: 2.3677\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7457 - mae: 2.0628 - val_loss: 9.5979 - val_mae: 2.2797\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5739 - mae: 2.0034 - val_loss: 9.6175 - val_mae: 2.2640\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5471 - mae: 2.0004 - val_loss: 9.5412 - val_mae: 2.2643\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4969 - mae: 2.0038 - val_loss: 9.2661 - val_mae: 2.2392\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3680 - mae: 1.9998 - val_loss: 9.4040 - val_mae: 2.2582\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3911 - mae: 2.0003 - val_loss: 9.5900 - val_mae: 2.2770\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7568 - mae: 2.0490 - val_loss: 10.1124 - val_mae: 2.2975\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5175 - mae: 1.9887 - val_loss: 9.7588 - val_mae: 2.2472\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5610 - mae: 2.0063 - val_loss: 9.8998 - val_mae: 2.2990\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4395 - mae: 2.0046 - val_loss: 9.8156 - val_mae: 2.2708\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4325 - mae: 2.0040 - val_loss: 9.3599 - val_mae: 2.2403\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2040 - mae: 1.9614 - val_loss: 9.5671 - val_mae: 2.2797\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1926 - mae: 1.9765 - val_loss: 9.2389 - val_mae: 2.2350\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9860 - mae: 1.9308 - val_loss: 9.6581 - val_mae: 2.2735\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0952 - mae: 1.9446 - val_loss: 9.3564 - val_mae: 2.2432\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9882 - mae: 1.9297 - val_loss: 9.1386 - val_mae: 2.2156\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0055 - mae: 1.9385 - val_loss: 9.0729 - val_mae: 2.2316\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9201 - mae: 1.9284 - val_loss: 9.1072 - val_mae: 2.2154\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8760 - mae: 1.9233 - val_loss: 9.1055 - val_mae: 2.2396\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7629 - mae: 1.9027 - val_loss: 8.9367 - val_mae: 2.1831\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8530 - mae: 1.9075 - val_loss: 9.0690 - val_mae: 2.2073\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7477 - mae: 1.8945 - val_loss: 8.9477 - val_mae: 2.1940\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7422 - mae: 1.8934 - val_loss: 9.0378 - val_mae: 2.2063\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.6763 - mae: 1.8935 - val_loss: 8.9965 - val_mae: 2.2089\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7262 - mae: 1.9009 - val_loss: 9.1558 - val_mae: 2.2259\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7281 - mae: 1.8982 - val_loss: 9.2671 - val_mae: 2.2334\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6616 - mae: 1.9085 - val_loss: 9.0278 - val_mae: 2.2393\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6448 - mae: 1.8971 - val_loss: 9.1304 - val_mae: 2.1951\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6718 - mae: 1.8974 - val_loss: 9.1300 - val_mae: 2.2178\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6530 - mae: 1.8949 - val_loss: 8.9100 - val_mae: 2.1706\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5357 - mae: 1.8721 - val_loss: 9.3763 - val_mae: 2.2442\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5742 - mae: 1.8747 - val_loss: 9.3102 - val_mae: 2.2303\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5435 - mae: 1.8774 - val_loss: 9.1363 - val_mae: 2.2043\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5902 - mae: 1.8713 - val_loss: 9.2442 - val_mae: 2.2087\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4313 - mae: 1.8653 - val_loss: 8.8141 - val_mae: 2.1632\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4852 - mae: 1.8805 - val_loss: 9.0340 - val_mae: 2.1929\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4476 - mae: 1.8590 - val_loss: 8.9038 - val_mae: 2.1467\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3353 - mae: 1.8373 - val_loss: 9.1673 - val_mae: 2.2124\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3345 - mae: 1.8470 - val_loss: 8.7823 - val_mae: 2.1595\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.3337 - mae: 2.0024 - val_loss: 9.2883 - val_mae: 2.2086\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4638 - mae: 1.8903 - val_loss: 9.9884 - val_mae: 2.2324\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4996 - mae: 1.8931 - val_loss: 9.1111 - val_mae: 2.1714\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1877 - mae: 1.8522 - val_loss: 9.0934 - val_mae: 2.2108\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0934 - mae: 1.8436 - val_loss: 9.5263 - val_mae: 2.2128\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2472 - mae: 1.8348 - val_loss: 8.7616 - val_mae: 2.1428\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3852 - mae: 1.8749 - val_loss: 8.7712 - val_mae: 2.1570\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4246 - mae: 1.8805 - val_loss: 10.0155 - val_mae: 2.2888\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.1536 - mae: 1.8356 - val_loss: 8.8312 - val_mae: 2.1193\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0305 - mae: 1.8249 - val_loss: 8.8392 - val_mae: 2.1077\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9641 - mae: 1.7989 - val_loss: 8.6966 - val_mae: 2.1089\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0873 - mae: 1.8454 - val_loss: 8.9801 - val_mae: 2.1682\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9710 - mae: 1.8145 - val_loss: 9.1555 - val_mae: 2.1180\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0614 - mae: 1.8150 - val_loss: 8.8740 - val_mae: 2.1376\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8543 - mae: 1.7888 - val_loss: 8.5678 - val_mae: 2.0998\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8795 - mae: 1.8055 - val_loss: 8.9138 - val_mae: 2.1648\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8840 - mae: 1.8146 - val_loss: 8.8887 - val_mae: 2.1194\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8603 - mae: 1.8103 - val_loss: 8.4329 - val_mae: 2.0718\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8560 - mae: 1.7716 - val_loss: 8.8266 - val_mae: 2.1045\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8813 - mae: 1.8252 - val_loss: 8.7302 - val_mae: 2.1474\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6535 - mae: 1.7705 - val_loss: 8.6590 - val_mae: 2.1145\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7277 - mae: 1.7864 - val_loss: 8.9236 - val_mae: 2.1560\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6112 - mae: 1.7727 - val_loss: 8.6809 - val_mae: 2.1139\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6733 - mae: 1.7646 - val_loss: 8.7833 - val_mae: 2.1112\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6419 - mae: 1.7594 - val_loss: 8.9325 - val_mae: 2.1515\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6973 - mae: 1.7887 - val_loss: 8.7388 - val_mae: 2.0907\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5335 - mae: 1.7540 - val_loss: 8.9846 - val_mae: 2.1278\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6836 - mae: 1.7691 - val_loss: 8.9442 - val_mae: 2.1035\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7439 - mae: 1.8091 - val_loss: 8.8096 - val_mae: 2.1509\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4256 - mae: 1.7354 - val_loss: 8.7225 - val_mae: 2.0750\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6773 - mae: 1.7662 - val_loss: 8.5657 - val_mae: 2.0660\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4398 - mae: 1.7342 - val_loss: 9.0081 - val_mae: 2.1269\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4592 - mae: 1.7252 - val_loss: 8.6916 - val_mae: 2.0796\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4274 - mae: 1.7232 - val_loss: 8.8627 - val_mae: 2.1031\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4590 - mae: 1.7453 - val_loss: 8.7529 - val_mae: 2.1047\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5366 - mae: 1.7315 - val_loss: 9.0138 - val_mae: 2.1156\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3763 - mae: 1.7180 - val_loss: 8.8105 - val_mae: 2.1296\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4033 - mae: 1.7422 - val_loss: 8.8597 - val_mae: 2.1131\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.3279 - mae: 1.7136 - val_loss: 8.7075 - val_mae: 2.0917\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2741 - mae: 1.7080 - val_loss: 8.6600 - val_mae: 2.0873\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2739 - mae: 1.7031 - val_loss: 8.9044 - val_mae: 2.1171\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3474 - mae: 1.7400 - val_loss: 8.8495 - val_mae: 2.1459\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2497 - mae: 1.7075 - val_loss: 8.5459 - val_mae: 2.0802\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2531 - mae: 1.7170 - val_loss: 8.8855 - val_mae: 2.1288\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2316 - mae: 1.7024 - val_loss: 8.6416 - val_mae: 2.0811\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1605 - mae: 1.7032 - val_loss: 8.6818 - val_mae: 2.0937\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1804 - mae: 1.6892 - val_loss: 8.7358 - val_mae: 2.0822\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1565 - mae: 1.6778 - val_loss: 9.1930 - val_mae: 2.1651\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2471 - mae: 1.6847 - val_loss: 8.9674 - val_mae: 2.1083\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1510 - mae: 1.6750 - val_loss: 8.6362 - val_mae: 2.0674\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0651 - mae: 1.6709 - val_loss: 8.6324 - val_mae: 2.0761\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1018 - mae: 1.6731 - val_loss: 8.7119 - val_mae: 2.0872\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9748 - mae: 1.6513 - val_loss: 8.7273 - val_mae: 2.1009\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0466 - mae: 1.6776 - val_loss: 8.7175 - val_mae: 2.0756\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0098 - mae: 1.6458 - val_loss: 8.7849 - val_mae: 2.0773\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9739 - mae: 1.6461 - val_loss: 9.0829 - val_mae: 2.0975\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1330 - mae: 1.6834 - val_loss: 8.8891 - val_mae: 2.1222\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9666 - mae: 1.6640 - val_loss: 8.9736 - val_mae: 2.1435\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0083 - mae: 1.6684 - val_loss: 8.8266 - val_mae: 2.1015\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9511 - mae: 1.6651 - val_loss: 8.5849 - val_mae: 2.0635\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8822 - mae: 1.6491 - val_loss: 8.6972 - val_mae: 2.0541\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8720 - mae: 1.6491 - val_loss: 9.1373 - val_mae: 2.0987\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8378 - mae: 1.6300 - val_loss: 8.9626 - val_mae: 2.1356\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8925 - mae: 1.6646 - val_loss: 8.7508 - val_mae: 2.1141\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7905 - mae: 1.6361 - val_loss: 8.6742 - val_mae: 2.0630\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0162 - mae: 1.6724 - val_loss: 9.3821 - val_mae: 2.1925\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9956 - mae: 1.6310 - val_loss: 8.9919 - val_mae: 2.1518\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7431 - mae: 1.8151 - val_loss: 9.2518 - val_mae: 2.1249\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7689 - mae: 1.7980 - val_loss: 10.7740 - val_mae: 2.2939\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.9318 - mae: 1.6638 - val_loss: 9.1154 - val_mae: 2.1252\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8553 - mae: 1.6743 - val_loss: 9.2350 - val_mae: 2.1634\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7836 - mae: 1.6211 - val_loss: 9.3853 - val_mae: 2.1483\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6950 - mae: 1.6089 - val_loss: 8.9071 - val_mae: 2.1060\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5906 - mae: 1.6012 - val_loss: 8.9775 - val_mae: 2.1186\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5985 - mae: 1.5964 - val_loss: 8.7355 - val_mae: 2.0918\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5546 - mae: 1.5927 - val_loss: 8.7978 - val_mae: 2.1092\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5746 - mae: 1.6064 - val_loss: 8.8011 - val_mae: 2.1025\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6294 - mae: 1.5990 - val_loss: 8.8695 - val_mae: 2.1076\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7920 - mae: 1.6682 - val_loss: 9.0873 - val_mae: 2.1705\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5676 - mae: 1.6182 - val_loss: 8.9894 - val_mae: 2.1241\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6519 - mae: 1.6047 - val_loss: 8.8027 - val_mae: 2.0786\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4984 - mae: 1.5830 - val_loss: 8.6122 - val_mae: 2.0590\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4548 - mae: 1.5485 - val_loss: 9.1259 - val_mae: 2.0975\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4622 - mae: 1.5673 - val_loss: 8.7734 - val_mae: 2.0714\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4539 - mae: 1.5683 - val_loss: 8.8245 - val_mae: 2.0733\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5099 - mae: 1.5539 - val_loss: 9.2516 - val_mae: 2.0978\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4702 - mae: 1.5656 - val_loss: 8.6202 - val_mae: 2.0489\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5291 - mae: 1.5946 - val_loss: 9.1139 - val_mae: 2.1222\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5387 - mae: 1.5708 - val_loss: 9.1279 - val_mae: 2.1501\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4178 - mae: 1.5649 - val_loss: 8.8260 - val_mae: 2.0783\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3215 - mae: 1.5488 - val_loss: 8.7164 - val_mae: 2.0690\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3151 - mae: 1.5582 - val_loss: 8.8375 - val_mae: 2.0926\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5130 - mae: 1.5465 - val_loss: 8.8603 - val_mae: 2.1016\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3024 - mae: 1.5387 - val_loss: 8.7281 - val_mae: 2.0963\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3442 - mae: 1.5402 - val_loss: 8.8795 - val_mae: 2.0827\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3432 - mae: 1.5687 - val_loss: 9.0799 - val_mae: 2.1215\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5653 - mae: 1.5417 - val_loss: 9.2128 - val_mae: 2.1176\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4578 - mae: 1.5514 - val_loss: 8.6045 - val_mae: 2.0859\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2207 - mae: 1.5516 - val_loss: 8.8654 - val_mae: 2.1119\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3137 - mae: 1.5371 - val_loss: 8.7597 - val_mae: 2.0987\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2112 - mae: 1.5343 - val_loss: 8.8877 - val_mae: 2.1445\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1777 - mae: 1.5247 - val_loss: 8.5867 - val_mae: 2.0441\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3520 - mae: 1.5313 - val_loss: 8.5480 - val_mae: 2.0482\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3187 - mae: 1.5581 - val_loss: 8.6462 - val_mae: 2.0594\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1632 - mae: 1.5137 - val_loss: 8.9741 - val_mae: 2.1218\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1752 - mae: 1.5136 - val_loss: 8.4444 - val_mae: 2.0464\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1103 - mae: 1.5071 - val_loss: 8.4510 - val_mae: 2.0480\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.1494 - mae: 1.4983 - val_loss: 8.7635 - val_mae: 2.1006\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2429 - mae: 1.5829 - val_loss: 8.7117 - val_mae: 2.1323\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1603 - mae: 1.5230 - val_loss: 9.1420 - val_mae: 2.1133\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1622 - mae: 1.5009 - val_loss: 8.7452 - val_mae: 2.0840\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1562 - mae: 1.5182 - val_loss: 8.5272 - val_mae: 2.0312\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5689211.5000 - mae: 2372.9824\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 16ms/step - loss: 561.0863 - mae: 21.8701 - val_loss: 459.3307 - val_mae: 19.7874\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 521.9145 - mae: 21.0217 - val_loss: 422.0389 - val_mae: 18.8790\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 474.7890 - mae: 19.9573 - val_loss: 376.2764 - val_mae: 17.7001\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 418.3864 - mae: 18.5709 - val_loss: 320.5807 - val_mae: 16.1403\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 349.6863 - mae: 16.7610 - val_loss: 255.6273 - val_mae: 14.1107\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 271.9101 - mae: 14.5006 - val_loss: 188.3544 - val_mae: 11.9286\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 195.4828 - mae: 11.8910 - val_loss: 128.5880 - val_mae: 9.6874\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 130.4917 - mae: 9.3076 - val_loss: 85.6090 - val_mae: 7.8182\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 86.5986 - mae: 7.3631 - val_loss: 62.9819 - val_mae: 6.6270\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 65.3141 - mae: 6.1550 - val_loss: 51.6311 - val_mae: 5.8646\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.7814 - mae: 5.4155 - val_loss: 43.1594 - val_mae: 5.3375\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 44.5841 - mae: 4.8765 - val_loss: 35.1236 - val_mae: 4.8057\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.8604 - mae: 4.4858 - val_loss: 29.1131 - val_mae: 4.3724\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.2181 - mae: 4.1649 - val_loss: 24.5657 - val_mae: 3.9840\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30.2265 - mae: 3.9249 - val_loss: 21.9468 - val_mae: 3.7446\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 28.1372 - mae: 3.7738 - val_loss: 20.1074 - val_mae: 3.5528\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.5452 - mae: 3.6536 - val_loss: 18.9742 - val_mae: 3.4274\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.4543 - mae: 3.5857 - val_loss: 17.9800 - val_mae: 3.3331\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.3391 - mae: 3.4923 - val_loss: 17.2748 - val_mae: 3.2689\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 23.6342 - mae: 3.4318 - val_loss: 16.6993 - val_mae: 3.2079\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.8838 - mae: 3.3833 - val_loss: 16.1692 - val_mae: 3.1646\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.0770 - mae: 3.3786 - val_loss: 16.0621 - val_mae: 3.1601\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.5158 - mae: 3.3493 - val_loss: 15.0774 - val_mae: 3.0515\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 20.9310 - mae: 3.2766 - val_loss: 14.5106 - val_mae: 2.9871\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.6525 - mae: 3.2085 - val_loss: 13.9267 - val_mae: 2.9339\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 20.0154 - mae: 3.1659 - val_loss: 14.0439 - val_mae: 2.9289\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.5317 - mae: 3.1880 - val_loss: 14.0980 - val_mae: 2.9188\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.1497 - mae: 3.1650 - val_loss: 13.4880 - val_mae: 2.8492\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.6891 - mae: 3.1022 - val_loss: 13.0532 - val_mae: 2.7929\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.2802 - mae: 3.0491 - val_loss: 12.8270 - val_mae: 2.7658\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.0443 - mae: 3.0347 - val_loss: 12.9791 - val_mae: 2.7511\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.6175 - mae: 3.0469 - val_loss: 13.0535 - val_mae: 2.7474\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.3809 - mae: 3.0176 - val_loss: 12.4890 - val_mae: 2.7052\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.0669 - mae: 2.9631 - val_loss: 12.1148 - val_mae: 2.6655\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.6935 - mae: 2.9041 - val_loss: 11.7173 - val_mae: 2.6053\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.3979 - mae: 2.8789 - val_loss: 11.6103 - val_mae: 2.5958\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.2033 - mae: 2.8549 - val_loss: 11.7227 - val_mae: 2.6179\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.9318 - mae: 2.8295 - val_loss: 11.7286 - val_mae: 2.6054\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.6856 - mae: 2.8213 - val_loss: 11.5860 - val_mae: 2.5718\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.4112 - mae: 2.7801 - val_loss: 11.0228 - val_mae: 2.5160\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.1792 - mae: 2.7361 - val_loss: 10.9882 - val_mae: 2.5170\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.9525 - mae: 2.7275 - val_loss: 10.9909 - val_mae: 2.5132\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7600 - mae: 2.7256 - val_loss: 11.0162 - val_mae: 2.5166\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.5418 - mae: 2.7070 - val_loss: 10.7571 - val_mae: 2.5025\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.2889 - mae: 2.6777 - val_loss: 10.3920 - val_mae: 2.4568\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.2638 - mae: 2.6750 - val_loss: 10.7128 - val_mae: 2.4980\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0529 - mae: 2.6830 - val_loss: 10.8011 - val_mae: 2.5066\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8974 - mae: 2.6519 - val_loss: 10.3938 - val_mae: 2.4608\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.7241 - mae: 2.6370 - val_loss: 10.7542 - val_mae: 2.5079\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.5759 - mae: 2.6176 - val_loss: 10.1472 - val_mae: 2.4443\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.3905 - mae: 2.5802 - val_loss: 10.0874 - val_mae: 2.4446\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.3760 - mae: 2.6305 - val_loss: 11.3016 - val_mae: 2.5913\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1548 - mae: 2.6223 - val_loss: 10.1785 - val_mae: 2.4507\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9886 - mae: 2.5598 - val_loss: 9.6976 - val_mae: 2.3941\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8432 - mae: 2.5413 - val_loss: 9.8783 - val_mae: 2.4242\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6365 - mae: 2.5361 - val_loss: 10.0331 - val_mae: 2.4448\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5096 - mae: 2.5363 - val_loss: 10.0599 - val_mae: 2.4441\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5450 - mae: 2.5363 - val_loss: 10.1729 - val_mae: 2.4535\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4203 - mae: 2.5135 - val_loss: 9.6708 - val_mae: 2.3960\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.6173 - mae: 2.5601 - val_loss: 11.4957 - val_mae: 2.6153\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.0743 - mae: 2.6494 - val_loss: 12.2714 - val_mae: 2.6941\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.3590 - mae: 2.5504 - val_loss: 9.8425 - val_mae: 2.4187\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0742 - mae: 2.5144 - val_loss: 9.5174 - val_mae: 2.3807\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8619 - mae: 2.4993 - val_loss: 10.3955 - val_mae: 2.4946\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.8015 - mae: 2.4994 - val_loss: 10.5169 - val_mae: 2.5028\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.6726 - mae: 2.4744 - val_loss: 9.7237 - val_mae: 2.4141\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5036 - mae: 2.4576 - val_loss: 9.9889 - val_mae: 2.4479\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.5716 - mae: 2.4288 - val_loss: 9.0929 - val_mae: 2.3297\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.3799 - mae: 2.4122 - val_loss: 9.3711 - val_mae: 2.3625\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3245 - mae: 2.4212 - val_loss: 9.7882 - val_mae: 2.4330\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.1859 - mae: 2.4189 - val_loss: 9.4519 - val_mae: 2.3848\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.1465 - mae: 2.4052 - val_loss: 9.6868 - val_mae: 2.4068\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.0493 - mae: 2.3936 - val_loss: 9.4457 - val_mae: 2.3665\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0046 - mae: 2.3816 - val_loss: 8.9358 - val_mae: 2.3097\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.9582 - mae: 2.3773 - val_loss: 9.2702 - val_mae: 2.3447\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8240 - mae: 2.3664 - val_loss: 9.4008 - val_mae: 2.3489\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.8041 - mae: 2.3465 - val_loss: 8.8738 - val_mae: 2.2858\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7710 - mae: 2.3529 - val_loss: 9.1148 - val_mae: 2.3196\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.6330 - mae: 2.3466 - val_loss: 9.2324 - val_mae: 2.3358\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.9043 - mae: 2.3999 - val_loss: 10.7184 - val_mae: 2.5512\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7006 - mae: 2.3880 - val_loss: 9.4841 - val_mae: 2.3793\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5657 - mae: 2.3494 - val_loss: 8.9670 - val_mae: 2.2918\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4479 - mae: 2.3265 - val_loss: 9.0423 - val_mae: 2.3060\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4119 - mae: 2.3204 - val_loss: 9.2025 - val_mae: 2.3335\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.3628 - mae: 2.3344 - val_loss: 9.6369 - val_mae: 2.3855\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.2974 - mae: 2.3343 - val_loss: 9.4231 - val_mae: 2.3452\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2399 - mae: 2.3237 - val_loss: 9.3057 - val_mae: 2.3274\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1192 - mae: 2.2979 - val_loss: 8.7557 - val_mae: 2.2678\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.0779 - mae: 2.2823 - val_loss: 9.0216 - val_mae: 2.2931\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1953 - mae: 2.3214 - val_loss: 10.0828 - val_mae: 2.4504\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2016 - mae: 2.3181 - val_loss: 8.8197 - val_mae: 2.2566\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2723 - mae: 2.2893 - val_loss: 8.2250 - val_mae: 2.1939\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9883 - mae: 2.2842 - val_loss: 9.4900 - val_mae: 2.3638\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.8784 - mae: 2.2860 - val_loss: 9.1868 - val_mae: 2.3390\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.8808 - mae: 2.3069 - val_loss: 9.8657 - val_mae: 2.4589\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.8375 - mae: 2.2830 - val_loss: 8.8830 - val_mae: 2.2826\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.8235 - mae: 2.2509 - val_loss: 8.4613 - val_mae: 2.1946\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9479 - mae: 2.2867 - val_loss: 11.1266 - val_mae: 2.5603\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9150 - mae: 2.2893 - val_loss: 9.0069 - val_mae: 2.2835\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6295 - mae: 2.2701 - val_loss: 9.0899 - val_mae: 2.2808\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5214 - mae: 2.2615 - val_loss: 9.2122 - val_mae: 2.3177\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3739 - mae: 2.2339 - val_loss: 8.9496 - val_mae: 2.2650\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4518 - mae: 2.2312 - val_loss: 8.8028 - val_mae: 2.2292\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4411 - mae: 2.2212 - val_loss: 8.9126 - val_mae: 2.2879\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3454 - mae: 2.2087 - val_loss: 8.5510 - val_mae: 2.2454\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2853 - mae: 2.2144 - val_loss: 9.0675 - val_mae: 2.3197\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2123 - mae: 2.2237 - val_loss: 8.9555 - val_mae: 2.2889\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1372 - mae: 2.2034 - val_loss: 8.7490 - val_mae: 2.2793\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0498 - mae: 2.1888 - val_loss: 9.2521 - val_mae: 2.3328\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0603 - mae: 2.1899 - val_loss: 8.9606 - val_mae: 2.2824\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0342 - mae: 2.1831 - val_loss: 8.8146 - val_mae: 2.2672\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0209 - mae: 2.1915 - val_loss: 9.3990 - val_mae: 2.3600\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1167 - mae: 2.2158 - val_loss: 8.9588 - val_mae: 2.3020\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0350 - mae: 2.1834 - val_loss: 8.9453 - val_mae: 2.2760\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9017 - mae: 2.1685 - val_loss: 8.9242 - val_mae: 2.2892\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7854 - mae: 2.1664 - val_loss: 9.0739 - val_mae: 2.3161\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7886 - mae: 2.1609 - val_loss: 9.0134 - val_mae: 2.2993\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7242 - mae: 2.1484 - val_loss: 8.8324 - val_mae: 2.2700\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6801 - mae: 2.1423 - val_loss: 8.7535 - val_mae: 2.2634\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6386 - mae: 2.1446 - val_loss: 8.7803 - val_mae: 2.2753\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6373 - mae: 2.1426 - val_loss: 8.4986 - val_mae: 2.2140\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6575 - mae: 2.1447 - val_loss: 8.7808 - val_mae: 2.2522\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6538 - mae: 2.1266 - val_loss: 8.3141 - val_mae: 2.1986\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6014 - mae: 2.1277 - val_loss: 8.5246 - val_mae: 2.2534\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5514 - mae: 2.1434 - val_loss: 8.6498 - val_mae: 2.2542\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5012 - mae: 2.1424 - val_loss: 8.6956 - val_mae: 2.2429\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4002 - mae: 2.1136 - val_loss: 8.4144 - val_mae: 2.2088\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3224 - mae: 2.1125 - val_loss: 8.7124 - val_mae: 2.2659\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3343 - mae: 2.1199 - val_loss: 8.8019 - val_mae: 2.2854\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3011 - mae: 2.1086 - val_loss: 8.7301 - val_mae: 2.2572\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3095 - mae: 2.1108 - val_loss: 9.2143 - val_mae: 2.3256\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3466 - mae: 2.1032 - val_loss: 8.1641 - val_mae: 2.1510\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1942 - mae: 2.0739 - val_loss: 8.6816 - val_mae: 2.2533\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1879 - mae: 2.0911 - val_loss: 8.5589 - val_mae: 2.2249\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1363 - mae: 2.0903 - val_loss: 8.5479 - val_mae: 2.2260\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1314 - mae: 2.0826 - val_loss: 8.3625 - val_mae: 2.2027\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0038 - mae: 2.0759 - val_loss: 8.4588 - val_mae: 2.2196\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1997 - mae: 2.1139 - val_loss: 8.4262 - val_mae: 2.2014\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5562 - mae: 2.1620 - val_loss: 10.7236 - val_mae: 2.4741\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3205 - mae: 2.1061 - val_loss: 9.1836 - val_mae: 2.2671\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0931 - mae: 2.0793 - val_loss: 8.7792 - val_mae: 2.2284\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3283 - mae: 2.1348 - val_loss: 10.5375 - val_mae: 2.4726\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0777 - mae: 2.0844 - val_loss: 8.6400 - val_mae: 2.2014\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7735 - mae: 2.0549 - val_loss: 8.9245 - val_mae: 2.2481\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9618 - mae: 2.1003 - val_loss: 9.2622 - val_mae: 2.2907\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7452 - mae: 2.0579 - val_loss: 8.5352 - val_mae: 2.1867\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7403 - mae: 2.0477 - val_loss: 8.9307 - val_mae: 2.2554\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6295 - mae: 2.0334 - val_loss: 8.6760 - val_mae: 2.2285\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5883 - mae: 2.0182 - val_loss: 8.5488 - val_mae: 2.2057\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5190 - mae: 2.0122 - val_loss: 8.5956 - val_mae: 2.2130\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5998 - mae: 2.0213 - val_loss: 8.3881 - val_mae: 2.1852\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6270 - mae: 2.0229 - val_loss: 8.5024 - val_mae: 2.1971\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5711 - mae: 2.0365 - val_loss: 8.9730 - val_mae: 2.2708\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4914 - mae: 2.0236 - val_loss: 8.4957 - val_mae: 2.1852\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5152 - mae: 2.0292 - val_loss: 8.5829 - val_mae: 2.2158\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4721 - mae: 2.0235 - val_loss: 9.0905 - val_mae: 2.2708\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4030 - mae: 2.0087 - val_loss: 8.3393 - val_mae: 2.1465\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3180 - mae: 1.9974 - val_loss: 8.6777 - val_mae: 2.1990\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3306 - mae: 2.0007 - val_loss: 8.9892 - val_mae: 2.2379\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3697 - mae: 1.9953 - val_loss: 8.7060 - val_mae: 2.2064\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2729 - mae: 1.9801 - val_loss: 8.1292 - val_mae: 2.1418\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2596 - mae: 1.9874 - val_loss: 8.4221 - val_mae: 2.1820\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2716 - mae: 1.9834 - val_loss: 8.9708 - val_mae: 2.2491\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1161 - mae: 1.9687 - val_loss: 8.1308 - val_mae: 2.1338\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4504 - mae: 2.0060 - val_loss: 7.5847 - val_mae: 2.0843\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2416 - mae: 1.9912 - val_loss: 9.2592 - val_mae: 2.2894\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1911 - mae: 1.9703 - val_loss: 8.2224 - val_mae: 2.1353\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0685 - mae: 1.9642 - val_loss: 8.2961 - val_mae: 2.1655\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0375 - mae: 1.9749 - val_loss: 8.6833 - val_mae: 2.2083\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9829 - mae: 1.9477 - val_loss: 8.0560 - val_mae: 2.1079\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9746 - mae: 1.9338 - val_loss: 7.9731 - val_mae: 2.1125\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9486 - mae: 1.9338 - val_loss: 8.0611 - val_mae: 2.1275\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9047 - mae: 1.9353 - val_loss: 8.1475 - val_mae: 2.1486\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8990 - mae: 1.9265 - val_loss: 7.9643 - val_mae: 2.1178\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9276 - mae: 1.9464 - val_loss: 8.3576 - val_mae: 2.1811\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9055 - mae: 1.9348 - val_loss: 8.0997 - val_mae: 2.1291\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8988 - mae: 1.9450 - val_loss: 8.3469 - val_mae: 2.1764\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8532 - mae: 1.9602 - val_loss: 8.9289 - val_mae: 2.2454\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8540 - mae: 1.9621 - val_loss: 7.9442 - val_mae: 2.0835\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7389 - mae: 1.9245 - val_loss: 8.0347 - val_mae: 2.1038\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7261 - mae: 1.9295 - val_loss: 8.4058 - val_mae: 2.1764\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8616 - mae: 1.9528 - val_loss: 8.6001 - val_mae: 2.1838\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7319 - mae: 1.9258 - val_loss: 7.7846 - val_mae: 2.0725\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6328 - mae: 1.9101 - val_loss: 8.7644 - val_mae: 2.2185\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7123 - mae: 1.9179 - val_loss: 8.3360 - val_mae: 2.1391\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5686 - mae: 1.8982 - val_loss: 8.1620 - val_mae: 2.1160\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5792 - mae: 1.9073 - val_loss: 8.2961 - val_mae: 2.1541\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5300 - mae: 1.8962 - val_loss: 8.2955 - val_mae: 2.1400\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6956 - mae: 1.9300 - val_loss: 8.9511 - val_mae: 2.2242\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6770 - mae: 1.9246 - val_loss: 8.2135 - val_mae: 2.1137\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5397 - mae: 1.8947 - val_loss: 7.7403 - val_mae: 2.0686\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5745 - mae: 1.8844 - val_loss: 8.2417 - val_mae: 2.1494\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8714 - mae: 1.9722 - val_loss: 8.8552 - val_mae: 2.2213\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4814 - mae: 1.8904 - val_loss: 7.7130 - val_mae: 2.0184\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4939 - mae: 1.8742 - val_loss: 8.0222 - val_mae: 2.0803\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5111 - mae: 1.9163 - val_loss: 8.2587 - val_mae: 2.1245\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3723 - mae: 1.8840 - val_loss: 7.9005 - val_mae: 2.0578\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4084 - mae: 1.8623 - val_loss: 7.6730 - val_mae: 2.0587\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3094 - mae: 1.8722 - val_loss: 8.3433 - val_mae: 2.1337\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2662 - mae: 1.8588 - val_loss: 7.6976 - val_mae: 2.0322\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3727 - mae: 1.8578 - val_loss: 7.8017 - val_mae: 2.0375\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1920 - mae: 1.8511 - val_loss: 8.1352 - val_mae: 2.0918\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2673 - mae: 1.8648 - val_loss: 8.3179 - val_mae: 2.1367\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1430 - mae: 1.8483 - val_loss: 7.6271 - val_mae: 2.0610\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2852 - mae: 1.8418 - val_loss: 8.0153 - val_mae: 2.1000\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.2466 - mae: 1.8814 - val_loss: 8.1310 - val_mae: 2.1182\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1248 - mae: 1.8461 - val_loss: 7.6916 - val_mae: 2.0569\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1620 - mae: 1.8607 - val_loss: 7.9274 - val_mae: 2.0716\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1242 - mae: 1.8408 - val_loss: 7.8144 - val_mae: 2.0514\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1296 - mae: 1.8244 - val_loss: 8.0291 - val_mae: 2.0816\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0402 - mae: 1.8228 - val_loss: 7.4063 - val_mae: 2.0013\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3530 - mae: 1.8621 - val_loss: 7.5339 - val_mae: 2.0057\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0627 - mae: 1.8258 - val_loss: 7.9948 - val_mae: 2.0765\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9877 - mae: 1.8335 - val_loss: 7.6674 - val_mae: 2.0448\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9036 - mae: 1.8029 - val_loss: 7.8786 - val_mae: 2.0600\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8676 - mae: 1.7970 - val_loss: 7.7743 - val_mae: 2.0660\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9453 - mae: 1.8055 - val_loss: 7.9268 - val_mae: 2.0500\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1077 - mae: 1.8218 - val_loss: 7.9881 - val_mae: 2.0591\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8661 - mae: 1.8030 - val_loss: 8.0533 - val_mae: 2.0886\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8772 - mae: 1.8288 - val_loss: 7.8893 - val_mae: 2.0452\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8795 - mae: 1.7970 - val_loss: 8.2708 - val_mae: 2.0783\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.9514 - mae: 1.8433 - val_loss: 7.9989 - val_mae: 2.0762\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9134 - mae: 1.8155 - val_loss: 7.5483 - val_mae: 2.0135\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7717 - mae: 1.7625 - val_loss: 7.7315 - val_mae: 2.0196\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7715 - mae: 1.7912 - val_loss: 7.2420 - val_mae: 1.9529\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8222 - mae: 1.7848 - val_loss: 7.8987 - val_mae: 2.0406\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7048 - mae: 1.7828 - val_loss: 7.8020 - val_mae: 2.0171\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6437 - mae: 1.7555 - val_loss: 7.8928 - val_mae: 2.0211\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5857 - mae: 1.7566 - val_loss: 7.6487 - val_mae: 1.9976\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6160 - mae: 1.7590 - val_loss: 7.6025 - val_mae: 2.0030\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5735 - mae: 1.7447 - val_loss: 7.7519 - val_mae: 2.0307\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6141 - mae: 1.7709 - val_loss: 8.0376 - val_mae: 2.0751\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5034 - mae: 1.7464 - val_loss: 7.6927 - val_mae: 2.0146\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5547 - mae: 1.7469 - val_loss: 7.9333 - val_mae: 2.0389\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5565 - mae: 1.7354 - val_loss: 8.1597 - val_mae: 2.0838\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4507 - mae: 1.7039 - val_loss: 7.6252 - val_mae: 1.9859\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5303 - mae: 1.7430 - val_loss: 7.7268 - val_mae: 2.0086\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4129 - mae: 1.7142 - val_loss: 7.8667 - val_mae: 2.0226\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4110 - mae: 1.7062 - val_loss: 7.8359 - val_mae: 2.0137\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5161 - mae: 1.7490 - val_loss: 8.2721 - val_mae: 2.0935\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4060 - mae: 1.7309 - val_loss: 7.6005 - val_mae: 1.9805\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2791 - mae: 1.6927 - val_loss: 7.8047 - val_mae: 2.0093\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2599 - mae: 1.6984 - val_loss: 7.5204 - val_mae: 1.9857\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2853 - mae: 1.6904 - val_loss: 7.7005 - val_mae: 2.0057\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2606 - mae: 1.6977 - val_loss: 7.4775 - val_mae: 1.9851\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3610 - mae: 1.7059 - val_loss: 7.9489 - val_mae: 2.0619\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3784 - mae: 1.7514 - val_loss: 8.6702 - val_mae: 2.1672\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4142 - mae: 1.7203 - val_loss: 7.7272 - val_mae: 1.9648\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2032 - mae: 1.6760 - val_loss: 7.7674 - val_mae: 1.9904\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1476 - mae: 1.6652 - val_loss: 7.6178 - val_mae: 1.9864\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0688 - mae: 1.6568 - val_loss: 7.9962 - val_mae: 2.0344\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7846 - mae: 1.8245 - val_loss: 8.8388 - val_mae: 2.0796\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5069 - mae: 1.7367 - val_loss: 8.0080 - val_mae: 1.9959\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1570 - mae: 1.6851 - val_loss: 8.4901 - val_mae: 2.0887\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0176 - mae: 1.6625 - val_loss: 7.9120 - val_mae: 2.0154\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1208 - mae: 1.6616 - val_loss: 7.9742 - val_mae: 2.0093\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9837 - mae: 1.6626 - val_loss: 7.8272 - val_mae: 2.0139\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1486 - mae: 1.6514 - val_loss: 7.7610 - val_mae: 2.0252\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0026 - mae: 1.6416 - val_loss: 7.8654 - val_mae: 2.0259\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9522 - mae: 1.6562 - val_loss: 8.0654 - val_mae: 2.0309\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.9876 - mae: 1.6396 - val_loss: 7.7871 - val_mae: 1.9886\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8910 - mae: 1.6402 - val_loss: 7.7814 - val_mae: 1.9834\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9035 - mae: 1.6326 - val_loss: 7.5652 - val_mae: 1.9517\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9056 - mae: 1.6459 - val_loss: 7.5285 - val_mae: 1.9555\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0383 - mae: 1.6649 - val_loss: 7.7418 - val_mae: 1.9845\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8252 - mae: 1.6158 - val_loss: 7.8023 - val_mae: 1.9968\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8478 - mae: 1.6536 - val_loss: 8.0970 - val_mae: 2.0406\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8964 - mae: 1.6296 - val_loss: 7.8832 - val_mae: 1.9749\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8180 - mae: 1.6290 - val_loss: 8.1042 - val_mae: 2.0272\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7156 - mae: 1.5930 - val_loss: 7.7775 - val_mae: 1.9922\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8592 - mae: 1.5919 - val_loss: 7.5527 - val_mae: 1.9600\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6555 - mae: 1.5935 - val_loss: 7.4463 - val_mae: 1.9585\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6690 - mae: 1.5814 - val_loss: 7.4118 - val_mae: 1.9626\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6350 - mae: 1.5875 - val_loss: 7.5879 - val_mae: 1.9801\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7035 - mae: 1.5808 - val_loss: 7.6582 - val_mae: 1.9882\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.6447 - mae: 1.5806 - val_loss: 7.6906 - val_mae: 1.9917\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5684 - mae: 1.6002 - val_loss: 7.9092 - val_mae: 2.0239\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5516 - mae: 1.5956 - val_loss: 7.6266 - val_mae: 1.9802\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4963 - mae: 1.5798 - val_loss: 7.6772 - val_mae: 1.9989\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4717 - mae: 1.5725 - val_loss: 7.5958 - val_mae: 1.9762\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5377 - mae: 1.5528 - val_loss: 7.6499 - val_mae: 1.9815\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5085 - mae: 1.5788 - val_loss: 7.6632 - val_mae: 1.9845\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4701 - mae: 1.5332 - val_loss: 7.5399 - val_mae: 1.9621\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6288 - mae: 1.6009 - val_loss: 7.6304 - val_mae: 1.9655\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5214 - mae: 1.5770 - val_loss: 7.8769 - val_mae: 2.0013\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5224 - mae: 1.5863 - val_loss: 7.5130 - val_mae: 1.9528\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3640 - mae: 1.5336 - val_loss: 7.6604 - val_mae: 1.9730\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3905 - mae: 1.5535 - val_loss: 7.0821 - val_mae: 1.9212\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3140 - mae: 1.5313 - val_loss: 7.2903 - val_mae: 1.9399\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3341 - mae: 1.5209 - val_loss: 7.1616 - val_mae: 1.9211\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3202 - mae: 1.5093 - val_loss: 7.2186 - val_mae: 1.9382\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4064 - mae: 1.5371 - val_loss: 7.2801 - val_mae: 1.9598\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3617 - mae: 1.5491 - val_loss: 7.3215 - val_mae: 1.9414\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2752 - mae: 1.5160 - val_loss: 7.6401 - val_mae: 2.0131\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2055 - mae: 1.5164 - val_loss: 7.3085 - val_mae: 1.9379\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2239 - mae: 1.4893 - val_loss: 7.3195 - val_mae: 1.9404\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2149 - mae: 1.4988 - val_loss: 7.6353 - val_mae: 2.0020\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.1308 - mae: 1.5065 - val_loss: 7.3245 - val_mae: 1.9723\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2049 - mae: 1.4923 - val_loss: 7.5339 - val_mae: 1.9896\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3184 - mae: 1.5576 - val_loss: 7.6413 - val_mae: 1.9837\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3328133.0000 - mae: 1785.1852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3UJLzAPUhJV",
        "outputId": "aa631b26-b6af-461a-e555-a5e5332e4d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1964.5044677734375"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}